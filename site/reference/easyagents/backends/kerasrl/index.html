



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.4.3">
    
    
      
        <title>Kerasrl - easyagents</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/application.30686662.css">
      
        <link rel="stylesheet" href="../../../../assets/stylesheets/application-palette.a8b3c06d.css">
      
      
        
        
        <meta name="theme-color" content="#4caf50">
      
    
    
      <script src="../../../../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../../../assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="green" data-md-color-accent="lightgreen">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#module-easyagentsbackendskerasrl" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../.." title="easyagents" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              easyagents
            </span>
            <span class="md-header-nav__topic">
              
                Kerasrl
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/christianhidber/easyagents/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    easyagents
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../.." title="easyagents" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    easyagents
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/christianhidber/easyagents/" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    easyagents
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../../../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../CODE_OF_CONDUCT/" title="Code Of Conduct" class="md-nav__link">
      Code Of Conduct
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../CONTRIBUTING/" title="Contributing" class="md-nav__link">
      Contributing
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../documentation/markdown/Release Notes/" title="Release Notes" class="md-nav__link">
      Release Notes
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5" checked>
    
    <label class="md-nav__link" for="nav-5">
      Reference
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Reference
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1" type="checkbox" id="nav-5-1" checked>
    
    <label class="md-nav__link" for="nav-5-1">
      Easyagents
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="2">
      <label class="md-nav__title" for="nav-5-1">
        Easyagents
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../agents/" title="Agents" class="md-nav__link">
      Agents
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/" title="Core" class="md-nav__link">
      Core
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1-3" type="checkbox" id="nav-5-1-3" checked>
    
    <label class="md-nav__link" for="nav-5-1-3">
      Backends
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-1-3">
        Backends
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../core/" title="Core" class="md-nav__link">
      Core
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Kerasrl
      </label>
    
    <a href="./" title="Kerasrl" class="md-nav__link md-nav__link--active">
      Kerasrl
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cemkerasrlagent" class="md-nav__link">
    CemKerasRlAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kerasrlagent" class="md-nav__link">
    KerasRlAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log_1" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api_1" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin_1" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end_1" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin_1" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end_1" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_1" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation_1" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_1" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation_1" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kerasrlagentfactory" class="md-nav__link">
    KerasRlAgentFactory
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_2" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_2" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_agent" class="md-nav__link">
    create_agent
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_algorithms" class="md-nav__link">
    get_algorithms
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kerasrlcemagent" class="md-nav__link">
    KerasRlCemAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_3" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_1" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_3" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log_2" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api_2" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin_2" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end_2" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin_2" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end_2" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_2" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation_2" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_2" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation_2" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kerasrldoubledqnagent" class="md-nav__link">
    KerasRlDoubleDqnAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_4" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_2" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_4" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log_3" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api_3" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin_3" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end_3" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin_3" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end_3" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_3" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation_3" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_3" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation_3" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kerasrldqnagent" class="md-nav__link">
    KerasRlDqnAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_5" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants_1" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_3" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_5" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log_4" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api_4" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin_4" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end_4" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin_4" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end_4" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_4" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation_4" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_4" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation_4" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kerasrlduelingdqnagent" class="md-nav__link">
    KerasRlDuelingDqnAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_6" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_4" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_6" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log_5" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api_5" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin_5" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end_5" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin_5" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end_5" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_5" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation_5" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_5" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation_5" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../tfagents/" title="Tfagents" class="md-nav__link">
      Tfagents
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../tforce/" title="Tforce" class="md-nav__link">
      Tforce
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5-1-4" type="checkbox" id="nav-5-1-4">
    
    <label class="md-nav__link" for="nav-5-1-4">
      Callbacks
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="3">
      <label class="md-nav__title" for="nav-5-1-4">
        Callbacks
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../callbacks/duration/" title="Duration" class="md-nav__link">
      Duration
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../callbacks/log/" title="Log" class="md-nav__link">
      Log
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../callbacks/plot/" title="Plot" class="md-nav__link">
      Plot
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cemkerasrlagent" class="md-nav__link">
    CemKerasRlAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kerasrlagent" class="md-nav__link">
    KerasRlAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log_1" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api_1" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin_1" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end_1" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin_1" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end_1" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_1" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation_1" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_1" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation_1" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kerasrlagentfactory" class="md-nav__link">
    KerasRlAgentFactory
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_2" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_2" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create_agent" class="md-nav__link">
    create_agent
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_algorithms" class="md-nav__link">
    get_algorithms
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kerasrlcemagent" class="md-nav__link">
    KerasRlCemAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_3" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_1" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_3" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log_2" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api_2" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin_2" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end_2" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin_2" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end_2" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_2" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation_2" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_2" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation_2" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kerasrldoubledqnagent" class="md-nav__link">
    KerasRlDoubleDqnAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_4" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_2" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_4" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log_3" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api_3" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin_3" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end_3" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin_3" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end_3" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_3" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation_3" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_3" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation_3" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kerasrldqnagent" class="md-nav__link">
    KerasRlDqnAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_5" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants_1" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_3" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_5" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log_4" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api_4" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin_4" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end_4" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin_4" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end_4" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_4" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation_4" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_4" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation_4" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kerasrlduelingdqnagent" class="md-nav__link">
    KerasRlDuelingDqnAgent
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_6" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_4" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_6" class="md-nav__link">
    Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#log_5" class="md-nav__link">
    log
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#log_api_5" class="md-nav__link">
    log_api
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_begin_5" class="md-nav__link">
    on_play_episode_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_play_episode_end_5" class="md-nav__link">
    on_play_episode_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_begin_5" class="md-nav__link">
    on_train_iteration_begin
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_iteration_end_5" class="md-nav__link">
    on_train_iteration_end
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_5" class="md-nav__link">
    play
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#play_implementation_5" class="md-nav__link">
    play_implementation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_5" class="md-nav__link">
    train
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_implementation_5" class="md-nav__link">
    train_implementation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/christianhidber/easyagents/edit/master/reference/easyagents/backends/kerasrl.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="module-easyagentsbackendskerasrl">Module easyagents.backends.kerasrl</h1>
<p>This module contains the backend implementation for keras-rl (see https://github.com/keras-rl/keras-rl)</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="sd">&quot;&quot;&quot;This module contains the backend implementation for keras-rl (see https://github.com/keras-rl/keras-rl)&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABCMeta</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Type</span>

<span class="kn">import</span> <span class="nn">math</span>

<span class="c1"># noinspection PyUnresolvedReferences</span>

<span class="kn">import</span> <span class="nn">easyagents.agents</span>

<span class="kn">from</span> <span class="nn">easyagents</span> <span class="kn">import</span> <span class="n">core</span>

<span class="kn">from</span> <span class="nn">easyagents.backends</span> <span class="kn">import</span> <span class="n">core</span> <span class="k">as</span> <span class="n">bcore</span>

<span class="kn">import</span> <span class="nn">keras.backend</span> <span class="kn">as</span> <span class="nn">K</span>

<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">Dense</span>

<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Model</span>

<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="kn">import</span> <span class="nn">rl.core</span>

<span class="kn">from</span> <span class="nn">rl.agents.dqn</span> <span class="kn">import</span> <span class="n">DQNAgent</span>

<span class="kn">from</span> <span class="nn">rl.agents.cem</span> <span class="kn">import</span> <span class="n">CEMAgent</span>

<span class="kn">from</span> <span class="nn">rl.callbacks</span> <span class="kn">import</span> <span class="n">Callback</span>

<span class="kn">from</span> <span class="nn">rl.policy</span> <span class="kn">import</span> <span class="n">BoltzmannQPolicy</span><span class="p">,</span> <span class="n">EpsGreedyQPolicy</span><span class="p">,</span> <span class="n">GreedyQPolicy</span>

<span class="kn">from</span> <span class="nn">rl.memory</span> <span class="kn">import</span> <span class="n">EpisodeParameterMemory</span><span class="p">,</span> <span class="n">SequentialMemory</span>

<span class="kn">import</span> <span class="nn">gym</span>

<span class="kn">import</span> <span class="nn">gym.spaces</span>

<span class="c1"># noinspection PyUnresolvedReferences,PyAbstractClass</span>

<span class="k">class</span> <span class="nc">KerasRlAgent</span><span class="p">(</span><span class="n">bcore</span><span class="o">.</span><span class="n">BackendAgent</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Reinforcement learning agents based on keras-rl originally developed by matthias plappert</span>

<span class="sd">        https://github.com/keras-rl/keras-rl</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_config</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">,</span>

                         <span class="n">backend_name</span><span class="o">=</span><span class="n">KerasRlAgentFactory</span><span class="o">.</span><span class="n">backend_name</span><span class="p">,</span>

                         <span class="n">tensorflow_v2_eager</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">rl</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Agent</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_play_env</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>

    <span class="k">def</span> <span class="nf">_create_env</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">:</span>

        <span class="sd">&quot;&quot;&quot;Creates a new gym instance.&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;gym.make&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(&quot;{self.model_config.original_env_name}&quot;)&#39;</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">gym_env_name</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gym_env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">activation</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequential</span><span class="p">:</span>

        <span class="sd">&quot;&quot;&quot;Creates a model consisting of  fully connected layers as given by self.model_config.fc_layers</span>

<span class="sd">        with relu as activation function.</span>

<span class="sd">        Args:</span>

<span class="sd">            gym_env: gym_env whose observation shape ofdefines the size of the input layer and</span>

<span class="sd">                whose action_space defines the size of the output layer.</span>

<span class="sd">            activation: output activation function eg &#39;linear&#39; or &#39;softmax&#39;</span>

<span class="sd">        Returns:</span>

<span class="sd">            Keras Sequential model according to model_config.fc_layers</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="n">gym_env</span>

        <span class="n">num_actions</span> <span class="o">=</span> <span class="n">gym_env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Sequential&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;()&#39;</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

        <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">gym_env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;model.add&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(Flatten(input_shape={input_shape}))&#39;</span><span class="p">)</span>

        <span class="n">result</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">layer_size</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">fc_layers</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;model.add&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(Dense({layer_size}))&#39;</span><span class="p">)</span>

            <span class="n">result</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">layer_size</span><span class="p">))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;model.add&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(Activation(&quot;relu&quot;))&#39;</span><span class="p">)</span>

            <span class="n">result</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;model.add&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(Dense({num_actions}))&#39;</span><span class="p">)</span>

        <span class="n">result</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_actions</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;model.add&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(Activation(&quot;{activation}&quot;))&#39;</span><span class="p">)</span>

        <span class="n">result</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">play_implementation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">play_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Agent specific implementation of playing a single episodes with the current policy.</span>

<span class="sd">            Args:</span>

<span class="sd">                play_context: play configuration to be used</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="n">play_context</span><span class="p">,</span> <span class="s2">&quot;play_context not set.&quot;</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span><span class="p">,</span> <span class="s2">&quot;_agent not set. call train() first.&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_play_env</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_play_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_env</span><span class="p">()</span>

        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">on_play_episode_begin</span><span class="p">(</span><span class="n">env</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_play_env</span><span class="p">)</span>

            <span class="n">observation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_play_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

            <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>

            <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>

                <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>

                <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_play_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">on_play_episode_end</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">play_context</span><span class="o">.</span><span class="n">play_done</span><span class="p">:</span>

                <span class="k">break</span>

<span class="k">class</span> <span class="nc">KerasRlCemAgent</span><span class="p">(</span><span class="n">KerasRlAgent</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Keras-rl implementation of the cross-entropy method algorithm.</span>

<span class="sd">        see &quot;https://learning.mpi-sws.org/mlss2016/slides/2016-MLSS-RL.pdf&quot; and</span>

<span class="sd">            &quot;https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.6579&amp;rep=rep1&amp;type=pdf&quot;</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">class</span> <span class="nc">CemCallback</span><span class="p">(</span><span class="n">rl</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Callback registered with keras rl agents to propagate iteration and episode updates.&quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cem_agent</span><span class="p">:</span> <span class="n">KerasRlAgent</span><span class="p">,</span> <span class="n">cem_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">CemTrainContext</span><span class="p">,</span> <span class="n">nb_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>

            <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">            Args:</span>

<span class="sd">                cem_agent: the agent to propagate iteration begn/end events to.</span>

<span class="sd">                cem_context: the train_context containing the iteration definitions</span>

<span class="sd">                nb_steps: value set in the keras cem agent.</span>

<span class="sd">            &quot;&quot;&quot;</span>

            <span class="k">assert</span> <span class="n">cem_agent</span>

            <span class="k">assert</span> <span class="n">cem_context</span>

            <span class="k">assert</span> <span class="n">nb_steps</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_cem_agent</span><span class="p">:</span> <span class="n">KerasRlAgent</span> <span class="o">=</span> <span class="n">cem_agent</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_cem_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">CemTrainContext</span> <span class="o">=</span> <span class="n">cem_context</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_nb_steps</span> <span class="o">=</span> <span class="n">nb_steps</span>

            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">on_episode_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">episode</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

            <span class="sd">&quot;&quot;&quot;Signals the base class the end / begin of a training iteration.&quot;&quot;&quot;</span>

            <span class="n">cc</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">CemTrainContext</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cem_context</span>

            <span class="n">episode</span> <span class="o">=</span> <span class="n">episode</span> <span class="o">+</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="n">episode</span> <span class="o">%</span> <span class="n">cc</span><span class="o">.</span><span class="n">num_episodes_per_iteration</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_cem_agent</span><span class="o">.</span><span class="n">on_train_iteration_end</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cem_context</span><span class="o">.</span><span class="n">training_done</span><span class="p">:</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">_cem_agent</span><span class="o">.</span><span class="n">_agent</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nb_steps</span>

                <span class="k">else</span><span class="p">:</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">_cem_agent</span><span class="o">.</span><span class="n">on_train_iteration_begin</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">train_implementation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">CemTrainContext</span><span class="p">):</span>

        <span class="k">assert</span> <span class="n">train_context</span>

        <span class="n">cc</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">CemTrainContext</span> <span class="o">=</span> <span class="n">train_context</span>

        <span class="n">train_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_env</span><span class="p">()</span>

        <span class="n">keras_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_model</span><span class="p">(</span><span class="n">gym_env</span><span class="o">=</span><span class="n">train_env</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>

        <span class="n">policy_buffer_size</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">cc</span><span class="o">.</span><span class="n">num_episodes_per_iteration</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;EpisodeParameterMemory&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(limit={policy_buffer_size}, window_length=1)&#39;</span><span class="p">)</span>

        <span class="n">memory</span> <span class="o">=</span> <span class="n">EpisodeParameterMemory</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="n">policy_buffer_size</span><span class="p">,</span> <span class="n">window_length</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">num_actions</span> <span class="o">=</span> <span class="n">train_env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;CEMAgent&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(model=..., nb_actions={num_actions}, memory=..., &#39;</span> <span class="o">+</span> \

                     <span class="n">f</span><span class="s1">&#39;nb_steps_warmup={cc.num_steps_buffer_preload}, &#39;</span> <span class="o">+</span> \

                     <span class="n">f</span><span class="s1">&#39;train_interval={cc.num_episodes_per_iteration}, &#39;</span> <span class="o">+</span> \

                     <span class="n">f</span><span class="s1">&#39;batch_size={cc.num_episodes_per_iteration}, &#39;</span> <span class="o">+</span> \

                     <span class="n">f</span><span class="s1">&#39;elite_frac={cc.elite_set_fraction})&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span> <span class="o">=</span> <span class="n">CEMAgent</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">keras_model</span><span class="p">,</span> <span class="n">nb_actions</span><span class="o">=</span><span class="n">num_actions</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span>

                               <span class="n">nb_steps_warmup</span><span class="o">=</span><span class="n">cc</span><span class="o">.</span><span class="n">num_steps_buffer_preload</span><span class="p">,</span>

                               <span class="n">batch_size</span><span class="o">=</span><span class="n">cc</span><span class="o">.</span><span class="n">num_episodes_per_iteration</span><span class="p">,</span>

                               <span class="n">train_interval</span><span class="o">=</span><span class="n">cc</span><span class="o">.</span><span class="n">num_episodes_per_iteration</span><span class="p">,</span>

                               <span class="n">elite_frac</span><span class="o">=</span><span class="n">cc</span><span class="o">.</span><span class="n">elite_set_fraction</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;agent.compile&#39;</span><span class="p">,</span> <span class="s1">&#39;()&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>

        <span class="n">nb_steps</span> <span class="o">=</span> <span class="n">cc</span><span class="o">.</span><span class="n">num_iterations</span> <span class="o">*</span> <span class="n">cc</span><span class="o">.</span><span class="n">num_episodes_per_iteration</span> <span class="o">*</span> <span class="n">cc</span><span class="o">.</span><span class="n">max_steps_per_episode</span>

        <span class="n">callback</span> <span class="o">=</span> <span class="n">KerasRlCemAgent</span><span class="o">.</span><span class="n">CemCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cc</span><span class="p">,</span> <span class="n">nb_steps</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">on_train_iteration_begin</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;agent.fit&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(train_env, nb_steps={nb_steps})&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_env</span><span class="p">,</span> <span class="n">nb_steps</span><span class="o">=</span><span class="n">nb_steps</span><span class="p">,</span> <span class="n">visualize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callback</span><span class="p">])</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">cc</span><span class="o">.</span><span class="n">training_done</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">on_train_iteration_end</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">KerasRlDqnAgent</span><span class="p">(</span><span class="n">KerasRlAgent</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Keras-rl implementation of the algorithm described in in Mnih (2013) and Mnih (2015).</span>

<span class="sd">        http://arxiv.org/pdf/1312.5602.pdf and http://arxiv.org/abs/1509.06461</span>

<span class="sd">        includes implementations for the double dqn and dueling dqn variations.</span>

<span class="sd">        &quot;&quot;&quot;</span>

    <span class="k">class</span> <span class="nc">DQNAgentWrapper</span><span class="p">(</span><span class="n">DQNAgent</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Override of the KerasRl DqnAgennt instantiation due to a conflict with tensorflow 1.15.</span>

<span class="sd">        Essentially a copy of  https://raw.githubusercontent.com/keras-rl/keras-rl/master/rl/agents/dqn.py</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">policy</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">test_policy</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">enable_double_dqn</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">enable_dueling_network</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>

                     <span class="n">dueling_type</span><span class="o">=</span><span class="s1">&#39;avg&#39;</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

            <span class="nb">super</span><span class="p">(</span><span class="n">DQNAgent</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">_keras_shape</span> <span class="o">!=</span> <span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nb_actions</span><span class="p">):</span>

                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Model output &quot;{model.output}&quot; has invalid shape. Dqn expects &#39;</span> <span class="o">+</span>

                                 <span class="n">f</span><span class="s1">&#39;a model that has one dimension for each action, in this case {self.nb_actions}.&#39;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">enable_double_dqn</span> <span class="o">=</span> <span class="n">enable_double_dqn</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">enable_dueling_network</span> <span class="o">=</span> <span class="n">enable_dueling_network</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">dueling_type</span> <span class="o">=</span> <span class="n">dueling_type</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_dueling_network</span><span class="p">:</span>

                <span class="n">layer</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>

                <span class="n">nb_action</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">_keras_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

                <span class="n">y</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">nb_action</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)(</span><span class="n">layer</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dueling_type</span> <span class="o">==</span> <span class="s1">&#39;avg&#39;</span><span class="p">:</span>

                    <span class="n">outputlayer</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span>

                        <span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">K</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">a</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">a</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">K</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>

                        <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="n">nb_action</span><span class="p">,))(</span><span class="n">y</span><span class="p">)</span>

                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dueling_type</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>

                    <span class="n">outputlayer</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span>

                        <span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">K</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">a</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">a</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">K</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">a</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>

                        <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="n">nb_action</span><span class="p">,))(</span><span class="n">y</span><span class="p">)</span>

                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dueling_type</span> <span class="o">==</span> <span class="s1">&#39;naive&#39;</span><span class="p">:</span>

                    <span class="n">outputlayer</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">K</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">a</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">a</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">(</span><span class="n">nb_action</span><span class="p">,))(</span><span class="n">y</span><span class="p">)</span>

                <span class="k">else</span><span class="p">:</span>

                    <span class="k">assert</span> <span class="bp">False</span><span class="p">,</span> <span class="s2">&quot;dueling_type must be one of {&#39;avg&#39;,&#39;max&#39;,&#39;naive&#39;}&quot;</span>

                <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">input</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputlayer</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

            <span class="k">if</span> <span class="n">policy</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>

                <span class="n">policy</span> <span class="o">=</span> <span class="n">EpsGreedyQPolicy</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">test_policy</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>

                <span class="n">test_policy</span> <span class="o">=</span> <span class="n">GreedyQPolicy</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">test_policy</span> <span class="o">=</span> <span class="n">test_policy</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>

    <span class="k">class</span> <span class="nc">DqnCallback</span><span class="p">(</span><span class="n">rl</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Callback registered with keras rl agents to propagate iteration and episode updates.&quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent</span><span class="p">:</span> <span class="n">bcore</span><span class="o">.</span><span class="n">BackendAgent</span><span class="p">,</span> <span class="n">dqn_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">StepsTrainContext</span><span class="p">,</span>

                     <span class="n">loss_metric_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]):</span>

            <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">            Args:</span>

<span class="sd">                agent: the agent to propagate iteration begn/end events to.</span>

<span class="sd">                dqn_context: the train_context containing the iteration definitions</span>

<span class="sd">                loss_metric_idx: the index of the loss in the metrics list, or None</span>

<span class="sd">            &quot;&quot;&quot;</span>

            <span class="k">assert</span> <span class="n">agent</span>

            <span class="k">assert</span> <span class="n">dqn_context</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span> <span class="o">=</span> <span class="n">agent</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_dqn_context</span> <span class="o">=</span> <span class="n">dqn_context</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_loss_metric_idx</span> <span class="o">=</span> <span class="n">loss_metric_idx</span>

            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

            <span class="sd">&quot;&quot;&quot;Signals the base class the end / begin of a training iteration.&quot;&quot;&quot;</span>

            <span class="n">steps_done</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dqn_context</span><span class="o">.</span><span class="n">steps_done_in_training</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dqn_context</span><span class="o">.</span><span class="n">num_steps_buffer_preload</span>

            <span class="k">if</span> <span class="n">steps_done</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">steps_done</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dqn_context</span><span class="o">.</span><span class="n">num_steps_per_iteration</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">nan</span>

                <span class="k">if</span> <span class="n">logs</span> <span class="ow">and</span> <span class="s1">&#39;metrics&#39;</span> <span class="ow">in</span> <span class="n">logs</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss_metric_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">):</span>

                    <span class="n">metrics</span> <span class="o">=</span> <span class="n">logs</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">]</span>

                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_metric_idx</span><span class="p">:</span>

                        <span class="n">loss</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss_metric_idx</span><span class="p">]</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span><span class="o">.</span><span class="n">on_train_iteration_end</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dqn_context</span><span class="o">.</span><span class="n">training_done</span><span class="p">:</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span><span class="o">.</span><span class="n">on_train_iteration_begin</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_config</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span><span class="p">,</span>

                 <span class="n">enable_dueling_dqn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">enable_double_dqn</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot; creates a new agent based on the DQN algorithm using the keras-rl implementation.</span>

<span class="sd">            Args:</span>

<span class="sd">                model_config: the model configuration including the name of the target gym environment</span>

<span class="sd">                    as well as the neural network architecture.</span>

<span class="sd">                enable_double_dqn: use the double dqn algorithm instead</span>

<span class="sd">                enable_dueling_dqn: use the dueling dqn algorithm instead</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_enable_double_dqn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">enable_double_dqn</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_enable_dueling_network</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">enable_dueling_dqn</span>

    <span class="k">def</span> <span class="nf">train_implementation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">StepsTrainContext</span><span class="p">):</span>

        <span class="k">assert</span> <span class="n">train_context</span>

        <span class="n">dc</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">StepsTrainContext</span> <span class="o">=</span> <span class="n">train_context</span>

        <span class="n">train_env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_env</span><span class="p">()</span>

        <span class="n">keras_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_model</span><span class="p">(</span><span class="n">gym_env</span><span class="o">=</span><span class="n">train_env</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;SequentialMemory&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(limit={dc.max_steps_in_buffer}, window_length=1)&#39;</span><span class="p">)</span>

        <span class="n">memory</span> <span class="o">=</span> <span class="n">SequentialMemory</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="n">dc</span><span class="o">.</span><span class="n">max_steps_in_buffer</span><span class="p">,</span> <span class="n">window_length</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;BoltzmannQPolicy&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;()&#39;</span><span class="p">)</span>

        <span class="n">policy</span> <span class="o">=</span> <span class="n">BoltzmannQPolicy</span><span class="p">()</span>

        <span class="n">num_actions</span> <span class="o">=</span> <span class="n">train_env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;DQNAgent&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(nb_actions={num_actions}, &#39;</span> <span class="o">+</span>

                     <span class="n">f</span><span class="s1">&#39;enable_double_dqn={self._enable_double_dqn}, &#39;</span> <span class="o">+</span>

                     <span class="n">f</span><span class="s1">&#39;enable_dueling_network={self._enable_dueling_network}, &#39;</span> <span class="o">+</span>

                     <span class="n">f</span><span class="s1">&#39;nb_steps_warmup={dc.num_steps_buffer_preload}, target_model_update=1e-2,&#39;</span> <span class="o">+</span>

                     <span class="n">f</span><span class="s1">&#39;gamma={dc.reward_discount_gamma}, batch_size={dc.num_steps_sampled_from_buffer}, &#39;</span> <span class="o">+</span>

                     <span class="n">f</span><span class="s1">&#39;train_interval={dc.num_steps_per_iteration}, model=..., memory=..., policy=...)&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span> <span class="o">=</span> <span class="n">KerasRlDqnAgent</span><span class="o">.</span><span class="n">DQNAgentWrapper</span><span class="p">(</span>

            <span class="n">enable_double_dqn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_enable_double_dqn</span><span class="p">,</span>

            <span class="n">enable_dueling_network</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_enable_dueling_network</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="n">keras_model</span><span class="p">,</span>

            <span class="n">nb_actions</span><span class="o">=</span><span class="n">num_actions</span><span class="p">,</span>

            <span class="n">memory</span><span class="o">=</span><span class="n">memory</span><span class="p">,</span>

            <span class="n">nb_steps_warmup</span><span class="o">=</span><span class="n">dc</span><span class="o">.</span><span class="n">num_steps_buffer_preload</span><span class="p">,</span>

            <span class="n">target_model_update</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span>

            <span class="n">gamma</span><span class="o">=</span><span class="n">dc</span><span class="o">.</span><span class="n">reward_discount_gamma</span><span class="p">,</span>

            <span class="n">batch_size</span><span class="o">=</span><span class="n">dc</span><span class="o">.</span><span class="n">num_steps_sampled_from_buffer</span><span class="p">,</span>

            <span class="n">train_interval</span><span class="o">=</span><span class="n">dc</span><span class="o">.</span><span class="n">num_steps_per_iteration</span><span class="p">,</span>

            <span class="n">policy</span><span class="o">=</span><span class="n">policy</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;agent.compile&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(Adam(lr=1e-3), metrics=[&quot;mae&quot;]&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mae&#39;</span><span class="p">])</span>

        <span class="n">num_steps</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">num_iterations</span> <span class="o">*</span> <span class="n">dc</span><span class="o">.</span><span class="n">num_steps_per_iteration</span>

        <span class="n">loss_metric_idx</span> <span class="o">=</span> <span class="bp">None</span>

        <span class="k">if</span> <span class="s1">&#39;loss&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">:</span>

            <span class="n">loss_metric_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span><span class="o">.</span><span class="n">metrics_names</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>

        <span class="n">dqn_callback</span> <span class="o">=</span> <span class="n">KerasRlDqnAgent</span><span class="o">.</span><span class="n">DqnCallback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dc</span><span class="p">,</span> <span class="n">loss_metric_idx</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">on_train_iteration_begin</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;agent.fit&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;(train_env, nb_steps={num_steps})&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_agent</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_env</span><span class="p">,</span> <span class="n">nb_steps</span><span class="o">=</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">visualize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">dqn_callback</span><span class="p">])</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">dc</span><span class="o">.</span><span class="n">training_done</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">on_train_iteration_end</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">KerasRlDoubleDqnAgent</span><span class="p">(</span><span class="n">KerasRlDqnAgent</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Keras-rl implementation of the algorithm described in https://arxiv.org/abs/1509.06461 &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_config</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Args:</span>

<span class="sd">                model_config: the model configuration including the name of the target gym environment</span>

<span class="sd">                    as well as the neural network architecture.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">,</span> <span class="n">enable_double_dqn</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">KerasRlDuelingDqnAgent</span><span class="p">(</span><span class="n">KerasRlDqnAgent</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Keras-rl implementation of the algorithm described in https://arxiv.org/abs/1511.06581 &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_config</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot; creates a new agent based on the DQN algorithm using the keras-rl implementation.</span>

<span class="sd">            Args:</span>

<span class="sd">                model_config: the model configuration including the name of the target gym environment</span>

<span class="sd">                    as well as the neural network architecture.</span>

<span class="sd">                enable_double_dqn:</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">,</span> <span class="n">enable_dueling_dqn</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">CemKerasRlAgent</span><span class="p">(</span><span class="n">KerasRlAgent</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot; creates a new agent based on the CEM algorithm using the keras-rl implementation.</span>

<span class="sd">        https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.6579&amp;rep=rep1&amp;type=pdf</span>

<span class="sd">         Args:</span>

<span class="sd">             model_config: the model configuration including the name of the target gym environment</span>

<span class="sd">                 as well as the neural network architecture.</span>

<span class="sd">     &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_config</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_implementation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">StepsTrainContext</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        train_env = self._create_env()</span>

<span class="sd">        assert isinstance(train_env,gym.spaces.Discrete), &quot;Only discrete actions environment are supported.&quot;</span>

<span class="sd">        action_space : gym.spaces.Discrete = train_env.action_space</span>

<span class="sd">        memory = EpisodeParameterMemory(limit=train_context.max_steps_in_buffer, window_length=1)</span>

<span class="sd">        cem = CEMAgent(model=model, nb_actions=action_space.n, memory=memory,</span>

<span class="sd">                       batch_size=train_context.num_steps_sampled_from_buffer,</span>

<span class="sd">                       nb_steps_warmup=train_context.num_steps_buffer_preload,</span>

<span class="sd">                       train_interval=50,</span>

<span class="sd">                       elite_frac=0.05)</span>

<span class="sd">        cem.compile()</span>

<span class="sd">        &quot;&quot;&quot;</span>

<span class="k">class</span> <span class="nc">KerasRlAgentFactory</span><span class="p">(</span><span class="n">bcore</span><span class="o">.</span><span class="n">BackendAgentFactory</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Backend for TfAgents.</span>

<span class="sd">        Serves as a factory to create algorithm specific wrappers for the keras-rl implementations.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">backend_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;kerasrl&#39;</span>

    <span class="n">tensorflow_v2_eager_compatible</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span>

    <span class="k">def</span> <span class="nf">get_algorithms</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Type</span><span class="p">,</span> <span class="n">Type</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">BackendAgent</span><span class="p">]]:</span>

        <span class="sd">&quot;&quot;&quot;Yields a mapping of EasyAgent types to the implementations provided by this backend.&quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="p">{</span>

            <span class="n">easyagents</span><span class="o">.</span><span class="n">agents</span><span class="o">.</span><span class="n">CemAgent</span><span class="p">:</span> <span class="n">KerasRlCemAgent</span><span class="p">,</span>

            <span class="n">easyagents</span><span class="o">.</span><span class="n">agents</span><span class="o">.</span><span class="n">DqnAgent</span><span class="p">:</span> <span class="n">KerasRlDqnAgent</span><span class="p">,</span>

            <span class="n">easyagents</span><span class="o">.</span><span class="n">agents</span><span class="o">.</span><span class="n">DoubleDqnAgent</span><span class="p">:</span> <span class="n">KerasRlDoubleDqnAgent</span><span class="p">,</span>

            <span class="n">easyagents</span><span class="o">.</span><span class="n">agents</span><span class="o">.</span><span class="n">DuelingDqnAgent</span><span class="p">:</span> <span class="n">KerasRlDuelingDqnAgent</span><span class="p">,</span>

        <span class="p">}</span>
</pre></div>


</details>
<h2 id="classes">Classes</h2>
<h3 id="cemkerasrlagent">CemKerasRlAgent</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">CemKerasRlAgent</span><span class="p">(</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span>
<span class="p">)</span>
</pre></div>


<p>creates a new agent based on the CEM algorithm using the keras-rl implementation.</p>
<p>https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.6579&amp;rep=rep1&amp;type=pdf</p>
<p>Args:
     model_config: the model configuration including the name of the target gym environment
         as well as the neural network architecture.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="n">CemKerasRlAgent</span>(<span class="n">KerasRlAgent</span>):

    <span class="s">&quot;&quot;&quot; creates a new agent based on the CEM algorithm using the keras-rl implementation.</span>

<span class="s">        https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.6579&amp;rep=rep1&amp;type=pdf</span>

<span class="s">         Args:</span>

<span class="s">             model_config: the model configuration including the name of the target gym environment</span>

<span class="s">                 as well as the neural network architecture.</span>

<span class="s">     &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">__init__</span>(<span class="k">self</span>, <span class="n">model_config:</span> <span class="n">core</span>.<span class="n">ModelConfig</span>):

        <span class="n">super</span>().<span class="n">__init__</span>(<span class="n">model_config</span>=<span class="n">model_config</span>)

    <span class="n">def</span> <span class="n">train_implementation</span>(<span class="k">self</span>, <span class="n">train_context:</span> <span class="n">core</span>.<span class="n">StepsTrainContext</span>):

        <span class="s">&quot;&quot;&quot;</span>

<span class="s">        train_env = self._create_env()</span>

<span class="s">        assert isinstance(train_env,gym.spaces.Discrete), &quot;</span><span class="n">Only</span> <span class="n">discrete</span> <span class="n">actions</span> <span class="n">environment</span> <span class="n">are</span> <span class="n">supported</span>.<span class="s">&quot;</span>

<span class="s">        action_space : gym.spaces.Discrete = train_env.action_space</span>

<span class="s">        memory = EpisodeParameterMemory(limit=train_context.max_steps_in_buffer, window_length=1)</span>

<span class="s">        cem = CEMAgent(model=model, nb_actions=action_space.n, memory=memory,</span>

<span class="s">                       batch_size=train_context.num_steps_sampled_from_buffer,</span>

<span class="s">                       nb_steps_warmup=train_context.num_steps_buffer_preload,</span>

<span class="s">                       train_interval=50,</span>

<span class="s">                       elite_frac=0.05)</span>

<span class="s">        cem.compile()</span>

<span class="s">        &quot;&quot;&quot;</span>
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro">Ancestors (in MRO)</h4>
<ul>
<li>easyagents.backends.kerasrl.KerasRlAgent</li>
<li>easyagents.backends.core.BackendAgent</li>
<li>easyagents.backends.core._BackendAgent</li>
<li>abc.ABC</li>
</ul>
<h4 id="methods">Methods</h4>
<h5 id="log">log</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span>
</pre></div>


<p>Logs msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">log</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">log_msg</span>: <span class="nv">str</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Logs msg.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_monitor_env</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="nv">log_msg</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_log</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span>, <span class="nv">log_msg</span><span class="o">=</span><span class="nv">log_msg</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="log_api">log_api</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log_api</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">api_target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Logs a call to api_target with additional log_msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">log_api</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">api_target</span>: <span class="nv">str</span>, <span class="nv">log_msg</span>: <span class="nv">Optional</span>[<span class="nv">str</span>] <span class="o">=</span> <span class="nv">None</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Logs a call to api_target with additional log_msg.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_monitor_env</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="nv">api_target</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">api_target</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">if</span> <span class="nv">log_msg</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_api_log</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span>, <span class="nv">api_target</span>, <span class="nv">log_msg</span><span class="o">=</span><span class="nv">log_msg</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_begin">on_play_episode_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Env</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the beginning of a new episode</p>
<p>Args:
    env: the gym environment used to play the episode.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">env</span>: <span class="nv">gym</span>.<span class="nv">core</span>.<span class="nv">Env</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by play_implementation at the beginning of a new episode</span>

        <span class="nv">Args</span>:

            <span class="nv">env</span>: <span class="nv">the</span> <span class="nv">gym</span> <span class="nv">environment</span> <span class="nv">used</span> <span class="nv">to</span> <span class="nv">play</span> <span class="nv">the</span> <span class="nv">episode</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">env</span>, <span class="s2">&quot;</span><span class="s">env not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">isinstance</span><span class="ss">(</span><span class="nv">env</span>, <span class="nv">gym</span>.<span class="nv">core</span>.<span class="nv">Env</span><span class="ss">)</span>, <span class="s2">&quot;</span><span class="s">env not an an instance of gym.Env.</span><span class="s2">&quot;</span>

        <span class="nv">pc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">play</span>

        <span class="nv">pc</span>.<span class="nv">gym_env</span> <span class="o">=</span> <span class="nv">env</span>

        <span class="nv">pc</span>.<span class="nv">steps_done_in_episode</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nv">pc</span>.<span class="nv">actions</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> []

        <span class="nv">pc</span>.<span class="nv">rewards</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> []

        <span class="nv">pc</span>.<span class="nv">sum_of_rewards</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_end">on_play_episode_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_end</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the end of an episode</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_play_episode_end</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by play_implementation at the end of an episode</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">pc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">play</span>

        <span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nv">pc</span>.<span class="nv">num_episodes</span> <span class="nv">and</span> <span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">&gt;=</span> <span class="nv">pc</span>.<span class="nv">num_episodes</span>:

            <span class="nv">pc</span>.<span class="nv">play_done</span> <span class="o">=</span> <span class="nv">True</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_play_episode_end</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_begin">on_train_iteration_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_begin</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the begining of a new iteration</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_train_iteration_begin</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by train_implementation at the begining of a new iteration</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">tc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">train</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nv">tc</span>.<span class="nv">steps_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">==</span> <span class="mi">0</span>:

            <span class="nv">self</span>.<span class="nv">_eval_current_policy</span><span class="ss">()</span>

        <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_totals</span>.<span class="nv">episodes_done</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_end">on_train_iteration_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the end of an iteration</p>
<p>Evaluates the current policy. Use kwargs to set additional dict values in train context.
Eg for an ActorCriticTrainContext the losses may be set like this:
    on_train_iteration(loss=123,actor_loss=456,critic_loss=789)</p>
<p>Args:
    loss: loss after the training of the model in this iteration or math.nan if the loss is not available
    **kwargs: if a keyword matches a dict property of the TrainContext instance, then
                the dict[episodes_done_in_training] is set to the arg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">loss</span>: <span class="nv">float</span>, <span class="o">**</span><span class="nv">kwargs</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by train_implementation at the end of an iteration</span>

        <span class="nv">Evaluates</span> <span class="nv">the</span> <span class="nv">current</span> <span class="nv">policy</span>. <span class="nv">Use</span> <span class="nv">kwargs</span> <span class="nv">to</span> <span class="nv">set</span> <span class="nv">additional</span> <span class="nv">dict</span> <span class="nv">values</span> <span class="nv">in</span> <span class="nv">train</span> <span class="nv">context</span>.

        <span class="nv">Eg</span> <span class="k">for</span> <span class="nv">an</span> <span class="nv">ActorCriticTrainContext</span> <span class="nv">the</span> <span class="nv">losses</span> <span class="nv">may</span> <span class="nv">be</span> <span class="nv">set</span> <span class="nv">like</span> <span class="nv">this</span>:

            <span class="nv">on_train_iteration</span><span class="ss">(</span><span class="nv">loss</span><span class="o">=</span><span class="mi">123</span>,<span class="nv">actor_loss</span><span class="o">=</span><span class="mi">456</span>,<span class="nv">critic_loss</span><span class="o">=</span><span class="mi">789</span><span class="ss">)</span>

        <span class="nv">Args</span>:

            <span class="nv">loss</span>: <span class="nv">loss</span> <span class="nv">after</span> <span class="nv">the</span> <span class="nv">training</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">model</span> <span class="nv">in</span> <span class="nv">this</span> <span class="nv">iteration</span> <span class="nv">or</span> <span class="nv">math</span>.<span class="nv">nan</span> <span class="k">if</span> <span class="nv">the</span> <span class="nv">loss</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">available</span>

            <span class="o">**</span><span class="nv">kwargs</span>: <span class="k">if</span> <span class="nv">a</span> <span class="nv">keyword</span> <span class="nv">matches</span> <span class="nv">a</span> <span class="nv">dict</span> <span class="nv">property</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">TrainContext</span> <span class="nv">instance</span>, <span class="k">then</span>

                        <span class="nv">the</span> <span class="nv">dict</span>[<span class="nv">episodes_done_in_training</span>] <span class="nv">is</span> <span class="nv">set</span> <span class="nv">to</span> <span class="nv">the</span> <span class="nv">arg</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">tc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">train</span>

        <span class="nv">totals</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_totals</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span> <span class="o">=</span> <span class="ss">(</span><span class="nv">totals</span>.<span class="nv">episodes_done</span> <span class="o">-</span> <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span><span class="ss">)</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span> <span class="o">+=</span> <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span>

        <span class="nv">tc</span>.<span class="nv">loss</span>[<span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span>] <span class="o">=</span> <span class="nv">loss</span>

        # <span class="nv">set</span> <span class="nv">traincontext</span> <span class="nv">dict</span> <span class="nv">from</span> <span class="nv">kwargs</span>:

        <span class="k">for</span> <span class="nv">prop_name</span> <span class="nv">in</span> <span class="nv">kwargs</span>:

            <span class="nv">prop_instance</span> <span class="o">=</span> <span class="nv">getattr</span><span class="ss">(</span><span class="nv">tc</span>, <span class="nv">prop_name</span>, <span class="nv">None</span><span class="ss">)</span>

            <span class="nv">prop_value</span> <span class="o">=</span> <span class="nv">kwargs</span>[<span class="nv">prop_name</span>]

            <span class="k">if</span> <span class="nv">prop_instance</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span> <span class="nv">and</span> <span class="nv">isinstance</span><span class="ss">(</span><span class="nv">prop_instance</span>, <span class="nv">dict</span><span class="ss">)</span>:

                <span class="nv">prop_instance</span>[<span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span>] <span class="o">=</span> <span class="nv">prop_value</span>

        <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">num_iterations</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span>:

            <span class="nv">tc</span>.<span class="nv">training_done</span> <span class="o">=</span> <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">&gt;=</span> <span class="nv">tc</span>.<span class="nv">num_iterations</span>

        <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">num_iterations_between_eval</span> <span class="nv">and</span> <span class="ss">(</span><span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">%</span> <span class="nv">tc</span>.<span class="nv">num_iterations_between_eval</span> <span class="o">==</span> <span class="mi">0</span><span class="ss">)</span>:

            <span class="nv">self</span>.<span class="nv">_eval_current_policy</span><span class="ss">()</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="play">play</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to play_implementation overriden by the subclass.</p>
<p>Args:
    play_context: play configuration to be used
    callbacks: list of callbacks called during play.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">play</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">play_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">PlayContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to play_implementation overriden by the subclass.</span>

<span class="ss">            Args:</span>

<span class="ss">                play_context: play configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during play.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">play_context</span><span class="p">,</span> <span class="ss">&quot;play_context not set&quot;</span>

        <span class="n">assert</span> <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="k">is</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;play_context already set in agent_context&quot;</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="n">play_context</span>

        <span class="n">old_callbacks</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">play_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">old_callbacks</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="play_implementation">play_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of playing a single episodes with the current policy.</p>
<p>Args:
    play_context: play configuration to be used</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">play_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">play_context</span>: <span class="nv">core</span>.<span class="nv">PlayContext</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Agent specific implementation of playing a single episodes with the current policy.</span>

            <span class="nv">Args</span>:

                <span class="nv">play_context</span>: <span class="nv">play</span> <span class="nv">configuration</span> <span class="nv">to</span> <span class="nv">be</span> <span class="nv">used</span>

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">play_context</span>, <span class="s2">&quot;</span><span class="s">play_context not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">self</span>.<span class="nv">_agent</span>, <span class="s2">&quot;</span><span class="s">_agent not set. call train() first.</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="k">while</span> <span class="nv">True</span>:

            <span class="nv">self</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">env</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_play_env</span><span class="ss">)</span>

            <span class="nv">observation</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">reset</span><span class="ss">()</span>

            <span class="nv">done</span> <span class="o">=</span> <span class="nv">False</span>

            <span class="k">while</span> <span class="nv">not</span> <span class="nv">done</span>:

                <span class="nv">action</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">forward</span><span class="ss">(</span><span class="nv">observation</span><span class="ss">)</span>

                <span class="nv">observation</span>, <span class="nv">reward</span>, <span class="nv">done</span>, <span class="nv">info</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">step</span><span class="ss">(</span><span class="nv">action</span><span class="ss">)</span>

            <span class="nv">self</span>.<span class="nv">on_play_episode_end</span><span class="ss">()</span>

            <span class="k">if</span> <span class="nv">play_context</span>.<span class="nv">play_done</span>:

                <span class="k">break</span>
</pre></div>


</details>
<h5 id="train">train</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to train_implementation overriden by the subclass</p>
<p>Args:
    train_context: training configuration to be used
    callbacks: list of callbacks called during the training and evaluation.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">train</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">TrainContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to train_implementation overriden by the subclass</span>

<span class="ss">            Args:</span>

<span class="ss">                train_context: training configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during the training and evaluation.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">train_context</span><span class="p">,</span> <span class="ss">&quot;train_context not set&quot;</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train_context</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="k">self</span><span class="p">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;backend_name&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;{self._backend_name}&#39;</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_set_seed</span><span class="p">()</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">train_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="train_implementation">train_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">StepsTrainContext</span>
<span class="p">)</span>
</pre></div>


<p>train_env = self._create_env()</p>
<p>assert isinstance(train_env,gym.spaces.Discrete), "Only discrete actions environment are supported."</p>
<p>action_space : gym.spaces.Discrete = train_env.action_space</p>
<p>memory = EpisodeParameterMemory(limit=train_context.max_steps_in_buffer, window_length=1)
cem = CEMAgent(model=model, nb_actions=action_space.n, memory=memory,
               batch_size=train_context.num_steps_sampled_from_buffer,
               nb_steps_warmup=train_context.num_steps_buffer_preload,
               train_interval=50,
               elite_frac=0.05)
cem.compile()</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">train_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">StepsTrainContext</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;</span>

<span class="ss">        train_env = self._create_env()</span>

<span class="ss">        assert isinstance(train_env,gym.spaces.Discrete), &quot;</span><span class="k">Only</span> <span class="n">discrete</span> <span class="n">actions</span> <span class="n">environment</span> <span class="k">are</span> <span class="n">supported</span><span class="p">.</span><span class="ss">&quot;</span>

<span class="ss">        action_space : gym.spaces.Discrete = train_env.action_space</span>

<span class="ss">        memory = EpisodeParameterMemory(limit=train_context.max_steps_in_buffer, window_length=1)</span>

<span class="ss">        cem = CEMAgent(model=model, nb_actions=action_space.n, memory=memory,</span>

<span class="ss">                       batch_size=train_context.num_steps_sampled_from_buffer,</span>

<span class="ss">                       nb_steps_warmup=train_context.num_steps_buffer_preload,</span>

<span class="ss">                       train_interval=50,</span>

<span class="ss">                       elite_frac=0.05)</span>

<span class="ss">        cem.compile()</span>

<span class="ss">        &quot;&quot;&quot;</span>
</pre></div>


</details>
<h3 id="kerasrlagent">KerasRlAgent</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">KerasRlAgent</span><span class="p">(</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span>
<span class="p">)</span>
</pre></div>


<p>Reinforcement learning agents based on keras-rl originally developed by matthias plappert</p>
<p>https://github.com/keras-rl/keras-rl</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="nv">class</span> <span class="nv">KerasRlAgent</span><span class="ss">(</span><span class="nv">bcore</span>.<span class="nv">BackendAgent</span>, <span class="nv">metaclass</span><span class="o">=</span><span class="nv">ABCMeta</span><span class="ss">)</span>:

    <span class="s2">&quot;&quot;&quot;</span><span class="s">Reinforcement learning agents based on keras-rl originally developed by matthias plappert</span>

        <span class="nv">https</span>:<span class="o">//</span><span class="nv">github</span>.<span class="nv">com</span><span class="o">/</span><span class="nv">keras</span><span class="o">-</span><span class="nv">rl</span><span class="o">/</span><span class="nv">keras</span><span class="o">-</span><span class="nv">rl</span>

    <span class="s2">&quot;&quot;&quot;</span>

    <span class="nv">def</span> <span class="nv">__init__</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">model_config</span>: <span class="nv">core</span>.<span class="nv">ModelConfig</span><span class="ss">)</span>:

        <span class="nv">super</span><span class="ss">()</span>.<span class="nv">__init__</span><span class="ss">(</span><span class="nv">model_config</span><span class="o">=</span><span class="nv">model_config</span>,

                         <span class="nv">backend_name</span><span class="o">=</span><span class="nv">KerasRlAgentFactory</span>.<span class="nv">backend_name</span>,

                         <span class="nv">tensorflow_v2_eager</span><span class="o">=</span><span class="nv">False</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>: <span class="nv">Optional</span>[<span class="nv">rl</span>.<span class="nv">core</span>.<span class="nv">Agent</span>] <span class="o">=</span> <span class="nv">None</span>

        <span class="nv">self</span>.<span class="nv">_play_env</span>: <span class="nv">Optional</span>[<span class="nv">gym</span>.<span class="nv">Env</span>] <span class="o">=</span> <span class="nv">None</span>

    <span class="nv">def</span> <span class="nv">_create_env</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span> <span class="o">-&gt;</span> <span class="nv">gym</span>.<span class="nv">Env</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Creates a new gym instance.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">gym.make</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(&quot;{self.model_config.original_env_name}&quot;)</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nb">result</span> <span class="o">=</span> <span class="nv">gym</span>.<span class="nv">make</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">model_config</span>.<span class="nv">gym_env_name</span><span class="ss">)</span>

        <span class="k">return</span> <span class="nb">result</span>

    <span class="nv">def</span> <span class="nv">_create_model</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">gym_env</span>: <span class="nv">gym</span>.<span class="nv">Env</span>, <span class="nv">activation</span>: <span class="nv">str</span><span class="ss">)</span> <span class="o">-&gt;</span> <span class="nv">Sequential</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Creates a model consisting of  fully connected layers as given by self.model_config.fc_layers</span>

        <span class="nv">with</span> <span class="nv">relu</span> <span class="nv">as</span> <span class="nv">activation</span> <span class="nv">function</span>.

        <span class="nv">Args</span>:

            <span class="nv">gym_env</span>: <span class="nv">gym_env</span> <span class="nv">whose</span> <span class="nv">observation</span> <span class="nv">shape</span> <span class="nv">ofdefines</span> <span class="nv">the</span> <span class="nv">size</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">input</span> <span class="nv">layer</span> <span class="nv">and</span>

                <span class="nv">whose</span> <span class="nv">action_space</span> <span class="nv">defines</span> <span class="nv">the</span> <span class="nv">size</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">output</span> <span class="nv">layer</span>.

            <span class="nv">activation</span>: <span class="nv">output</span> <span class="nv">activation</span> <span class="nv">function</span> <span class="nv">eg</span> <span class="s1">&#39;</span><span class="s">linear</span><span class="s1">&#39;</span> <span class="nv">or</span> <span class="s1">&#39;</span><span class="s">softmax</span><span class="s1">&#39;</span>

        <span class="nv">Returns</span>:

            <span class="nv">Keras</span> <span class="nv">Sequential</span> <span class="nv">model</span> <span class="nv">according</span> <span class="nv">to</span> <span class="nv">model_config</span>.<span class="nv">fc_layers</span>

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">gym_env</span>

        <span class="nv">num_actions</span> <span class="o">=</span> <span class="nv">gym_env</span>.<span class="nv">action_space</span>.<span class="nv">n</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">Sequential</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">()</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nb">result</span> <span class="o">=</span> <span class="nv">Sequential</span><span class="ss">()</span>

        <span class="nv">input_shape</span> <span class="o">=</span> <span class="ss">(</span><span class="mi">1</span>,<span class="ss">)</span> <span class="o">+</span> <span class="nv">gym_env</span>.<span class="nv">observation_space</span>.<span class="nv">shape</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">model.add</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(Flatten(input_shape={input_shape}))</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nb">result</span>.<span class="nv">add</span><span class="ss">(</span><span class="nv">Flatten</span><span class="ss">(</span><span class="nv">input_shape</span><span class="o">=</span><span class="nv">input_shape</span><span class="ss">))</span>

        <span class="k">for</span> <span class="nv">layer_size</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">model_config</span>.<span class="nv">fc_layers</span>:

            <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">model.add</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(Dense({layer_size}))</span><span class="s1">&#39;</span><span class="ss">)</span>

            <span class="nb">result</span>.<span class="nv">add</span><span class="ss">(</span><span class="nv">Dense</span><span class="ss">(</span><span class="nv">layer_size</span><span class="ss">))</span>

            <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">model.add</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(Activation(&quot;relu&quot;))</span><span class="s1">&#39;</span><span class="ss">)</span>

            <span class="nb">result</span>.<span class="nv">add</span><span class="ss">(</span><span class="nv">Activation</span><span class="ss">(</span><span class="s1">&#39;</span><span class="s">relu</span><span class="s1">&#39;</span><span class="ss">))</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">model.add</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(Dense({num_actions}))</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nb">result</span>.<span class="nv">add</span><span class="ss">(</span><span class="nv">Dense</span><span class="ss">(</span><span class="nv">num_actions</span><span class="ss">))</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">model.add</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(Activation(&quot;{activation}&quot;))</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nb">result</span>.<span class="nv">add</span><span class="ss">(</span><span class="nv">Activation</span><span class="ss">(</span><span class="nv">activation</span><span class="ss">))</span>

        <span class="k">return</span> <span class="nb">result</span>

    <span class="nv">def</span> <span class="nv">play_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">play_context</span>: <span class="nv">core</span>.<span class="nv">PlayContext</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Agent specific implementation of playing a single episodes with the current policy.</span>

            <span class="nv">Args</span>:

                <span class="nv">play_context</span>: <span class="nv">play</span> <span class="nv">configuration</span> <span class="nv">to</span> <span class="nv">be</span> <span class="nv">used</span>

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">play_context</span>, <span class="s2">&quot;</span><span class="s">play_context not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">self</span>.<span class="nv">_agent</span>, <span class="s2">&quot;</span><span class="s">_agent not set. call train() first.</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="k">while</span> <span class="nv">True</span>:

            <span class="nv">self</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">env</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_play_env</span><span class="ss">)</span>

            <span class="nv">observation</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">reset</span><span class="ss">()</span>

            <span class="nv">done</span> <span class="o">=</span> <span class="nv">False</span>

            <span class="k">while</span> <span class="nv">not</span> <span class="nv">done</span>:

                <span class="nv">action</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">forward</span><span class="ss">(</span><span class="nv">observation</span><span class="ss">)</span>

                <span class="nv">observation</span>, <span class="nv">reward</span>, <span class="nv">done</span>, <span class="nv">info</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">step</span><span class="ss">(</span><span class="nv">action</span><span class="ss">)</span>

            <span class="nv">self</span>.<span class="nv">on_play_episode_end</span><span class="ss">()</span>

            <span class="k">if</span> <span class="nv">play_context</span>.<span class="nv">play_done</span>:

                <span class="k">break</span>
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro_1">Ancestors (in MRO)</h4>
<ul>
<li>easyagents.backends.core.BackendAgent</li>
<li>easyagents.backends.core._BackendAgent</li>
<li>abc.ABC</li>
</ul>
<h4 id="descendants">Descendants</h4>
<ul>
<li>easyagents.backends.kerasrl.KerasRlCemAgent</li>
<li>easyagents.backends.kerasrl.KerasRlDqnAgent</li>
<li>easyagents.backends.kerasrl.CemKerasRlAgent</li>
</ul>
<h4 id="methods_1">Methods</h4>
<h5 id="log_1">log</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span>
</pre></div>


<p>Logs msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">log</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">log_msg</span>: <span class="nv">str</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Logs msg.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_monitor_env</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="nv">log_msg</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_log</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span>, <span class="nv">log_msg</span><span class="o">=</span><span class="nv">log_msg</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="log_api_1">log_api</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log_api</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">api_target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Logs a call to api_target with additional log_msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">log_api</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">api_target</span>: <span class="nv">str</span>, <span class="nv">log_msg</span>: <span class="nv">Optional</span>[<span class="nv">str</span>] <span class="o">=</span> <span class="nv">None</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Logs a call to api_target with additional log_msg.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_monitor_env</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="nv">api_target</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">api_target</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">if</span> <span class="nv">log_msg</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_api_log</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span>, <span class="nv">api_target</span>, <span class="nv">log_msg</span><span class="o">=</span><span class="nv">log_msg</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_begin_1">on_play_episode_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Env</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the beginning of a new episode</p>
<p>Args:
    env: the gym environment used to play the episode.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">env</span>: <span class="nv">gym</span>.<span class="nv">core</span>.<span class="nv">Env</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by play_implementation at the beginning of a new episode</span>

        <span class="nv">Args</span>:

            <span class="nv">env</span>: <span class="nv">the</span> <span class="nv">gym</span> <span class="nv">environment</span> <span class="nv">used</span> <span class="nv">to</span> <span class="nv">play</span> <span class="nv">the</span> <span class="nv">episode</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">env</span>, <span class="s2">&quot;</span><span class="s">env not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">isinstance</span><span class="ss">(</span><span class="nv">env</span>, <span class="nv">gym</span>.<span class="nv">core</span>.<span class="nv">Env</span><span class="ss">)</span>, <span class="s2">&quot;</span><span class="s">env not an an instance of gym.Env.</span><span class="s2">&quot;</span>

        <span class="nv">pc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">play</span>

        <span class="nv">pc</span>.<span class="nv">gym_env</span> <span class="o">=</span> <span class="nv">env</span>

        <span class="nv">pc</span>.<span class="nv">steps_done_in_episode</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nv">pc</span>.<span class="nv">actions</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> []

        <span class="nv">pc</span>.<span class="nv">rewards</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> []

        <span class="nv">pc</span>.<span class="nv">sum_of_rewards</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_end_1">on_play_episode_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_end</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the end of an episode</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_play_episode_end</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by play_implementation at the end of an episode</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">pc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">play</span>

        <span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nv">pc</span>.<span class="nv">num_episodes</span> <span class="nv">and</span> <span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">&gt;=</span> <span class="nv">pc</span>.<span class="nv">num_episodes</span>:

            <span class="nv">pc</span>.<span class="nv">play_done</span> <span class="o">=</span> <span class="nv">True</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_play_episode_end</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_begin_1">on_train_iteration_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_begin</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the begining of a new iteration</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_train_iteration_begin</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by train_implementation at the begining of a new iteration</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">tc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">train</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nv">tc</span>.<span class="nv">steps_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">==</span> <span class="mi">0</span>:

            <span class="nv">self</span>.<span class="nv">_eval_current_policy</span><span class="ss">()</span>

        <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_totals</span>.<span class="nv">episodes_done</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_end_1">on_train_iteration_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the end of an iteration</p>
<p>Evaluates the current policy. Use kwargs to set additional dict values in train context.
Eg for an ActorCriticTrainContext the losses may be set like this:
    on_train_iteration(loss=123,actor_loss=456,critic_loss=789)</p>
<p>Args:
    loss: loss after the training of the model in this iteration or math.nan if the loss is not available
    **kwargs: if a keyword matches a dict property of the TrainContext instance, then
                the dict[episodes_done_in_training] is set to the arg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">loss</span>: <span class="nv">float</span>, <span class="o">**</span><span class="nv">kwargs</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by train_implementation at the end of an iteration</span>

        <span class="nv">Evaluates</span> <span class="nv">the</span> <span class="nv">current</span> <span class="nv">policy</span>. <span class="nv">Use</span> <span class="nv">kwargs</span> <span class="nv">to</span> <span class="nv">set</span> <span class="nv">additional</span> <span class="nv">dict</span> <span class="nv">values</span> <span class="nv">in</span> <span class="nv">train</span> <span class="nv">context</span>.

        <span class="nv">Eg</span> <span class="k">for</span> <span class="nv">an</span> <span class="nv">ActorCriticTrainContext</span> <span class="nv">the</span> <span class="nv">losses</span> <span class="nv">may</span> <span class="nv">be</span> <span class="nv">set</span> <span class="nv">like</span> <span class="nv">this</span>:

            <span class="nv">on_train_iteration</span><span class="ss">(</span><span class="nv">loss</span><span class="o">=</span><span class="mi">123</span>,<span class="nv">actor_loss</span><span class="o">=</span><span class="mi">456</span>,<span class="nv">critic_loss</span><span class="o">=</span><span class="mi">789</span><span class="ss">)</span>

        <span class="nv">Args</span>:

            <span class="nv">loss</span>: <span class="nv">loss</span> <span class="nv">after</span> <span class="nv">the</span> <span class="nv">training</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">model</span> <span class="nv">in</span> <span class="nv">this</span> <span class="nv">iteration</span> <span class="nv">or</span> <span class="nv">math</span>.<span class="nv">nan</span> <span class="k">if</span> <span class="nv">the</span> <span class="nv">loss</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">available</span>

            <span class="o">**</span><span class="nv">kwargs</span>: <span class="k">if</span> <span class="nv">a</span> <span class="nv">keyword</span> <span class="nv">matches</span> <span class="nv">a</span> <span class="nv">dict</span> <span class="nv">property</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">TrainContext</span> <span class="nv">instance</span>, <span class="k">then</span>

                        <span class="nv">the</span> <span class="nv">dict</span>[<span class="nv">episodes_done_in_training</span>] <span class="nv">is</span> <span class="nv">set</span> <span class="nv">to</span> <span class="nv">the</span> <span class="nv">arg</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">tc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">train</span>

        <span class="nv">totals</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_totals</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span> <span class="o">=</span> <span class="ss">(</span><span class="nv">totals</span>.<span class="nv">episodes_done</span> <span class="o">-</span> <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span><span class="ss">)</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span> <span class="o">+=</span> <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span>

        <span class="nv">tc</span>.<span class="nv">loss</span>[<span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span>] <span class="o">=</span> <span class="nv">loss</span>

        # <span class="nv">set</span> <span class="nv">traincontext</span> <span class="nv">dict</span> <span class="nv">from</span> <span class="nv">kwargs</span>:

        <span class="k">for</span> <span class="nv">prop_name</span> <span class="nv">in</span> <span class="nv">kwargs</span>:

            <span class="nv">prop_instance</span> <span class="o">=</span> <span class="nv">getattr</span><span class="ss">(</span><span class="nv">tc</span>, <span class="nv">prop_name</span>, <span class="nv">None</span><span class="ss">)</span>

            <span class="nv">prop_value</span> <span class="o">=</span> <span class="nv">kwargs</span>[<span class="nv">prop_name</span>]

            <span class="k">if</span> <span class="nv">prop_instance</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span> <span class="nv">and</span> <span class="nv">isinstance</span><span class="ss">(</span><span class="nv">prop_instance</span>, <span class="nv">dict</span><span class="ss">)</span>:

                <span class="nv">prop_instance</span>[<span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span>] <span class="o">=</span> <span class="nv">prop_value</span>

        <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">num_iterations</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span>:

            <span class="nv">tc</span>.<span class="nv">training_done</span> <span class="o">=</span> <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">&gt;=</span> <span class="nv">tc</span>.<span class="nv">num_iterations</span>

        <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">num_iterations_between_eval</span> <span class="nv">and</span> <span class="ss">(</span><span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">%</span> <span class="nv">tc</span>.<span class="nv">num_iterations_between_eval</span> <span class="o">==</span> <span class="mi">0</span><span class="ss">)</span>:

            <span class="nv">self</span>.<span class="nv">_eval_current_policy</span><span class="ss">()</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="play_1">play</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to play_implementation overriden by the subclass.</p>
<p>Args:
    play_context: play configuration to be used
    callbacks: list of callbacks called during play.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">play</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">play_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">PlayContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to play_implementation overriden by the subclass.</span>

<span class="ss">            Args:</span>

<span class="ss">                play_context: play configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during play.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">play_context</span><span class="p">,</span> <span class="ss">&quot;play_context not set&quot;</span>

        <span class="n">assert</span> <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="k">is</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;play_context already set in agent_context&quot;</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="n">play_context</span>

        <span class="n">old_callbacks</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">play_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">old_callbacks</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="play_implementation_1">play_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of playing a single episodes with the current policy.</p>
<p>Args:
    play_context: play configuration to be used</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">play_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">play_context</span>: <span class="nv">core</span>.<span class="nv">PlayContext</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Agent specific implementation of playing a single episodes with the current policy.</span>

            <span class="nv">Args</span>:

                <span class="nv">play_context</span>: <span class="nv">play</span> <span class="nv">configuration</span> <span class="nv">to</span> <span class="nv">be</span> <span class="nv">used</span>

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">play_context</span>, <span class="s2">&quot;</span><span class="s">play_context not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">self</span>.<span class="nv">_agent</span>, <span class="s2">&quot;</span><span class="s">_agent not set. call train() first.</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="k">while</span> <span class="nv">True</span>:

            <span class="nv">self</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">env</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_play_env</span><span class="ss">)</span>

            <span class="nv">observation</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">reset</span><span class="ss">()</span>

            <span class="nv">done</span> <span class="o">=</span> <span class="nv">False</span>

            <span class="k">while</span> <span class="nv">not</span> <span class="nv">done</span>:

                <span class="nv">action</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">forward</span><span class="ss">(</span><span class="nv">observation</span><span class="ss">)</span>

                <span class="nv">observation</span>, <span class="nv">reward</span>, <span class="nv">done</span>, <span class="nv">info</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">step</span><span class="ss">(</span><span class="nv">action</span><span class="ss">)</span>

            <span class="nv">self</span>.<span class="nv">on_play_episode_end</span><span class="ss">()</span>

            <span class="k">if</span> <span class="nv">play_context</span>.<span class="nv">play_done</span>:

                <span class="k">break</span>
</pre></div>


</details>
<h5 id="train_1">train</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to train_implementation overriden by the subclass</p>
<p>Args:
    train_context: training configuration to be used
    callbacks: list of callbacks called during the training and evaluation.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">train</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">TrainContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to train_implementation overriden by the subclass</span>

<span class="ss">            Args:</span>

<span class="ss">                train_context: training configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during the training and evaluation.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">train_context</span><span class="p">,</span> <span class="ss">&quot;train_context not set&quot;</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train_context</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="k">self</span><span class="p">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;backend_name&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;{self._backend_name}&#39;</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_set_seed</span><span class="p">()</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">train_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="train_implementation_1">train_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of the train loop.</p>
<p>The implementation should have the form:</p>
<p>while True:
    on_iteration_begin
    for e in num_episodes_per_iterations
        play episode and record steps (while steps_in_episode &lt; max_steps_per_episode and)
    train policy for num_epochs_per_iteration epochs
    on_iteration_end( loss )
    if training_done
        break</p>
<p>Args:
    train_context: context configuring the train loop</p>
<p>Hints:
o the subclasses training loss is passed through to BackendAgent by on_iteration_end.
  Thus the subclass must not add the experienced loss to the TrainContext.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    @<span class="nv">abstractmethod</span>

    <span class="nv">def</span> <span class="nv">train_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">train_context</span>: <span class="nv">core</span>.<span class="nv">TrainContext</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Agent specific implementation of the train loop.</span>

            <span class="nv">The</span> <span class="nv">implementation</span> <span class="nv">should</span> <span class="nv">have</span> <span class="nv">the</span> <span class="nv">form</span>:

            <span class="k">while</span> <span class="nv">True</span>:

                <span class="nv">on_iteration_begin</span>

                <span class="k">for</span> <span class="nv">e</span> <span class="nv">in</span> <span class="nv">num_episodes_per_iterations</span>

                    <span class="nv">play</span> <span class="nv">episode</span> <span class="nv">and</span> <span class="nv">record</span> <span class="nv">steps</span> <span class="ss">(</span><span class="k">while</span> <span class="nv">steps_in_episode</span> <span class="o">&lt;</span> <span class="nv">max_steps_per_episode</span> <span class="nv">and</span><span class="ss">)</span>

                <span class="nv">train</span> <span class="nv">policy</span> <span class="k">for</span> <span class="nv">num_epochs_per_iteration</span> <span class="nv">epochs</span>

                <span class="nv">on_iteration_end</span><span class="ss">(</span> <span class="nv">loss</span> <span class="ss">)</span>

                <span class="k">if</span> <span class="nv">training_done</span>

                    <span class="k">break</span>

            <span class="nv">Args</span>:

                <span class="nv">train_context</span>: <span class="nv">context</span> <span class="nv">configuring</span> <span class="nv">the</span> <span class="nv">train</span> <span class="k">loop</span>

            <span class="nv">Hints</span>:

            <span class="nv">o</span> <span class="nv">the</span> <span class="nv">subclasses</span> <span class="nv">training</span> <span class="nv">loss</span> <span class="nv">is</span> <span class="nv">passed</span> <span class="nv">through</span> <span class="nv">to</span> <span class="nv">BackendAgent</span> <span class="nv">by</span> <span class="nv">on_iteration_end</span>.

              <span class="nv">Thus</span> <span class="nv">the</span> <span class="nv">subclass</span> <span class="nv">must</span> <span class="nv">not</span> <span class="nv">add</span> <span class="nv">the</span> <span class="nv">experienced</span> <span class="nv">loss</span> <span class="nv">to</span> <span class="nv">the</span> <span class="nv">TrainContext</span>.

        <span class="s2">&quot;&quot;&quot;</span>
</pre></div>


</details>
<h3 id="kerasrlagentfactory">KerasRlAgentFactory</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">KerasRlAgentFactory</span><span class="p">(</span>
    <span class="o">/</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Backend for TfAgents.</p>
<p>Serves as a factory to create algorithm specific wrappers for the keras-rl implementations.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="nv">class</span> <span class="nv">KerasRlAgentFactory</span><span class="ss">(</span><span class="nv">bcore</span>.<span class="nv">BackendAgentFactory</span><span class="ss">)</span>:

    <span class="s2">&quot;&quot;&quot;</span><span class="s">Backend for TfAgents.</span>

        <span class="nv">Serves</span> <span class="nv">as</span> <span class="nv">a</span> <span class="nv">factory</span> <span class="nv">to</span> <span class="nv">create</span> <span class="nv">algorithm</span> <span class="nv">specific</span> <span class="nv">wrappers</span> <span class="k">for</span> <span class="nv">the</span> <span class="nv">keras</span><span class="o">-</span><span class="nv">rl</span> <span class="nv">implementations</span>.

    <span class="s2">&quot;&quot;&quot;</span>

    <span class="nv">backend_name</span>: <span class="nv">str</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="s">kerasrl</span><span class="s1">&#39;</span>

    <span class="nv">tensorflow_v2_eager_compatible</span>: <span class="nv">bool</span> <span class="o">=</span> <span class="nv">False</span>

    <span class="nv">def</span> <span class="nv">get_algorithms</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span> <span class="o">-&gt;</span> <span class="nv">Dict</span>[<span class="nv">Type</span>, <span class="nv">Type</span>[<span class="nv">easyagents</span>.<span class="nv">backends</span>.<span class="nv">core</span>.<span class="nv">BackendAgent</span>]]:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Yields a mapping of EasyAgent types to the implementations provided by this backend.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="k">return</span> {

            <span class="nv">easyagents</span>.<span class="nv">agents</span>.<span class="nv">CemAgent</span>: <span class="nv">KerasRlCemAgent</span>,

            <span class="nv">easyagents</span>.<span class="nv">agents</span>.<span class="nv">DqnAgent</span>: <span class="nv">KerasRlDqnAgent</span>,

            <span class="nv">easyagents</span>.<span class="nv">agents</span>.<span class="nv">DoubleDqnAgent</span>: <span class="nv">KerasRlDoubleDqnAgent</span>,

            <span class="nv">easyagents</span>.<span class="nv">agents</span>.<span class="nv">DuelingDqnAgent</span>: <span class="nv">KerasRlDuelingDqnAgent</span>,

        }
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro_2">Ancestors (in MRO)</h4>
<ul>
<li>easyagents.backends.core.BackendAgentFactory</li>
<li>abc.ABC</li>
</ul>
<h4 id="class-variables">Class variables</h4>
<div class="codehilite"><pre><span></span><span class="n">backend_name</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">tensorflow_v2_eager_compatible</span>
</pre></div>


<h4 id="methods_2">Methods</h4>
<h5 id="create_agent">create_agent</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">create_agent</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">easyagent_type</span><span class="p">:</span> <span class="n">Type</span><span class="p">,</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">_BackendAgent</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span>
</pre></div>


<p>Creates a backend agent instance implementing the algorithm given by agent_type.</p>
<p>Args:
    easyagent_type: the EasyAgent derived type for which an implementing backend instance will be created
    model_config: the model_config passed to the constructor of the backend instance.</p>
<p>Returns:
    instance of the agent or None if not implemented by this backend.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">create_agent</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">easyagent_type</span>: <span class="nv">Type</span>, <span class="nv">model_config</span>: <span class="nv">core</span>.<span class="nv">ModelConfig</span><span class="ss">)</span> \

            <span class="o">-&gt;</span> <span class="nv">Optional</span>[<span class="nv">_BackendAgent</span>]:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Creates a backend agent instance implementing the algorithm given by agent_type.</span>

        <span class="nv">Args</span>:

            <span class="nv">easyagent_type</span>: <span class="nv">the</span> <span class="nv">EasyAgent</span> <span class="nv">derived</span> <span class="nv">type</span> <span class="k">for</span> <span class="nv">which</span> <span class="nv">an</span> <span class="nv">implementing</span> <span class="nv">backend</span> <span class="nv">instance</span> <span class="nv">will</span> <span class="nv">be</span> <span class="nv">created</span>

            <span class="nv">model_config</span>: <span class="nv">the</span> <span class="nv">model_config</span> <span class="nv">passed</span> <span class="nv">to</span> <span class="nv">the</span> <span class="nv">constructor</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">backend</span> <span class="nv">instance</span>.

        <span class="nv">Returns</span>:

            <span class="nv">instance</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">agent</span> <span class="nv">or</span> <span class="nv">None</span> <span class="k">if</span> <span class="nv">not</span> <span class="nv">implemented</span> <span class="nv">by</span> <span class="nv">this</span> <span class="nv">backend</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nb">result</span>: <span class="nv">Optional</span>[<span class="nv">_BackendAgent</span>] <span class="o">=</span> <span class="nv">None</span>

        <span class="nv">algorithms</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">get_algorithms</span><span class="ss">()</span>

        <span class="k">if</span> <span class="nv">easyagent_type</span> <span class="nv">in</span> <span class="nv">algorithms</span>:

            <span class="nb">result</span> <span class="o">=</span> <span class="nv">algorithms</span>[<span class="nv">easyagent_type</span>]<span class="ss">(</span><span class="nv">model_config</span><span class="o">=</span><span class="nv">model_config</span><span class="ss">)</span>

        <span class="k">return</span> <span class="nb">result</span>
</pre></div>


</details>
<h5 id="get_algorithms">get_algorithms</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_algorithms</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Type</span><span class="p">,</span> <span class="n">Type</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">BackendAgent</span><span class="p">]]</span>
</pre></div>


<p>Yields a mapping of EasyAgent types to the implementations provided by this backend.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">get_algorithms</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span> <span class="o">-&gt;</span> <span class="nv">Dict</span>[<span class="nv">Type</span>, <span class="nv">Type</span>[<span class="nv">easyagents</span>.<span class="nv">backends</span>.<span class="nv">core</span>.<span class="nv">BackendAgent</span>]]:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Yields a mapping of EasyAgent types to the implementations provided by this backend.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="k">return</span> {

            <span class="nv">easyagents</span>.<span class="nv">agents</span>.<span class="nv">CemAgent</span>: <span class="nv">KerasRlCemAgent</span>,

            <span class="nv">easyagents</span>.<span class="nv">agents</span>.<span class="nv">DqnAgent</span>: <span class="nv">KerasRlDqnAgent</span>,

            <span class="nv">easyagents</span>.<span class="nv">agents</span>.<span class="nv">DoubleDqnAgent</span>: <span class="nv">KerasRlDoubleDqnAgent</span>,

            <span class="nv">easyagents</span>.<span class="nv">agents</span>.<span class="nv">DuelingDqnAgent</span>: <span class="nv">KerasRlDuelingDqnAgent</span>,

        }
</pre></div>


</details>
<h3 id="kerasrlcemagent">KerasRlCemAgent</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">KerasRlCemAgent</span><span class="p">(</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span>
<span class="p">)</span>
</pre></div>


<p>Keras-rl implementation of the cross-entropy method algorithm.</p>
<p>see "https://learning.mpi-sws.org/mlss2016/slides/2016-MLSS-RL.pdf" and
    "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.6579&amp;rep=rep1&amp;type=pdf"</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="nv">class</span> <span class="nv">KerasRlCemAgent</span><span class="ss">(</span><span class="nv">KerasRlAgent</span><span class="ss">)</span>:

    <span class="s2">&quot;&quot;&quot;</span><span class="s">Keras-rl implementation of the cross-entropy method algorithm.</span>

        <span class="nv">see</span> <span class="s2">&quot;</span><span class="s">https://learning.mpi-sws.org/mlss2016/slides/2016-MLSS-RL.pdf</span><span class="s2">&quot;</span> <span class="nv">and</span>

            <span class="s2">&quot;</span><span class="s">https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.6579&amp;rep=rep1&amp;type=pdf</span><span class="s2">&quot;</span>

    <span class="s2">&quot;&quot;&quot;</span>

    <span class="nv">class</span> <span class="nv">CemCallback</span><span class="ss">(</span><span class="nv">rl</span>.<span class="nv">callbacks</span>.<span class="nv">Callback</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Callback registered with keras rl agents to propagate iteration and episode updates.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">def</span> <span class="nv">__init__</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">cem_agent</span>: <span class="nv">KerasRlAgent</span>, <span class="nv">cem_context</span>: <span class="nv">core</span>.<span class="nv">CemTrainContext</span>, <span class="nv">nb_steps</span>: <span class="nv">int</span><span class="ss">)</span>:

            <span class="s2">&quot;&quot;&quot;</span>

            <span class="nv">Args</span>:

                <span class="nv">cem_agent</span>: <span class="nv">the</span> <span class="nv">agent</span> <span class="nv">to</span> <span class="nv">propagate</span> <span class="nv">iteration</span> <span class="nv">begn</span><span class="o">/</span><span class="k">end</span> <span class="nv">events</span> <span class="nv">to</span>.

                <span class="nv">cem_context</span>: <span class="nv">the</span> <span class="nv">train_context</span> <span class="nv">containing</span> <span class="nv">the</span> <span class="nv">iteration</span> <span class="nv">definitions</span>

                <span class="nv">nb_steps</span>: <span class="nv">value</span> <span class="nv">set</span> <span class="nv">in</span> <span class="nv">the</span> <span class="nv">keras</span> <span class="nv">cem</span> <span class="nv">agent</span>.

            <span class="s2">&quot;&quot;&quot;</span>

            <span class="nv">assert</span> <span class="nv">cem_agent</span>

            <span class="nv">assert</span> <span class="nv">cem_context</span>

            <span class="nv">assert</span> <span class="nv">nb_steps</span>

            <span class="nv">self</span>.<span class="nv">_cem_agent</span>: <span class="nv">KerasRlAgent</span> <span class="o">=</span> <span class="nv">cem_agent</span>

            <span class="nv">self</span>.<span class="nv">_cem_context</span>: <span class="nv">core</span>.<span class="nv">CemTrainContext</span> <span class="o">=</span> <span class="nv">cem_context</span>

            <span class="nv">self</span>.<span class="nv">_nb_steps</span> <span class="o">=</span> <span class="nv">nb_steps</span>

            <span class="nv">super</span><span class="ss">()</span>.<span class="nv">__init__</span><span class="ss">()</span>

        <span class="nv">def</span> <span class="nv">on_episode_end</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">episode</span>, <span class="nv">logs</span><span class="o">=</span><span class="nv">None</span><span class="ss">)</span>:

            <span class="s2">&quot;&quot;&quot;</span><span class="s">Signals the base class the end / begin of a training iteration.</span><span class="s2">&quot;&quot;&quot;</span>

            <span class="nv">cc</span>: <span class="nv">core</span>.<span class="nv">CemTrainContext</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_cem_context</span>

            <span class="nv">episode</span> <span class="o">=</span> <span class="nv">episode</span> <span class="o">+</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="nv">episode</span> <span class="o">%</span> <span class="nv">cc</span>.<span class="nv">num_episodes_per_iteration</span> <span class="o">==</span> <span class="mi">0</span>:

                <span class="nv">self</span>.<span class="nv">_cem_agent</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">math</span>.<span class="nv">nan</span><span class="ss">)</span>

                <span class="k">if</span> <span class="nv">self</span>.<span class="nv">_cem_context</span>.<span class="nv">training_done</span>:

                    <span class="nv">self</span>.<span class="nv">_cem_agent</span>.<span class="nv">_agent</span>.<span class="nv">step</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_nb_steps</span>

                <span class="k">else</span>:

                    <span class="nv">self</span>.<span class="nv">_cem_agent</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">()</span>

    <span class="nv">def</span> <span class="nv">train_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">train_context</span>: <span class="nv">core</span>.<span class="nv">CemTrainContext</span><span class="ss">)</span>:

        <span class="nv">assert</span> <span class="nv">train_context</span>

        <span class="nv">cc</span>: <span class="nv">core</span>.<span class="nv">CemTrainContext</span> <span class="o">=</span> <span class="nv">train_context</span>

        <span class="nv">train_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="nv">keras_model</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_model</span><span class="ss">(</span><span class="nv">gym_env</span><span class="o">=</span><span class="nv">train_env</span>, <span class="nv">activation</span><span class="o">=</span><span class="s1">&#39;</span><span class="s">softmax</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">policy_buffer_size</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="nv">cc</span>.<span class="nv">num_episodes_per_iteration</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">EpisodeParameterMemory</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(limit={policy_buffer_size}, window_length=1)</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">memory</span> <span class="o">=</span> <span class="nv">EpisodeParameterMemory</span><span class="ss">(</span><span class="nv">limit</span><span class="o">=</span><span class="nv">policy_buffer_size</span>, <span class="nv">window_length</span><span class="o">=</span><span class="mi">1</span><span class="ss">)</span>

        <span class="nv">num_actions</span> <span class="o">=</span> <span class="nv">train_env</span>.<span class="nv">action_space</span>.<span class="nv">n</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">CEMAgent</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(model=..., nb_actions={num_actions}, memory=..., </span><span class="s1">&#39;</span> <span class="o">+</span> \

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">nb_steps_warmup={cc.num_steps_buffer_preload}, </span><span class="s1">&#39;</span> <span class="o">+</span> \

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">train_interval={cc.num_episodes_per_iteration}, </span><span class="s1">&#39;</span> <span class="o">+</span> \

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">batch_size={cc.num_episodes_per_iteration}, </span><span class="s1">&#39;</span> <span class="o">+</span> \

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">elite_frac={cc.elite_set_fraction})</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span> <span class="o">=</span> <span class="nv">CEMAgent</span><span class="ss">(</span><span class="nv">model</span><span class="o">=</span><span class="nv">keras_model</span>, <span class="nv">nb_actions</span><span class="o">=</span><span class="nv">num_actions</span>, <span class="nv">memory</span><span class="o">=</span><span class="nv">memory</span>,

                               <span class="nv">nb_steps_warmup</span><span class="o">=</span><span class="nv">cc</span>.<span class="nv">num_steps_buffer_preload</span>,

                               <span class="nv">batch_size</span><span class="o">=</span><span class="nv">cc</span>.<span class="nv">num_episodes_per_iteration</span>,

                               <span class="nv">train_interval</span><span class="o">=</span><span class="nv">cc</span>.<span class="nv">num_episodes_per_iteration</span>,

                               <span class="nv">elite_frac</span><span class="o">=</span><span class="nv">cc</span>.<span class="nv">elite_set_fraction</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">agent.compile</span><span class="s1">&#39;</span>, <span class="s1">&#39;</span><span class="s">()</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">compile</span><span class="ss">()</span>

        <span class="nv">nb_steps</span> <span class="o">=</span> <span class="nv">cc</span>.<span class="nv">num_iterations</span> <span class="o">*</span> <span class="nv">cc</span>.<span class="nv">num_episodes_per_iteration</span> <span class="o">*</span> <span class="nv">cc</span>.<span class="nv">max_steps_per_episode</span>

        <span class="nv">callback</span> <span class="o">=</span> <span class="nv">KerasRlCemAgent</span>.<span class="nv">CemCallback</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">cc</span>, <span class="nv">nb_steps</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">()</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">agent.fit</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(train_env, nb_steps={nb_steps})</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">fit</span><span class="ss">(</span><span class="nv">train_env</span>, <span class="nv">nb_steps</span><span class="o">=</span><span class="nv">nb_steps</span>, <span class="nv">visualize</span><span class="o">=</span><span class="nv">False</span>, <span class="nv">verbose</span><span class="o">=</span><span class="mi">0</span>, <span class="nv">callbacks</span><span class="o">=</span>[<span class="nv">callback</span>]<span class="ss">)</span>

        <span class="k">if</span> <span class="nv">not</span> <span class="nv">cc</span>.<span class="nv">training_done</span>:

            <span class="nv">self</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">math</span>.<span class="nv">nan</span><span class="ss">)</span>
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro_3">Ancestors (in MRO)</h4>
<ul>
<li>easyagents.backends.kerasrl.KerasRlAgent</li>
<li>easyagents.backends.core.BackendAgent</li>
<li>easyagents.backends.core._BackendAgent</li>
<li>abc.ABC</li>
</ul>
<h4 id="class-variables_1">Class variables</h4>
<div class="codehilite"><pre><span></span><span class="n">CemCallback</span>
</pre></div>


<h4 id="methods_3">Methods</h4>
<h5 id="log_2">log</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span>
</pre></div>


<p>Logs msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">log</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">log_msg</span>: <span class="nv">str</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Logs msg.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_monitor_env</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="nv">log_msg</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_log</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span>, <span class="nv">log_msg</span><span class="o">=</span><span class="nv">log_msg</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="log_api_2">log_api</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log_api</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">api_target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Logs a call to api_target with additional log_msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">log_api</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">api_target</span>: <span class="nv">str</span>, <span class="nv">log_msg</span>: <span class="nv">Optional</span>[<span class="nv">str</span>] <span class="o">=</span> <span class="nv">None</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Logs a call to api_target with additional log_msg.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_monitor_env</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="nv">api_target</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">api_target</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">if</span> <span class="nv">log_msg</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_api_log</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span>, <span class="nv">api_target</span>, <span class="nv">log_msg</span><span class="o">=</span><span class="nv">log_msg</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_begin_2">on_play_episode_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Env</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the beginning of a new episode</p>
<p>Args:
    env: the gym environment used to play the episode.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">env</span>: <span class="nv">gym</span>.<span class="nv">core</span>.<span class="nv">Env</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by play_implementation at the beginning of a new episode</span>

        <span class="nv">Args</span>:

            <span class="nv">env</span>: <span class="nv">the</span> <span class="nv">gym</span> <span class="nv">environment</span> <span class="nv">used</span> <span class="nv">to</span> <span class="nv">play</span> <span class="nv">the</span> <span class="nv">episode</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">env</span>, <span class="s2">&quot;</span><span class="s">env not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">isinstance</span><span class="ss">(</span><span class="nv">env</span>, <span class="nv">gym</span>.<span class="nv">core</span>.<span class="nv">Env</span><span class="ss">)</span>, <span class="s2">&quot;</span><span class="s">env not an an instance of gym.Env.</span><span class="s2">&quot;</span>

        <span class="nv">pc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">play</span>

        <span class="nv">pc</span>.<span class="nv">gym_env</span> <span class="o">=</span> <span class="nv">env</span>

        <span class="nv">pc</span>.<span class="nv">steps_done_in_episode</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nv">pc</span>.<span class="nv">actions</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> []

        <span class="nv">pc</span>.<span class="nv">rewards</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> []

        <span class="nv">pc</span>.<span class="nv">sum_of_rewards</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_end_2">on_play_episode_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_end</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the end of an episode</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_play_episode_end</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by play_implementation at the end of an episode</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">pc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">play</span>

        <span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nv">pc</span>.<span class="nv">num_episodes</span> <span class="nv">and</span> <span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">&gt;=</span> <span class="nv">pc</span>.<span class="nv">num_episodes</span>:

            <span class="nv">pc</span>.<span class="nv">play_done</span> <span class="o">=</span> <span class="nv">True</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_play_episode_end</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_begin_2">on_train_iteration_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_begin</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the begining of a new iteration</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_train_iteration_begin</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by train_implementation at the begining of a new iteration</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">tc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">train</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nv">tc</span>.<span class="nv">steps_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">==</span> <span class="mi">0</span>:

            <span class="nv">self</span>.<span class="nv">_eval_current_policy</span><span class="ss">()</span>

        <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_totals</span>.<span class="nv">episodes_done</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_end_2">on_train_iteration_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the end of an iteration</p>
<p>Evaluates the current policy. Use kwargs to set additional dict values in train context.
Eg for an ActorCriticTrainContext the losses may be set like this:
    on_train_iteration(loss=123,actor_loss=456,critic_loss=789)</p>
<p>Args:
    loss: loss after the training of the model in this iteration or math.nan if the loss is not available
    **kwargs: if a keyword matches a dict property of the TrainContext instance, then
                the dict[episodes_done_in_training] is set to the arg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">loss</span>: <span class="nv">float</span>, <span class="o">**</span><span class="nv">kwargs</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by train_implementation at the end of an iteration</span>

        <span class="nv">Evaluates</span> <span class="nv">the</span> <span class="nv">current</span> <span class="nv">policy</span>. <span class="nv">Use</span> <span class="nv">kwargs</span> <span class="nv">to</span> <span class="nv">set</span> <span class="nv">additional</span> <span class="nv">dict</span> <span class="nv">values</span> <span class="nv">in</span> <span class="nv">train</span> <span class="nv">context</span>.

        <span class="nv">Eg</span> <span class="k">for</span> <span class="nv">an</span> <span class="nv">ActorCriticTrainContext</span> <span class="nv">the</span> <span class="nv">losses</span> <span class="nv">may</span> <span class="nv">be</span> <span class="nv">set</span> <span class="nv">like</span> <span class="nv">this</span>:

            <span class="nv">on_train_iteration</span><span class="ss">(</span><span class="nv">loss</span><span class="o">=</span><span class="mi">123</span>,<span class="nv">actor_loss</span><span class="o">=</span><span class="mi">456</span>,<span class="nv">critic_loss</span><span class="o">=</span><span class="mi">789</span><span class="ss">)</span>

        <span class="nv">Args</span>:

            <span class="nv">loss</span>: <span class="nv">loss</span> <span class="nv">after</span> <span class="nv">the</span> <span class="nv">training</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">model</span> <span class="nv">in</span> <span class="nv">this</span> <span class="nv">iteration</span> <span class="nv">or</span> <span class="nv">math</span>.<span class="nv">nan</span> <span class="k">if</span> <span class="nv">the</span> <span class="nv">loss</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">available</span>

            <span class="o">**</span><span class="nv">kwargs</span>: <span class="k">if</span> <span class="nv">a</span> <span class="nv">keyword</span> <span class="nv">matches</span> <span class="nv">a</span> <span class="nv">dict</span> <span class="nv">property</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">TrainContext</span> <span class="nv">instance</span>, <span class="k">then</span>

                        <span class="nv">the</span> <span class="nv">dict</span>[<span class="nv">episodes_done_in_training</span>] <span class="nv">is</span> <span class="nv">set</span> <span class="nv">to</span> <span class="nv">the</span> <span class="nv">arg</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">tc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">train</span>

        <span class="nv">totals</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_totals</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span> <span class="o">=</span> <span class="ss">(</span><span class="nv">totals</span>.<span class="nv">episodes_done</span> <span class="o">-</span> <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span><span class="ss">)</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span> <span class="o">+=</span> <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span>

        <span class="nv">tc</span>.<span class="nv">loss</span>[<span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span>] <span class="o">=</span> <span class="nv">loss</span>

        # <span class="nv">set</span> <span class="nv">traincontext</span> <span class="nv">dict</span> <span class="nv">from</span> <span class="nv">kwargs</span>:

        <span class="k">for</span> <span class="nv">prop_name</span> <span class="nv">in</span> <span class="nv">kwargs</span>:

            <span class="nv">prop_instance</span> <span class="o">=</span> <span class="nv">getattr</span><span class="ss">(</span><span class="nv">tc</span>, <span class="nv">prop_name</span>, <span class="nv">None</span><span class="ss">)</span>

            <span class="nv">prop_value</span> <span class="o">=</span> <span class="nv">kwargs</span>[<span class="nv">prop_name</span>]

            <span class="k">if</span> <span class="nv">prop_instance</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span> <span class="nv">and</span> <span class="nv">isinstance</span><span class="ss">(</span><span class="nv">prop_instance</span>, <span class="nv">dict</span><span class="ss">)</span>:

                <span class="nv">prop_instance</span>[<span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span>] <span class="o">=</span> <span class="nv">prop_value</span>

        <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">num_iterations</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span>:

            <span class="nv">tc</span>.<span class="nv">training_done</span> <span class="o">=</span> <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">&gt;=</span> <span class="nv">tc</span>.<span class="nv">num_iterations</span>

        <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">num_iterations_between_eval</span> <span class="nv">and</span> <span class="ss">(</span><span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">%</span> <span class="nv">tc</span>.<span class="nv">num_iterations_between_eval</span> <span class="o">==</span> <span class="mi">0</span><span class="ss">)</span>:

            <span class="nv">self</span>.<span class="nv">_eval_current_policy</span><span class="ss">()</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="play_2">play</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to play_implementation overriden by the subclass.</p>
<p>Args:
    play_context: play configuration to be used
    callbacks: list of callbacks called during play.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">play</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">play_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">PlayContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to play_implementation overriden by the subclass.</span>

<span class="ss">            Args:</span>

<span class="ss">                play_context: play configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during play.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">play_context</span><span class="p">,</span> <span class="ss">&quot;play_context not set&quot;</span>

        <span class="n">assert</span> <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="k">is</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;play_context already set in agent_context&quot;</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="n">play_context</span>

        <span class="n">old_callbacks</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">play_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">old_callbacks</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="play_implementation_2">play_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of playing a single episodes with the current policy.</p>
<p>Args:
    play_context: play configuration to be used</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">play_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">play_context</span>: <span class="nv">core</span>.<span class="nv">PlayContext</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Agent specific implementation of playing a single episodes with the current policy.</span>

            <span class="nv">Args</span>:

                <span class="nv">play_context</span>: <span class="nv">play</span> <span class="nv">configuration</span> <span class="nv">to</span> <span class="nv">be</span> <span class="nv">used</span>

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">play_context</span>, <span class="s2">&quot;</span><span class="s">play_context not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">self</span>.<span class="nv">_agent</span>, <span class="s2">&quot;</span><span class="s">_agent not set. call train() first.</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="k">while</span> <span class="nv">True</span>:

            <span class="nv">self</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">env</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_play_env</span><span class="ss">)</span>

            <span class="nv">observation</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">reset</span><span class="ss">()</span>

            <span class="nv">done</span> <span class="o">=</span> <span class="nv">False</span>

            <span class="k">while</span> <span class="nv">not</span> <span class="nv">done</span>:

                <span class="nv">action</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">forward</span><span class="ss">(</span><span class="nv">observation</span><span class="ss">)</span>

                <span class="nv">observation</span>, <span class="nv">reward</span>, <span class="nv">done</span>, <span class="nv">info</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">step</span><span class="ss">(</span><span class="nv">action</span><span class="ss">)</span>

            <span class="nv">self</span>.<span class="nv">on_play_episode_end</span><span class="ss">()</span>

            <span class="k">if</span> <span class="nv">play_context</span>.<span class="nv">play_done</span>:

                <span class="k">break</span>
</pre></div>


</details>
<h5 id="train_2">train</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to train_implementation overriden by the subclass</p>
<p>Args:
    train_context: training configuration to be used
    callbacks: list of callbacks called during the training and evaluation.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">train</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">TrainContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to train_implementation overriden by the subclass</span>

<span class="ss">            Args:</span>

<span class="ss">                train_context: training configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during the training and evaluation.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">train_context</span><span class="p">,</span> <span class="ss">&quot;train_context not set&quot;</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train_context</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="k">self</span><span class="p">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;backend_name&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;{self._backend_name}&#39;</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_set_seed</span><span class="p">()</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">train_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="train_implementation_2">train_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">CemTrainContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of the train loop.</p>
<p>The implementation should have the form:</p>
<p>while True:
    on_iteration_begin
    for e in num_episodes_per_iterations
        play episode and record steps (while steps_in_episode &lt; max_steps_per_episode and)
    train policy for num_epochs_per_iteration epochs
    on_iteration_end( loss )
    if training_done
        break</p>
<p>Args:
    train_context: context configuring the train loop</p>
<p>Hints:
o the subclasses training loss is passed through to BackendAgent by on_iteration_end.
  Thus the subclass must not add the experienced loss to the TrainContext.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">train_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">train_context</span>: <span class="nv">core</span>.<span class="nv">CemTrainContext</span><span class="ss">)</span>:

        <span class="nv">assert</span> <span class="nv">train_context</span>

        <span class="nv">cc</span>: <span class="nv">core</span>.<span class="nv">CemTrainContext</span> <span class="o">=</span> <span class="nv">train_context</span>

        <span class="nv">train_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="nv">keras_model</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_model</span><span class="ss">(</span><span class="nv">gym_env</span><span class="o">=</span><span class="nv">train_env</span>, <span class="nv">activation</span><span class="o">=</span><span class="s1">&#39;</span><span class="s">softmax</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">policy_buffer_size</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="nv">cc</span>.<span class="nv">num_episodes_per_iteration</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">EpisodeParameterMemory</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(limit={policy_buffer_size}, window_length=1)</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">memory</span> <span class="o">=</span> <span class="nv">EpisodeParameterMemory</span><span class="ss">(</span><span class="nv">limit</span><span class="o">=</span><span class="nv">policy_buffer_size</span>, <span class="nv">window_length</span><span class="o">=</span><span class="mi">1</span><span class="ss">)</span>

        <span class="nv">num_actions</span> <span class="o">=</span> <span class="nv">train_env</span>.<span class="nv">action_space</span>.<span class="nv">n</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">CEMAgent</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(model=..., nb_actions={num_actions}, memory=..., </span><span class="s1">&#39;</span> <span class="o">+</span> \

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">nb_steps_warmup={cc.num_steps_buffer_preload}, </span><span class="s1">&#39;</span> <span class="o">+</span> \

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">train_interval={cc.num_episodes_per_iteration}, </span><span class="s1">&#39;</span> <span class="o">+</span> \

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">batch_size={cc.num_episodes_per_iteration}, </span><span class="s1">&#39;</span> <span class="o">+</span> \

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">elite_frac={cc.elite_set_fraction})</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span> <span class="o">=</span> <span class="nv">CEMAgent</span><span class="ss">(</span><span class="nv">model</span><span class="o">=</span><span class="nv">keras_model</span>, <span class="nv">nb_actions</span><span class="o">=</span><span class="nv">num_actions</span>, <span class="nv">memory</span><span class="o">=</span><span class="nv">memory</span>,

                               <span class="nv">nb_steps_warmup</span><span class="o">=</span><span class="nv">cc</span>.<span class="nv">num_steps_buffer_preload</span>,

                               <span class="nv">batch_size</span><span class="o">=</span><span class="nv">cc</span>.<span class="nv">num_episodes_per_iteration</span>,

                               <span class="nv">train_interval</span><span class="o">=</span><span class="nv">cc</span>.<span class="nv">num_episodes_per_iteration</span>,

                               <span class="nv">elite_frac</span><span class="o">=</span><span class="nv">cc</span>.<span class="nv">elite_set_fraction</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">agent.compile</span><span class="s1">&#39;</span>, <span class="s1">&#39;</span><span class="s">()</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">compile</span><span class="ss">()</span>

        <span class="nv">nb_steps</span> <span class="o">=</span> <span class="nv">cc</span>.<span class="nv">num_iterations</span> <span class="o">*</span> <span class="nv">cc</span>.<span class="nv">num_episodes_per_iteration</span> <span class="o">*</span> <span class="nv">cc</span>.<span class="nv">max_steps_per_episode</span>

        <span class="nv">callback</span> <span class="o">=</span> <span class="nv">KerasRlCemAgent</span>.<span class="nv">CemCallback</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">cc</span>, <span class="nv">nb_steps</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">()</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">agent.fit</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(train_env, nb_steps={nb_steps})</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">fit</span><span class="ss">(</span><span class="nv">train_env</span>, <span class="nv">nb_steps</span><span class="o">=</span><span class="nv">nb_steps</span>, <span class="nv">visualize</span><span class="o">=</span><span class="nv">False</span>, <span class="nv">verbose</span><span class="o">=</span><span class="mi">0</span>, <span class="nv">callbacks</span><span class="o">=</span>[<span class="nv">callback</span>]<span class="ss">)</span>

        <span class="k">if</span> <span class="nv">not</span> <span class="nv">cc</span>.<span class="nv">training_done</span>:

            <span class="nv">self</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">math</span>.<span class="nv">nan</span><span class="ss">)</span>
</pre></div>


</details>
<h3 id="kerasrldoubledqnagent">KerasRlDoubleDqnAgent</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">KerasRlDoubleDqnAgent</span><span class="p">(</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span>
<span class="p">)</span>
</pre></div>


<p>Keras-rl implementation of the algorithm described in https://arxiv.org/abs/1509.06461 </p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="n">KerasRlDoubleDqnAgent</span>(<span class="n">KerasRlDqnAgent</span>):

    <span class="s">&quot;&quot;&quot;Keras-rl implementation of the algorithm described in https://arxiv.org/abs/1509.06461 &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">__init__</span>(<span class="k">self</span>, <span class="n">model_config:</span> <span class="n">core</span>.<span class="n">ModelConfig</span>):

        <span class="s">&quot;&quot;&quot;Args:</span>

<span class="s">                model_config: the model configuration including the name of the target gym environment</span>

<span class="s">                    as well as the neural network architecture.</span>

<span class="s">        &quot;&quot;&quot;</span>

        <span class="n">super</span>().<span class="n">__init__</span>(<span class="n">model_config</span>=<span class="n">model_config</span>, <span class="n">enable_double_dqn</span>=<span class="nb">True</span>)
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro_4">Ancestors (in MRO)</h4>
<ul>
<li>easyagents.backends.kerasrl.KerasRlDqnAgent</li>
<li>easyagents.backends.kerasrl.KerasRlAgent</li>
<li>easyagents.backends.core.BackendAgent</li>
<li>easyagents.backends.core._BackendAgent</li>
<li>abc.ABC</li>
</ul>
<h4 id="class-variables_2">Class variables</h4>
<div class="codehilite"><pre><span></span><span class="n">DQNAgentWrapper</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">DqnCallback</span>
</pre></div>


<h4 id="methods_4">Methods</h4>
<h5 id="log_3">log</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span>
</pre></div>


<p>Logs msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">log</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">log_msg</span>: <span class="nv">str</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Logs msg.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_monitor_env</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="nv">log_msg</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_log</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span>, <span class="nv">log_msg</span><span class="o">=</span><span class="nv">log_msg</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="log_api_3">log_api</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log_api</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">api_target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Logs a call to api_target with additional log_msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">log_api</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">api_target</span>: <span class="nv">str</span>, <span class="nv">log_msg</span>: <span class="nv">Optional</span>[<span class="nv">str</span>] <span class="o">=</span> <span class="nv">None</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Logs a call to api_target with additional log_msg.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_monitor_env</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="nv">api_target</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">api_target</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">if</span> <span class="nv">log_msg</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_api_log</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span>, <span class="nv">api_target</span>, <span class="nv">log_msg</span><span class="o">=</span><span class="nv">log_msg</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_begin_3">on_play_episode_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Env</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the beginning of a new episode</p>
<p>Args:
    env: the gym environment used to play the episode.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">env</span>: <span class="nv">gym</span>.<span class="nv">core</span>.<span class="nv">Env</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by play_implementation at the beginning of a new episode</span>

        <span class="nv">Args</span>:

            <span class="nv">env</span>: <span class="nv">the</span> <span class="nv">gym</span> <span class="nv">environment</span> <span class="nv">used</span> <span class="nv">to</span> <span class="nv">play</span> <span class="nv">the</span> <span class="nv">episode</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">env</span>, <span class="s2">&quot;</span><span class="s">env not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">isinstance</span><span class="ss">(</span><span class="nv">env</span>, <span class="nv">gym</span>.<span class="nv">core</span>.<span class="nv">Env</span><span class="ss">)</span>, <span class="s2">&quot;</span><span class="s">env not an an instance of gym.Env.</span><span class="s2">&quot;</span>

        <span class="nv">pc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">play</span>

        <span class="nv">pc</span>.<span class="nv">gym_env</span> <span class="o">=</span> <span class="nv">env</span>

        <span class="nv">pc</span>.<span class="nv">steps_done_in_episode</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nv">pc</span>.<span class="nv">actions</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> []

        <span class="nv">pc</span>.<span class="nv">rewards</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> []

        <span class="nv">pc</span>.<span class="nv">sum_of_rewards</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_end_3">on_play_episode_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_end</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the end of an episode</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_play_episode_end</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by play_implementation at the end of an episode</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">pc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">play</span>

        <span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nv">pc</span>.<span class="nv">num_episodes</span> <span class="nv">and</span> <span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">&gt;=</span> <span class="nv">pc</span>.<span class="nv">num_episodes</span>:

            <span class="nv">pc</span>.<span class="nv">play_done</span> <span class="o">=</span> <span class="nv">True</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_play_episode_end</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_begin_3">on_train_iteration_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_begin</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the begining of a new iteration</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_train_iteration_begin</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by train_implementation at the begining of a new iteration</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">tc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">train</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nv">tc</span>.<span class="nv">steps_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">==</span> <span class="mi">0</span>:

            <span class="nv">self</span>.<span class="nv">_eval_current_policy</span><span class="ss">()</span>

        <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_totals</span>.<span class="nv">episodes_done</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_end_3">on_train_iteration_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the end of an iteration</p>
<p>Evaluates the current policy. Use kwargs to set additional dict values in train context.
Eg for an ActorCriticTrainContext the losses may be set like this:
    on_train_iteration(loss=123,actor_loss=456,critic_loss=789)</p>
<p>Args:
    loss: loss after the training of the model in this iteration or math.nan if the loss is not available
    **kwargs: if a keyword matches a dict property of the TrainContext instance, then
                the dict[episodes_done_in_training] is set to the arg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">loss</span>: <span class="nv">float</span>, <span class="o">**</span><span class="nv">kwargs</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by train_implementation at the end of an iteration</span>

        <span class="nv">Evaluates</span> <span class="nv">the</span> <span class="nv">current</span> <span class="nv">policy</span>. <span class="nv">Use</span> <span class="nv">kwargs</span> <span class="nv">to</span> <span class="nv">set</span> <span class="nv">additional</span> <span class="nv">dict</span> <span class="nv">values</span> <span class="nv">in</span> <span class="nv">train</span> <span class="nv">context</span>.

        <span class="nv">Eg</span> <span class="k">for</span> <span class="nv">an</span> <span class="nv">ActorCriticTrainContext</span> <span class="nv">the</span> <span class="nv">losses</span> <span class="nv">may</span> <span class="nv">be</span> <span class="nv">set</span> <span class="nv">like</span> <span class="nv">this</span>:

            <span class="nv">on_train_iteration</span><span class="ss">(</span><span class="nv">loss</span><span class="o">=</span><span class="mi">123</span>,<span class="nv">actor_loss</span><span class="o">=</span><span class="mi">456</span>,<span class="nv">critic_loss</span><span class="o">=</span><span class="mi">789</span><span class="ss">)</span>

        <span class="nv">Args</span>:

            <span class="nv">loss</span>: <span class="nv">loss</span> <span class="nv">after</span> <span class="nv">the</span> <span class="nv">training</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">model</span> <span class="nv">in</span> <span class="nv">this</span> <span class="nv">iteration</span> <span class="nv">or</span> <span class="nv">math</span>.<span class="nv">nan</span> <span class="k">if</span> <span class="nv">the</span> <span class="nv">loss</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">available</span>

            <span class="o">**</span><span class="nv">kwargs</span>: <span class="k">if</span> <span class="nv">a</span> <span class="nv">keyword</span> <span class="nv">matches</span> <span class="nv">a</span> <span class="nv">dict</span> <span class="nv">property</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">TrainContext</span> <span class="nv">instance</span>, <span class="k">then</span>

                        <span class="nv">the</span> <span class="nv">dict</span>[<span class="nv">episodes_done_in_training</span>] <span class="nv">is</span> <span class="nv">set</span> <span class="nv">to</span> <span class="nv">the</span> <span class="nv">arg</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">tc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">train</span>

        <span class="nv">totals</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_totals</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span> <span class="o">=</span> <span class="ss">(</span><span class="nv">totals</span>.<span class="nv">episodes_done</span> <span class="o">-</span> <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span><span class="ss">)</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span> <span class="o">+=</span> <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span>

        <span class="nv">tc</span>.<span class="nv">loss</span>[<span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span>] <span class="o">=</span> <span class="nv">loss</span>

        # <span class="nv">set</span> <span class="nv">traincontext</span> <span class="nv">dict</span> <span class="nv">from</span> <span class="nv">kwargs</span>:

        <span class="k">for</span> <span class="nv">prop_name</span> <span class="nv">in</span> <span class="nv">kwargs</span>:

            <span class="nv">prop_instance</span> <span class="o">=</span> <span class="nv">getattr</span><span class="ss">(</span><span class="nv">tc</span>, <span class="nv">prop_name</span>, <span class="nv">None</span><span class="ss">)</span>

            <span class="nv">prop_value</span> <span class="o">=</span> <span class="nv">kwargs</span>[<span class="nv">prop_name</span>]

            <span class="k">if</span> <span class="nv">prop_instance</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span> <span class="nv">and</span> <span class="nv">isinstance</span><span class="ss">(</span><span class="nv">prop_instance</span>, <span class="nv">dict</span><span class="ss">)</span>:

                <span class="nv">prop_instance</span>[<span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span>] <span class="o">=</span> <span class="nv">prop_value</span>

        <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">num_iterations</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span>:

            <span class="nv">tc</span>.<span class="nv">training_done</span> <span class="o">=</span> <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">&gt;=</span> <span class="nv">tc</span>.<span class="nv">num_iterations</span>

        <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">num_iterations_between_eval</span> <span class="nv">and</span> <span class="ss">(</span><span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">%</span> <span class="nv">tc</span>.<span class="nv">num_iterations_between_eval</span> <span class="o">==</span> <span class="mi">0</span><span class="ss">)</span>:

            <span class="nv">self</span>.<span class="nv">_eval_current_policy</span><span class="ss">()</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="play_3">play</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to play_implementation overriden by the subclass.</p>
<p>Args:
    play_context: play configuration to be used
    callbacks: list of callbacks called during play.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">play</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">play_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">PlayContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to play_implementation overriden by the subclass.</span>

<span class="ss">            Args:</span>

<span class="ss">                play_context: play configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during play.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">play_context</span><span class="p">,</span> <span class="ss">&quot;play_context not set&quot;</span>

        <span class="n">assert</span> <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="k">is</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;play_context already set in agent_context&quot;</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="n">play_context</span>

        <span class="n">old_callbacks</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">play_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">old_callbacks</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="play_implementation_3">play_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of playing a single episodes with the current policy.</p>
<p>Args:
    play_context: play configuration to be used</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">play_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">play_context</span>: <span class="nv">core</span>.<span class="nv">PlayContext</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Agent specific implementation of playing a single episodes with the current policy.</span>

            <span class="nv">Args</span>:

                <span class="nv">play_context</span>: <span class="nv">play</span> <span class="nv">configuration</span> <span class="nv">to</span> <span class="nv">be</span> <span class="nv">used</span>

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">play_context</span>, <span class="s2">&quot;</span><span class="s">play_context not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">self</span>.<span class="nv">_agent</span>, <span class="s2">&quot;</span><span class="s">_agent not set. call train() first.</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="k">while</span> <span class="nv">True</span>:

            <span class="nv">self</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">env</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_play_env</span><span class="ss">)</span>

            <span class="nv">observation</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">reset</span><span class="ss">()</span>

            <span class="nv">done</span> <span class="o">=</span> <span class="nv">False</span>

            <span class="k">while</span> <span class="nv">not</span> <span class="nv">done</span>:

                <span class="nv">action</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">forward</span><span class="ss">(</span><span class="nv">observation</span><span class="ss">)</span>

                <span class="nv">observation</span>, <span class="nv">reward</span>, <span class="nv">done</span>, <span class="nv">info</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">step</span><span class="ss">(</span><span class="nv">action</span><span class="ss">)</span>

            <span class="nv">self</span>.<span class="nv">on_play_episode_end</span><span class="ss">()</span>

            <span class="k">if</span> <span class="nv">play_context</span>.<span class="nv">play_done</span>:

                <span class="k">break</span>
</pre></div>


</details>
<h5 id="train_3">train</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to train_implementation overriden by the subclass</p>
<p>Args:
    train_context: training configuration to be used
    callbacks: list of callbacks called during the training and evaluation.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">train</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">TrainContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to train_implementation overriden by the subclass</span>

<span class="ss">            Args:</span>

<span class="ss">                train_context: training configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during the training and evaluation.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">train_context</span><span class="p">,</span> <span class="ss">&quot;train_context not set&quot;</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train_context</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="k">self</span><span class="p">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;backend_name&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;{self._backend_name}&#39;</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_set_seed</span><span class="p">()</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">train_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="train_implementation_3">train_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">StepsTrainContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of the train loop.</p>
<p>The implementation should have the form:</p>
<p>while True:
    on_iteration_begin
    for e in num_episodes_per_iterations
        play episode and record steps (while steps_in_episode &lt; max_steps_per_episode and)
    train policy for num_epochs_per_iteration epochs
    on_iteration_end( loss )
    if training_done
        break</p>
<p>Args:
    train_context: context configuring the train loop</p>
<p>Hints:
o the subclasses training loss is passed through to BackendAgent by on_iteration_end.
  Thus the subclass must not add the experienced loss to the TrainContext.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">train_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">train_context</span>: <span class="nv">core</span>.<span class="nv">StepsTrainContext</span><span class="ss">)</span>:

        <span class="nv">assert</span> <span class="nv">train_context</span>

        <span class="nv">dc</span>: <span class="nv">core</span>.<span class="nv">StepsTrainContext</span> <span class="o">=</span> <span class="nv">train_context</span>

        <span class="nv">train_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="nv">keras_model</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_model</span><span class="ss">(</span><span class="nv">gym_env</span><span class="o">=</span><span class="nv">train_env</span>, <span class="nv">activation</span><span class="o">=</span><span class="s1">&#39;</span><span class="s">linear</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">SequentialMemory</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(limit={dc.max_steps_in_buffer}, window_length=1)</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">memory</span> <span class="o">=</span> <span class="nv">SequentialMemory</span><span class="ss">(</span><span class="nv">limit</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">max_steps_in_buffer</span>, <span class="nv">window_length</span><span class="o">=</span><span class="mi">1</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">BoltzmannQPolicy</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">()</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">policy</span> <span class="o">=</span> <span class="nv">BoltzmannQPolicy</span><span class="ss">()</span>

        <span class="nv">num_actions</span> <span class="o">=</span> <span class="nv">train_env</span>.<span class="nv">action_space</span>.<span class="nv">n</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">DQNAgent</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(nb_actions={num_actions}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">enable_double_dqn={self._enable_double_dqn}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">enable_dueling_network={self._enable_dueling_network}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">nb_steps_warmup={dc.num_steps_buffer_preload}, target_model_update=1e-2,</span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">gamma={dc.reward_discount_gamma}, batch_size={dc.num_steps_sampled_from_buffer}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">train_interval={dc.num_steps_per_iteration}, model=..., memory=..., policy=...)</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span> <span class="o">=</span> <span class="nv">KerasRlDqnAgent</span>.<span class="nv">DQNAgentWrapper</span><span class="ss">(</span>

            <span class="nv">enable_double_dqn</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_enable_double_dqn</span>,

            <span class="nv">enable_dueling_network</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_enable_dueling_network</span>,

            <span class="nv">model</span><span class="o">=</span><span class="nv">keras_model</span>,

            <span class="nv">nb_actions</span><span class="o">=</span><span class="nv">num_actions</span>,

            <span class="nv">memory</span><span class="o">=</span><span class="nv">memory</span>,

            <span class="nv">nb_steps_warmup</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">num_steps_buffer_preload</span>,

            <span class="nv">target_model_update</span><span class="o">=</span><span class="mi">1</span><span class="nv">e</span><span class="o">-</span><span class="mi">2</span>,

            <span class="nv">gamma</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">reward_discount_gamma</span>,

            <span class="nv">batch_size</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">num_steps_sampled_from_buffer</span>,

            <span class="nv">train_interval</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">num_steps_per_iteration</span>,

            <span class="nv">policy</span><span class="o">=</span><span class="nv">policy</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">agent.compile</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(Adam(lr=1e-3), metrics=[&quot;mae&quot;]</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">compile</span><span class="ss">(</span><span class="nv">Adam</span><span class="ss">(</span><span class="nv">lr</span><span class="o">=</span><span class="mi">1</span><span class="nv">e</span><span class="o">-</span><span class="mi">3</span><span class="ss">)</span>, <span class="nv">metrics</span><span class="o">=</span>[<span class="s1">&#39;</span><span class="s">mae</span><span class="s1">&#39;</span>]<span class="ss">)</span>

        <span class="nv">num_steps</span> <span class="o">=</span> <span class="nv">dc</span>.<span class="nv">num_iterations</span> <span class="o">*</span> <span class="nv">dc</span>.<span class="nv">num_steps_per_iteration</span>

        <span class="nv">loss_metric_idx</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="s1">&#39;</span><span class="s">loss</span><span class="s1">&#39;</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">metrics_names</span>:

            <span class="nv">loss_metric_idx</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">metrics_names</span>.<span class="nv">index</span><span class="ss">(</span><span class="s2">&quot;</span><span class="s">loss</span><span class="s2">&quot;</span><span class="ss">)</span>

        <span class="nv">dqn_callback</span> <span class="o">=</span> <span class="nv">KerasRlDqnAgent</span>.<span class="nv">DqnCallback</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">dc</span>, <span class="nv">loss_metric_idx</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">()</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">agent.fit</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(train_env, nb_steps={num_steps})</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">fit</span><span class="ss">(</span><span class="nv">train_env</span>, <span class="nv">nb_steps</span><span class="o">=</span><span class="nv">num_steps</span>, <span class="nv">visualize</span><span class="o">=</span><span class="nv">False</span>, <span class="nv">verbose</span><span class="o">=</span><span class="mi">0</span>, <span class="nv">callbacks</span><span class="o">=</span>[<span class="nv">dqn_callback</span>]<span class="ss">)</span>

        <span class="k">if</span> <span class="nv">not</span> <span class="nv">dc</span>.<span class="nv">training_done</span>:

            <span class="nv">self</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">math</span>.<span class="nv">nan</span><span class="ss">)</span>
</pre></div>


</details>
<h3 id="kerasrldqnagent">KerasRlDqnAgent</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">KerasRlDqnAgent</span><span class="p">(</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span><span class="p">,</span>
    <span class="n">enable_dueling_dqn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">enable_double_dqn</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>


<p>Keras-rl implementation of the algorithm described in in Mnih (2013) and Mnih (2015).
http://arxiv.org/pdf/1312.5602.pdf and http://arxiv.org/abs/1509.06461</p>
<p>includes implementations for the double dqn and dueling dqn variations.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="nv">class</span> <span class="nv">KerasRlDqnAgent</span><span class="ss">(</span><span class="nv">KerasRlAgent</span><span class="ss">)</span>:

    <span class="s2">&quot;&quot;&quot;</span><span class="s">Keras-rl implementation of the algorithm described in in Mnih (2013) and Mnih (2015).</span>

        <span class="nv">http</span>:<span class="o">//</span><span class="nv">arxiv</span>.<span class="nv">org</span><span class="o">/</span><span class="nv">pdf</span><span class="o">/</span><span class="mi">1312</span>.<span class="mi">5602</span>.<span class="nv">pdf</span> <span class="nv">and</span> <span class="nv">http</span>:<span class="o">//</span><span class="nv">arxiv</span>.<span class="nv">org</span><span class="o">/</span><span class="nv">abs</span><span class="o">/</span><span class="mi">1509</span>.<span class="mi">06461</span>

        <span class="nv">includes</span> <span class="nv">implementations</span> <span class="k">for</span> <span class="nv">the</span> <span class="nv">double</span> <span class="nv">dqn</span> <span class="nv">and</span> <span class="nv">dueling</span> <span class="nv">dqn</span> <span class="nv">variations</span>.

        <span class="s2">&quot;&quot;&quot;</span>

    <span class="nv">class</span> <span class="nv">DQNAgentWrapper</span><span class="ss">(</span><span class="nv">DQNAgent</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Override of the KerasRl DqnAgennt instantiation due to a conflict with tensorflow 1.15.</span>

        <span class="nv">Essentially</span> <span class="nv">a</span> <span class="nv">copy</span> <span class="nv">of</span>  <span class="nv">https</span>:<span class="o">//</span><span class="nv">raw</span>.<span class="nv">githubusercontent</span>.<span class="nv">com</span><span class="o">/</span><span class="nv">keras</span><span class="o">-</span><span class="nv">rl</span><span class="o">/</span><span class="nv">keras</span><span class="o">-</span><span class="nv">rl</span><span class="o">/</span><span class="nv">master</span><span class="o">/</span><span class="nv">rl</span><span class="o">/</span><span class="nv">agents</span><span class="o">/</span><span class="nv">dqn</span>.<span class="nv">py</span>

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">def</span> <span class="nv">__init__</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">model</span>, <span class="nv">policy</span><span class="o">=</span><span class="nv">None</span>, <span class="nv">test_policy</span><span class="o">=</span><span class="nv">None</span>, <span class="nv">enable_double_dqn</span><span class="o">=</span><span class="nv">False</span>, <span class="nv">enable_dueling_network</span><span class="o">=</span><span class="nv">False</span>,

                     <span class="nv">dueling_type</span><span class="o">=</span><span class="s1">&#39;</span><span class="s">avg</span><span class="s1">&#39;</span>, <span class="o">*</span><span class="nv">args</span>, <span class="o">**</span><span class="nv">kwargs</span><span class="ss">)</span>:

            <span class="nv">super</span><span class="ss">(</span><span class="nv">DQNAgent</span>, <span class="nv">self</span><span class="ss">)</span>.<span class="nv">__init__</span><span class="ss">(</span><span class="o">*</span><span class="nv">args</span>, <span class="o">**</span><span class="nv">kwargs</span><span class="ss">)</span>

            <span class="k">if</span> <span class="nv">model</span>.<span class="nv">output</span>.<span class="nv">_keras_shape</span> <span class="o">!=</span> <span class="ss">(</span><span class="nv">None</span>, <span class="nv">self</span>.<span class="nv">nb_actions</span><span class="ss">)</span>:

                <span class="nv">raise</span> <span class="nv">ValueError</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">Model output &quot;{model.output}&quot; has invalid shape. Dqn expects </span><span class="s1">&#39;</span> <span class="o">+</span>

                                 <span class="nv">f</span><span class="s1">&#39;</span><span class="s">a model that has one dimension for each action, in this case {self.nb_actions}.</span><span class="s1">&#39;</span><span class="ss">)</span>

            <span class="nv">self</span>.<span class="nv">enable_double_dqn</span> <span class="o">=</span> <span class="nv">enable_double_dqn</span>

            <span class="nv">self</span>.<span class="nv">enable_dueling_network</span> <span class="o">=</span> <span class="nv">enable_dueling_network</span>

            <span class="nv">self</span>.<span class="nv">dueling_type</span> <span class="o">=</span> <span class="nv">dueling_type</span>

            <span class="k">if</span> <span class="nv">self</span>.<span class="nv">enable_dueling_network</span>:

                <span class="nv">layer</span> <span class="o">=</span> <span class="nv">model</span>.<span class="nv">layers</span>[<span class="o">-</span><span class="mi">2</span>]

                <span class="nv">nb_action</span> <span class="o">=</span> <span class="nv">model</span>.<span class="nv">output</span>.<span class="nv">_keras_shape</span>[<span class="o">-</span><span class="mi">1</span>]

                <span class="nv">y</span> <span class="o">=</span> <span class="nv">Dense</span><span class="ss">(</span><span class="nv">nb_action</span> <span class="o">+</span> <span class="mi">1</span>, <span class="nv">activation</span><span class="o">=</span><span class="s1">&#39;</span><span class="s">linear</span><span class="s1">&#39;</span><span class="ss">)(</span><span class="nv">layer</span>.<span class="nv">output</span><span class="ss">)</span>

                <span class="k">if</span> <span class="nv">self</span>.<span class="nv">dueling_type</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="s">avg</span><span class="s1">&#39;</span>:

                    <span class="nv">outputlayer</span> <span class="o">=</span> <span class="nv">Lambda</span><span class="ss">(</span>

                        <span class="nv">lambda</span> <span class="nv">a</span>: <span class="nv">K</span>.<span class="nv">expand_dims</span><span class="ss">(</span><span class="nv">a</span>[:, <span class="mi">0</span>], <span class="o">-</span><span class="mi">1</span><span class="ss">)</span> <span class="o">+</span> <span class="nv">a</span>[:, <span class="mi">1</span>:] <span class="o">-</span> <span class="nv">K</span>.<span class="nv">mean</span><span class="ss">(</span><span class="nv">a</span>[:, <span class="mi">1</span>:], <span class="nv">keepdims</span><span class="o">=</span><span class="nv">True</span><span class="ss">)</span>,

                        <span class="nv">output_shape</span><span class="o">=</span><span class="ss">(</span><span class="nv">nb_action</span>,<span class="ss">))(</span><span class="nv">y</span><span class="ss">)</span>

                <span class="nv">elif</span> <span class="nv">self</span>.<span class="nv">dueling_type</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="s">max</span><span class="s1">&#39;</span>:

                    <span class="nv">outputlayer</span> <span class="o">=</span> <span class="nv">Lambda</span><span class="ss">(</span>

                        <span class="nv">lambda</span> <span class="nv">a</span>: <span class="nv">K</span>.<span class="nv">expand_dims</span><span class="ss">(</span><span class="nv">a</span>[:, <span class="mi">0</span>], <span class="o">-</span><span class="mi">1</span><span class="ss">)</span> <span class="o">+</span> <span class="nv">a</span>[:, <span class="mi">1</span>:] <span class="o">-</span> <span class="nv">K</span>.<span class="nv">max</span><span class="ss">(</span><span class="nv">a</span>[:, <span class="mi">1</span>:], <span class="nv">keepdims</span><span class="o">=</span><span class="nv">True</span><span class="ss">)</span>,

                        <span class="nv">output_shape</span><span class="o">=</span><span class="ss">(</span><span class="nv">nb_action</span>,<span class="ss">))(</span><span class="nv">y</span><span class="ss">)</span>

                <span class="nv">elif</span> <span class="nv">self</span>.<span class="nv">dueling_type</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="s">naive</span><span class="s1">&#39;</span>:

                    <span class="nv">outputlayer</span> <span class="o">=</span> <span class="nv">Lambda</span><span class="ss">(</span><span class="nv">lambda</span> <span class="nv">a</span>: <span class="nv">K</span>.<span class="nv">expand_dims</span><span class="ss">(</span><span class="nv">a</span>[:, <span class="mi">0</span>], <span class="o">-</span><span class="mi">1</span><span class="ss">)</span> <span class="o">+</span> <span class="nv">a</span>[:, <span class="mi">1</span>:], <span class="nv">output_shape</span><span class="o">=</span><span class="ss">(</span><span class="nv">nb_action</span>,<span class="ss">))(</span><span class="nv">y</span><span class="ss">)</span>

                <span class="k">else</span>:

                    <span class="nv">assert</span> <span class="nv">False</span>, <span class="s2">&quot;</span><span class="s">dueling_type must be one of {&#39;avg&#39;,&#39;max&#39;,&#39;naive&#39;}</span><span class="s2">&quot;</span>

                <span class="nv">model</span> <span class="o">=</span> <span class="nv">Model</span><span class="ss">(</span><span class="nv">inputs</span><span class="o">=</span><span class="nv">model</span>.<span class="nv">input</span>, <span class="nv">outputs</span><span class="o">=</span><span class="nv">outputlayer</span><span class="ss">)</span>

            <span class="nv">self</span>.<span class="nv">model</span> <span class="o">=</span> <span class="nv">model</span>

            <span class="k">if</span> <span class="nv">policy</span> <span class="nv">is</span> <span class="nv">None</span>:

                <span class="nv">policy</span> <span class="o">=</span> <span class="nv">EpsGreedyQPolicy</span><span class="ss">()</span>

            <span class="k">if</span> <span class="nv">test_policy</span> <span class="nv">is</span> <span class="nv">None</span>:

                <span class="nv">test_policy</span> <span class="o">=</span> <span class="nv">GreedyQPolicy</span><span class="ss">()</span>

            <span class="nv">self</span>.<span class="nv">policy</span> <span class="o">=</span> <span class="nv">policy</span>

            <span class="nv">self</span>.<span class="nv">test_policy</span> <span class="o">=</span> <span class="nv">test_policy</span>

            <span class="nv">self</span>.<span class="nv">reset_states</span><span class="ss">()</span>

    <span class="nv">class</span> <span class="nv">DqnCallback</span><span class="ss">(</span><span class="nv">rl</span>.<span class="nv">callbacks</span>.<span class="nv">Callback</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Callback registered with keras rl agents to propagate iteration and episode updates.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">def</span> <span class="nv">__init__</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">agent</span>: <span class="nv">bcore</span>.<span class="nv">BackendAgent</span>, <span class="nv">dqn_context</span>: <span class="nv">core</span>.<span class="nv">StepsTrainContext</span>,

                     <span class="nv">loss_metric_idx</span>: <span class="nv">Optional</span>[<span class="nv">int</span>]<span class="ss">)</span>:

            <span class="s2">&quot;&quot;&quot;</span>

            <span class="nv">Args</span>:

                <span class="nv">agent</span>: <span class="nv">the</span> <span class="nv">agent</span> <span class="nv">to</span> <span class="nv">propagate</span> <span class="nv">iteration</span> <span class="nv">begn</span><span class="o">/</span><span class="k">end</span> <span class="nv">events</span> <span class="nv">to</span>.

                <span class="nv">dqn_context</span>: <span class="nv">the</span> <span class="nv">train_context</span> <span class="nv">containing</span> <span class="nv">the</span> <span class="nv">iteration</span> <span class="nv">definitions</span>

                <span class="nv">loss_metric_idx</span>: <span class="nv">the</span> <span class="nv">index</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">loss</span> <span class="nv">in</span> <span class="nv">the</span> <span class="nv">metrics</span> <span class="nv">list</span>, <span class="nv">or</span> <span class="nv">None</span>

            <span class="s2">&quot;&quot;&quot;</span>

            <span class="nv">assert</span> <span class="nv">agent</span>

            <span class="nv">assert</span> <span class="nv">dqn_context</span>

            <span class="nv">self</span>.<span class="nv">_agent</span> <span class="o">=</span> <span class="nv">agent</span>

            <span class="nv">self</span>.<span class="nv">_dqn_context</span> <span class="o">=</span> <span class="nv">dqn_context</span>

            <span class="nv">self</span>.<span class="nv">_loss_metric_idx</span> <span class="o">=</span> <span class="nv">loss_metric_idx</span>

            <span class="nv">super</span><span class="ss">()</span>.<span class="nv">__init__</span><span class="ss">()</span>

        <span class="nv">def</span> <span class="nv">on_step_end</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">step</span>, <span class="nv">logs</span><span class="o">=</span><span class="nv">None</span><span class="ss">)</span>:

            <span class="s2">&quot;&quot;&quot;</span><span class="s">Signals the base class the end / begin of a training iteration.</span><span class="s2">&quot;&quot;&quot;</span>

            <span class="nv">steps_done</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_dqn_context</span>.<span class="nv">steps_done_in_training</span> <span class="o">-</span> <span class="nv">self</span>.<span class="nv">_dqn_context</span>.<span class="nv">num_steps_buffer_preload</span>

            <span class="k">if</span> <span class="nv">steps_done</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="nv">and</span> <span class="nv">steps_done</span> <span class="o">%</span> <span class="nv">self</span>.<span class="nv">_dqn_context</span>.<span class="nv">num_steps_per_iteration</span> <span class="o">==</span> <span class="mi">0</span>:

                <span class="nv">loss</span> <span class="o">=</span> <span class="nv">math</span>.<span class="nv">nan</span>

                <span class="k">if</span> <span class="nv">logs</span> <span class="nv">and</span> <span class="s1">&#39;</span><span class="s">metrics</span><span class="s1">&#39;</span> <span class="nv">in</span> <span class="nv">logs</span> <span class="nv">and</span> <span class="ss">(</span><span class="nv">self</span>.<span class="nv">_loss_metric_idx</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span><span class="ss">)</span>:

                    <span class="nv">metrics</span> <span class="o">=</span> <span class="nv">logs</span>[<span class="s1">&#39;</span><span class="s">metrics</span><span class="s1">&#39;</span>]

                    <span class="k">if</span> <span class="nv">len</span><span class="ss">(</span><span class="nv">metrics</span><span class="ss">)</span> <span class="o">&gt;</span> <span class="nv">self</span>.<span class="nv">_loss_metric_idx</span>:

                        <span class="nv">loss</span> <span class="o">=</span> <span class="nv">metrics</span>[<span class="nv">self</span>.<span class="nv">_loss_metric_idx</span>]

                <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">loss</span><span class="ss">)</span>

                <span class="k">if</span> <span class="nv">not</span> <span class="nv">self</span>.<span class="nv">_dqn_context</span>.<span class="nv">training_done</span>:

                    <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">()</span>

    <span class="nv">def</span> <span class="nv">__init__</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">model_config</span>: <span class="nv">core</span>.<span class="nv">ModelConfig</span>,

                 <span class="nv">enable_dueling_dqn</span>: <span class="nv">bool</span> <span class="o">=</span> <span class="nv">False</span>, <span class="nv">enable_double_dqn</span><span class="o">=</span><span class="nv">False</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s"> creates a new agent based on the DQN algorithm using the keras-rl implementation.</span>

            <span class="nv">Args</span>:

                <span class="nv">model_config</span>: <span class="nv">the</span> <span class="nv">model</span> <span class="nv">configuration</span> <span class="nv">including</span> <span class="nv">the</span> <span class="nv">name</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">target</span> <span class="nv">gym</span> <span class="nv">environment</span>

                    <span class="nv">as</span> <span class="nv">well</span> <span class="nv">as</span> <span class="nv">the</span> <span class="nv">neural</span> <span class="nv">network</span> <span class="nv">architecture</span>.

                <span class="nv">enable_double_dqn</span>: <span class="nv">use</span> <span class="nv">the</span> <span class="nv">double</span> <span class="nv">dqn</span> <span class="nv">algorithm</span> <span class="nv">instead</span>

                <span class="nv">enable_dueling_dqn</span>: <span class="nv">use</span> <span class="nv">the</span> <span class="nv">dueling</span> <span class="nv">dqn</span> <span class="nv">algorithm</span> <span class="nv">instead</span>

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">super</span><span class="ss">()</span>.<span class="nv">__init__</span><span class="ss">(</span><span class="nv">model_config</span><span class="o">=</span><span class="nv">model_config</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_enable_double_dqn</span>: <span class="nv">bool</span> <span class="o">=</span> <span class="nv">enable_double_dqn</span>

        <span class="nv">self</span>.<span class="nv">_enable_dueling_network</span>: <span class="nv">bool</span> <span class="o">=</span> <span class="nv">enable_dueling_dqn</span>

    <span class="nv">def</span> <span class="nv">train_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">train_context</span>: <span class="nv">core</span>.<span class="nv">StepsTrainContext</span><span class="ss">)</span>:

        <span class="nv">assert</span> <span class="nv">train_context</span>

        <span class="nv">dc</span>: <span class="nv">core</span>.<span class="nv">StepsTrainContext</span> <span class="o">=</span> <span class="nv">train_context</span>

        <span class="nv">train_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="nv">keras_model</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_model</span><span class="ss">(</span><span class="nv">gym_env</span><span class="o">=</span><span class="nv">train_env</span>, <span class="nv">activation</span><span class="o">=</span><span class="s1">&#39;</span><span class="s">linear</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">SequentialMemory</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(limit={dc.max_steps_in_buffer}, window_length=1)</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">memory</span> <span class="o">=</span> <span class="nv">SequentialMemory</span><span class="ss">(</span><span class="nv">limit</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">max_steps_in_buffer</span>, <span class="nv">window_length</span><span class="o">=</span><span class="mi">1</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">BoltzmannQPolicy</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">()</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">policy</span> <span class="o">=</span> <span class="nv">BoltzmannQPolicy</span><span class="ss">()</span>

        <span class="nv">num_actions</span> <span class="o">=</span> <span class="nv">train_env</span>.<span class="nv">action_space</span>.<span class="nv">n</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">DQNAgent</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(nb_actions={num_actions}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">enable_double_dqn={self._enable_double_dqn}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">enable_dueling_network={self._enable_dueling_network}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">nb_steps_warmup={dc.num_steps_buffer_preload}, target_model_update=1e-2,</span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">gamma={dc.reward_discount_gamma}, batch_size={dc.num_steps_sampled_from_buffer}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">train_interval={dc.num_steps_per_iteration}, model=..., memory=..., policy=...)</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span> <span class="o">=</span> <span class="nv">KerasRlDqnAgent</span>.<span class="nv">DQNAgentWrapper</span><span class="ss">(</span>

            <span class="nv">enable_double_dqn</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_enable_double_dqn</span>,

            <span class="nv">enable_dueling_network</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_enable_dueling_network</span>,

            <span class="nv">model</span><span class="o">=</span><span class="nv">keras_model</span>,

            <span class="nv">nb_actions</span><span class="o">=</span><span class="nv">num_actions</span>,

            <span class="nv">memory</span><span class="o">=</span><span class="nv">memory</span>,

            <span class="nv">nb_steps_warmup</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">num_steps_buffer_preload</span>,

            <span class="nv">target_model_update</span><span class="o">=</span><span class="mi">1</span><span class="nv">e</span><span class="o">-</span><span class="mi">2</span>,

            <span class="nv">gamma</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">reward_discount_gamma</span>,

            <span class="nv">batch_size</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">num_steps_sampled_from_buffer</span>,

            <span class="nv">train_interval</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">num_steps_per_iteration</span>,

            <span class="nv">policy</span><span class="o">=</span><span class="nv">policy</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">agent.compile</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(Adam(lr=1e-3), metrics=[&quot;mae&quot;]</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">compile</span><span class="ss">(</span><span class="nv">Adam</span><span class="ss">(</span><span class="nv">lr</span><span class="o">=</span><span class="mi">1</span><span class="nv">e</span><span class="o">-</span><span class="mi">3</span><span class="ss">)</span>, <span class="nv">metrics</span><span class="o">=</span>[<span class="s1">&#39;</span><span class="s">mae</span><span class="s1">&#39;</span>]<span class="ss">)</span>

        <span class="nv">num_steps</span> <span class="o">=</span> <span class="nv">dc</span>.<span class="nv">num_iterations</span> <span class="o">*</span> <span class="nv">dc</span>.<span class="nv">num_steps_per_iteration</span>

        <span class="nv">loss_metric_idx</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="s1">&#39;</span><span class="s">loss</span><span class="s1">&#39;</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">metrics_names</span>:

            <span class="nv">loss_metric_idx</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">metrics_names</span>.<span class="nv">index</span><span class="ss">(</span><span class="s2">&quot;</span><span class="s">loss</span><span class="s2">&quot;</span><span class="ss">)</span>

        <span class="nv">dqn_callback</span> <span class="o">=</span> <span class="nv">KerasRlDqnAgent</span>.<span class="nv">DqnCallback</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">dc</span>, <span class="nv">loss_metric_idx</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">()</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">agent.fit</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(train_env, nb_steps={num_steps})</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">fit</span><span class="ss">(</span><span class="nv">train_env</span>, <span class="nv">nb_steps</span><span class="o">=</span><span class="nv">num_steps</span>, <span class="nv">visualize</span><span class="o">=</span><span class="nv">False</span>, <span class="nv">verbose</span><span class="o">=</span><span class="mi">0</span>, <span class="nv">callbacks</span><span class="o">=</span>[<span class="nv">dqn_callback</span>]<span class="ss">)</span>

        <span class="k">if</span> <span class="nv">not</span> <span class="nv">dc</span>.<span class="nv">training_done</span>:

            <span class="nv">self</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">math</span>.<span class="nv">nan</span><span class="ss">)</span>
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro_5">Ancestors (in MRO)</h4>
<ul>
<li>easyagents.backends.kerasrl.KerasRlAgent</li>
<li>easyagents.backends.core.BackendAgent</li>
<li>easyagents.backends.core._BackendAgent</li>
<li>abc.ABC</li>
</ul>
<h4 id="descendants_1">Descendants</h4>
<ul>
<li>easyagents.backends.kerasrl.KerasRlDoubleDqnAgent</li>
<li>easyagents.backends.kerasrl.KerasRlDuelingDqnAgent</li>
</ul>
<h4 id="class-variables_3">Class variables</h4>
<div class="codehilite"><pre><span></span><span class="n">DQNAgentWrapper</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">DqnCallback</span>
</pre></div>


<h4 id="methods_5">Methods</h4>
<h5 id="log_4">log</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span>
</pre></div>


<p>Logs msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">log</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">log_msg</span>: <span class="nv">str</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Logs msg.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_monitor_env</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="nv">log_msg</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_log</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span>, <span class="nv">log_msg</span><span class="o">=</span><span class="nv">log_msg</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="log_api_4">log_api</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log_api</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">api_target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Logs a call to api_target with additional log_msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">log_api</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">api_target</span>: <span class="nv">str</span>, <span class="nv">log_msg</span>: <span class="nv">Optional</span>[<span class="nv">str</span>] <span class="o">=</span> <span class="nv">None</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Logs a call to api_target with additional log_msg.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_monitor_env</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="nv">api_target</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">api_target</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">if</span> <span class="nv">log_msg</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_api_log</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span>, <span class="nv">api_target</span>, <span class="nv">log_msg</span><span class="o">=</span><span class="nv">log_msg</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_begin_4">on_play_episode_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Env</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the beginning of a new episode</p>
<p>Args:
    env: the gym environment used to play the episode.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">env</span>: <span class="nv">gym</span>.<span class="nv">core</span>.<span class="nv">Env</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by play_implementation at the beginning of a new episode</span>

        <span class="nv">Args</span>:

            <span class="nv">env</span>: <span class="nv">the</span> <span class="nv">gym</span> <span class="nv">environment</span> <span class="nv">used</span> <span class="nv">to</span> <span class="nv">play</span> <span class="nv">the</span> <span class="nv">episode</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">env</span>, <span class="s2">&quot;</span><span class="s">env not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">isinstance</span><span class="ss">(</span><span class="nv">env</span>, <span class="nv">gym</span>.<span class="nv">core</span>.<span class="nv">Env</span><span class="ss">)</span>, <span class="s2">&quot;</span><span class="s">env not an an instance of gym.Env.</span><span class="s2">&quot;</span>

        <span class="nv">pc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">play</span>

        <span class="nv">pc</span>.<span class="nv">gym_env</span> <span class="o">=</span> <span class="nv">env</span>

        <span class="nv">pc</span>.<span class="nv">steps_done_in_episode</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nv">pc</span>.<span class="nv">actions</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> []

        <span class="nv">pc</span>.<span class="nv">rewards</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> []

        <span class="nv">pc</span>.<span class="nv">sum_of_rewards</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_end_4">on_play_episode_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_end</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the end of an episode</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_play_episode_end</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by play_implementation at the end of an episode</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">pc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">play</span>

        <span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nv">pc</span>.<span class="nv">num_episodes</span> <span class="nv">and</span> <span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">&gt;=</span> <span class="nv">pc</span>.<span class="nv">num_episodes</span>:

            <span class="nv">pc</span>.<span class="nv">play_done</span> <span class="o">=</span> <span class="nv">True</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_play_episode_end</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_begin_4">on_train_iteration_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_begin</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the begining of a new iteration</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_train_iteration_begin</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by train_implementation at the begining of a new iteration</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">tc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">train</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nv">tc</span>.<span class="nv">steps_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">==</span> <span class="mi">0</span>:

            <span class="nv">self</span>.<span class="nv">_eval_current_policy</span><span class="ss">()</span>

        <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_totals</span>.<span class="nv">episodes_done</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_end_4">on_train_iteration_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the end of an iteration</p>
<p>Evaluates the current policy. Use kwargs to set additional dict values in train context.
Eg for an ActorCriticTrainContext the losses may be set like this:
    on_train_iteration(loss=123,actor_loss=456,critic_loss=789)</p>
<p>Args:
    loss: loss after the training of the model in this iteration or math.nan if the loss is not available
    **kwargs: if a keyword matches a dict property of the TrainContext instance, then
                the dict[episodes_done_in_training] is set to the arg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">loss</span>: <span class="nv">float</span>, <span class="o">**</span><span class="nv">kwargs</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by train_implementation at the end of an iteration</span>

        <span class="nv">Evaluates</span> <span class="nv">the</span> <span class="nv">current</span> <span class="nv">policy</span>. <span class="nv">Use</span> <span class="nv">kwargs</span> <span class="nv">to</span> <span class="nv">set</span> <span class="nv">additional</span> <span class="nv">dict</span> <span class="nv">values</span> <span class="nv">in</span> <span class="nv">train</span> <span class="nv">context</span>.

        <span class="nv">Eg</span> <span class="k">for</span> <span class="nv">an</span> <span class="nv">ActorCriticTrainContext</span> <span class="nv">the</span> <span class="nv">losses</span> <span class="nv">may</span> <span class="nv">be</span> <span class="nv">set</span> <span class="nv">like</span> <span class="nv">this</span>:

            <span class="nv">on_train_iteration</span><span class="ss">(</span><span class="nv">loss</span><span class="o">=</span><span class="mi">123</span>,<span class="nv">actor_loss</span><span class="o">=</span><span class="mi">456</span>,<span class="nv">critic_loss</span><span class="o">=</span><span class="mi">789</span><span class="ss">)</span>

        <span class="nv">Args</span>:

            <span class="nv">loss</span>: <span class="nv">loss</span> <span class="nv">after</span> <span class="nv">the</span> <span class="nv">training</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">model</span> <span class="nv">in</span> <span class="nv">this</span> <span class="nv">iteration</span> <span class="nv">or</span> <span class="nv">math</span>.<span class="nv">nan</span> <span class="k">if</span> <span class="nv">the</span> <span class="nv">loss</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">available</span>

            <span class="o">**</span><span class="nv">kwargs</span>: <span class="k">if</span> <span class="nv">a</span> <span class="nv">keyword</span> <span class="nv">matches</span> <span class="nv">a</span> <span class="nv">dict</span> <span class="nv">property</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">TrainContext</span> <span class="nv">instance</span>, <span class="k">then</span>

                        <span class="nv">the</span> <span class="nv">dict</span>[<span class="nv">episodes_done_in_training</span>] <span class="nv">is</span> <span class="nv">set</span> <span class="nv">to</span> <span class="nv">the</span> <span class="nv">arg</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">tc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">train</span>

        <span class="nv">totals</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_totals</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span> <span class="o">=</span> <span class="ss">(</span><span class="nv">totals</span>.<span class="nv">episodes_done</span> <span class="o">-</span> <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span><span class="ss">)</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span> <span class="o">+=</span> <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span>

        <span class="nv">tc</span>.<span class="nv">loss</span>[<span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span>] <span class="o">=</span> <span class="nv">loss</span>

        # <span class="nv">set</span> <span class="nv">traincontext</span> <span class="nv">dict</span> <span class="nv">from</span> <span class="nv">kwargs</span>:

        <span class="k">for</span> <span class="nv">prop_name</span> <span class="nv">in</span> <span class="nv">kwargs</span>:

            <span class="nv">prop_instance</span> <span class="o">=</span> <span class="nv">getattr</span><span class="ss">(</span><span class="nv">tc</span>, <span class="nv">prop_name</span>, <span class="nv">None</span><span class="ss">)</span>

            <span class="nv">prop_value</span> <span class="o">=</span> <span class="nv">kwargs</span>[<span class="nv">prop_name</span>]

            <span class="k">if</span> <span class="nv">prop_instance</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span> <span class="nv">and</span> <span class="nv">isinstance</span><span class="ss">(</span><span class="nv">prop_instance</span>, <span class="nv">dict</span><span class="ss">)</span>:

                <span class="nv">prop_instance</span>[<span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span>] <span class="o">=</span> <span class="nv">prop_value</span>

        <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">num_iterations</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span>:

            <span class="nv">tc</span>.<span class="nv">training_done</span> <span class="o">=</span> <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">&gt;=</span> <span class="nv">tc</span>.<span class="nv">num_iterations</span>

        <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">num_iterations_between_eval</span> <span class="nv">and</span> <span class="ss">(</span><span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">%</span> <span class="nv">tc</span>.<span class="nv">num_iterations_between_eval</span> <span class="o">==</span> <span class="mi">0</span><span class="ss">)</span>:

            <span class="nv">self</span>.<span class="nv">_eval_current_policy</span><span class="ss">()</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="play_4">play</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to play_implementation overriden by the subclass.</p>
<p>Args:
    play_context: play configuration to be used
    callbacks: list of callbacks called during play.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">play</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">play_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">PlayContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to play_implementation overriden by the subclass.</span>

<span class="ss">            Args:</span>

<span class="ss">                play_context: play configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during play.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">play_context</span><span class="p">,</span> <span class="ss">&quot;play_context not set&quot;</span>

        <span class="n">assert</span> <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="k">is</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;play_context already set in agent_context&quot;</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="n">play_context</span>

        <span class="n">old_callbacks</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">play_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">old_callbacks</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="play_implementation_4">play_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of playing a single episodes with the current policy.</p>
<p>Args:
    play_context: play configuration to be used</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">play_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">play_context</span>: <span class="nv">core</span>.<span class="nv">PlayContext</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Agent specific implementation of playing a single episodes with the current policy.</span>

            <span class="nv">Args</span>:

                <span class="nv">play_context</span>: <span class="nv">play</span> <span class="nv">configuration</span> <span class="nv">to</span> <span class="nv">be</span> <span class="nv">used</span>

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">play_context</span>, <span class="s2">&quot;</span><span class="s">play_context not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">self</span>.<span class="nv">_agent</span>, <span class="s2">&quot;</span><span class="s">_agent not set. call train() first.</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="k">while</span> <span class="nv">True</span>:

            <span class="nv">self</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">env</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_play_env</span><span class="ss">)</span>

            <span class="nv">observation</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">reset</span><span class="ss">()</span>

            <span class="nv">done</span> <span class="o">=</span> <span class="nv">False</span>

            <span class="k">while</span> <span class="nv">not</span> <span class="nv">done</span>:

                <span class="nv">action</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">forward</span><span class="ss">(</span><span class="nv">observation</span><span class="ss">)</span>

                <span class="nv">observation</span>, <span class="nv">reward</span>, <span class="nv">done</span>, <span class="nv">info</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">step</span><span class="ss">(</span><span class="nv">action</span><span class="ss">)</span>

            <span class="nv">self</span>.<span class="nv">on_play_episode_end</span><span class="ss">()</span>

            <span class="k">if</span> <span class="nv">play_context</span>.<span class="nv">play_done</span>:

                <span class="k">break</span>
</pre></div>


</details>
<h5 id="train_4">train</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to train_implementation overriden by the subclass</p>
<p>Args:
    train_context: training configuration to be used
    callbacks: list of callbacks called during the training and evaluation.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">train</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">TrainContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to train_implementation overriden by the subclass</span>

<span class="ss">            Args:</span>

<span class="ss">                train_context: training configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during the training and evaluation.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">train_context</span><span class="p">,</span> <span class="ss">&quot;train_context not set&quot;</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train_context</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="k">self</span><span class="p">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;backend_name&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;{self._backend_name}&#39;</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_set_seed</span><span class="p">()</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">train_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="train_implementation_4">train_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">StepsTrainContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of the train loop.</p>
<p>The implementation should have the form:</p>
<p>while True:
    on_iteration_begin
    for e in num_episodes_per_iterations
        play episode and record steps (while steps_in_episode &lt; max_steps_per_episode and)
    train policy for num_epochs_per_iteration epochs
    on_iteration_end( loss )
    if training_done
        break</p>
<p>Args:
    train_context: context configuring the train loop</p>
<p>Hints:
o the subclasses training loss is passed through to BackendAgent by on_iteration_end.
  Thus the subclass must not add the experienced loss to the TrainContext.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">train_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">train_context</span>: <span class="nv">core</span>.<span class="nv">StepsTrainContext</span><span class="ss">)</span>:

        <span class="nv">assert</span> <span class="nv">train_context</span>

        <span class="nv">dc</span>: <span class="nv">core</span>.<span class="nv">StepsTrainContext</span> <span class="o">=</span> <span class="nv">train_context</span>

        <span class="nv">train_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="nv">keras_model</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_model</span><span class="ss">(</span><span class="nv">gym_env</span><span class="o">=</span><span class="nv">train_env</span>, <span class="nv">activation</span><span class="o">=</span><span class="s1">&#39;</span><span class="s">linear</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">SequentialMemory</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(limit={dc.max_steps_in_buffer}, window_length=1)</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">memory</span> <span class="o">=</span> <span class="nv">SequentialMemory</span><span class="ss">(</span><span class="nv">limit</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">max_steps_in_buffer</span>, <span class="nv">window_length</span><span class="o">=</span><span class="mi">1</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">BoltzmannQPolicy</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">()</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">policy</span> <span class="o">=</span> <span class="nv">BoltzmannQPolicy</span><span class="ss">()</span>

        <span class="nv">num_actions</span> <span class="o">=</span> <span class="nv">train_env</span>.<span class="nv">action_space</span>.<span class="nv">n</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">DQNAgent</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(nb_actions={num_actions}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">enable_double_dqn={self._enable_double_dqn}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">enable_dueling_network={self._enable_dueling_network}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">nb_steps_warmup={dc.num_steps_buffer_preload}, target_model_update=1e-2,</span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">gamma={dc.reward_discount_gamma}, batch_size={dc.num_steps_sampled_from_buffer}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">train_interval={dc.num_steps_per_iteration}, model=..., memory=..., policy=...)</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span> <span class="o">=</span> <span class="nv">KerasRlDqnAgent</span>.<span class="nv">DQNAgentWrapper</span><span class="ss">(</span>

            <span class="nv">enable_double_dqn</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_enable_double_dqn</span>,

            <span class="nv">enable_dueling_network</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_enable_dueling_network</span>,

            <span class="nv">model</span><span class="o">=</span><span class="nv">keras_model</span>,

            <span class="nv">nb_actions</span><span class="o">=</span><span class="nv">num_actions</span>,

            <span class="nv">memory</span><span class="o">=</span><span class="nv">memory</span>,

            <span class="nv">nb_steps_warmup</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">num_steps_buffer_preload</span>,

            <span class="nv">target_model_update</span><span class="o">=</span><span class="mi">1</span><span class="nv">e</span><span class="o">-</span><span class="mi">2</span>,

            <span class="nv">gamma</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">reward_discount_gamma</span>,

            <span class="nv">batch_size</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">num_steps_sampled_from_buffer</span>,

            <span class="nv">train_interval</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">num_steps_per_iteration</span>,

            <span class="nv">policy</span><span class="o">=</span><span class="nv">policy</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">agent.compile</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(Adam(lr=1e-3), metrics=[&quot;mae&quot;]</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">compile</span><span class="ss">(</span><span class="nv">Adam</span><span class="ss">(</span><span class="nv">lr</span><span class="o">=</span><span class="mi">1</span><span class="nv">e</span><span class="o">-</span><span class="mi">3</span><span class="ss">)</span>, <span class="nv">metrics</span><span class="o">=</span>[<span class="s1">&#39;</span><span class="s">mae</span><span class="s1">&#39;</span>]<span class="ss">)</span>

        <span class="nv">num_steps</span> <span class="o">=</span> <span class="nv">dc</span>.<span class="nv">num_iterations</span> <span class="o">*</span> <span class="nv">dc</span>.<span class="nv">num_steps_per_iteration</span>

        <span class="nv">loss_metric_idx</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="s1">&#39;</span><span class="s">loss</span><span class="s1">&#39;</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">metrics_names</span>:

            <span class="nv">loss_metric_idx</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">metrics_names</span>.<span class="nv">index</span><span class="ss">(</span><span class="s2">&quot;</span><span class="s">loss</span><span class="s2">&quot;</span><span class="ss">)</span>

        <span class="nv">dqn_callback</span> <span class="o">=</span> <span class="nv">KerasRlDqnAgent</span>.<span class="nv">DqnCallback</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">dc</span>, <span class="nv">loss_metric_idx</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">()</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">agent.fit</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(train_env, nb_steps={num_steps})</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">fit</span><span class="ss">(</span><span class="nv">train_env</span>, <span class="nv">nb_steps</span><span class="o">=</span><span class="nv">num_steps</span>, <span class="nv">visualize</span><span class="o">=</span><span class="nv">False</span>, <span class="nv">verbose</span><span class="o">=</span><span class="mi">0</span>, <span class="nv">callbacks</span><span class="o">=</span>[<span class="nv">dqn_callback</span>]<span class="ss">)</span>

        <span class="k">if</span> <span class="nv">not</span> <span class="nv">dc</span>.<span class="nv">training_done</span>:

            <span class="nv">self</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">math</span>.<span class="nv">nan</span><span class="ss">)</span>
</pre></div>


</details>
<h3 id="kerasrlduelingdqnagent">KerasRlDuelingDqnAgent</h3>
<div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">KerasRlDuelingDqnAgent</span><span class="p">(</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">ModelConfig</span>
<span class="p">)</span>
</pre></div>


<p>Keras-rl implementation of the algorithm described in https://arxiv.org/abs/1511.06581 </p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><span class="k">class</span> <span class="n">KerasRlDuelingDqnAgent</span>(<span class="n">KerasRlDqnAgent</span>):

    <span class="s">&quot;&quot;&quot;Keras-rl implementation of the algorithm described in https://arxiv.org/abs/1511.06581 &quot;&quot;&quot;</span>

    <span class="n">def</span> <span class="n">__init__</span>(<span class="k">self</span>, <span class="n">model_config:</span> <span class="n">core</span>.<span class="n">ModelConfig</span>):

        <span class="s">&quot;&quot;&quot; creates a new agent based on the DQN algorithm using the keras-rl implementation.</span>

<span class="s">            Args:</span>

<span class="s">                model_config: the model configuration including the name of the target gym environment</span>

<span class="s">                    as well as the neural network architecture.</span>

<span class="s">                enable_double_dqn:</span>

<span class="s">        &quot;&quot;&quot;</span>

        <span class="n">super</span>().<span class="n">__init__</span>(<span class="n">model_config</span>=<span class="n">model_config</span>, <span class="n">enable_dueling_dqn</span>=<span class="nb">True</span>)
</pre></div>


</details>
<hr />
<h4 id="ancestors-in-mro_6">Ancestors (in MRO)</h4>
<ul>
<li>easyagents.backends.kerasrl.KerasRlDqnAgent</li>
<li>easyagents.backends.kerasrl.KerasRlAgent</li>
<li>easyagents.backends.core.BackendAgent</li>
<li>easyagents.backends.core._BackendAgent</li>
<li>abc.ABC</li>
</ul>
<h4 id="class-variables_4">Class variables</h4>
<div class="codehilite"><pre><span></span><span class="n">DQNAgentWrapper</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="n">DqnCallback</span>
</pre></div>


<h4 id="methods_6">Methods</h4>
<h5 id="log_5">log</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="nb">str</span>
<span class="p">)</span>
</pre></div>


<p>Logs msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">log</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">log_msg</span>: <span class="nv">str</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Logs msg.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_monitor_env</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="nv">log_msg</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_log</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span>, <span class="nv">log_msg</span><span class="o">=</span><span class="nv">log_msg</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="log_api_5">log_api</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">log_api</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">api_target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">log_msg</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>
</pre></div>


<p>Logs a call to api_target with additional log_msg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">log_api</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">api_target</span>: <span class="nv">str</span>, <span class="nv">log_msg</span>: <span class="nv">Optional</span>[<span class="nv">str</span>] <span class="o">=</span> <span class="nv">None</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Logs a call to api_target with additional log_msg.</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_monitor_env</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="nv">api_target</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">api_target</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">if</span> <span class="nv">log_msg</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">log_msg</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_api_log</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span>, <span class="nv">api_target</span>, <span class="nv">log_msg</span><span class="o">=</span><span class="nv">log_msg</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_begin_5">on_play_episode_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_begin</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Env</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the beginning of a new episode</p>
<p>Args:
    env: the gym environment used to play the episode.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">env</span>: <span class="nv">gym</span>.<span class="nv">core</span>.<span class="nv">Env</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by play_implementation at the beginning of a new episode</span>

        <span class="nv">Args</span>:

            <span class="nv">env</span>: <span class="nv">the</span> <span class="nv">gym</span> <span class="nv">environment</span> <span class="nv">used</span> <span class="nv">to</span> <span class="nv">play</span> <span class="nv">the</span> <span class="nv">episode</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">env</span>, <span class="s2">&quot;</span><span class="s">env not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">isinstance</span><span class="ss">(</span><span class="nv">env</span>, <span class="nv">gym</span>.<span class="nv">core</span>.<span class="nv">Env</span><span class="ss">)</span>, <span class="s2">&quot;</span><span class="s">env not an an instance of gym.Env.</span><span class="s2">&quot;</span>

        <span class="nv">pc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">play</span>

        <span class="nv">pc</span>.<span class="nv">gym_env</span> <span class="o">=</span> <span class="nv">env</span>

        <span class="nv">pc</span>.<span class="nv">steps_done_in_episode</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nv">pc</span>.<span class="nv">actions</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> []

        <span class="nv">pc</span>.<span class="nv">rewards</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> []

        <span class="nv">pc</span>.<span class="nv">sum_of_rewards</span>[<span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+</span> <span class="mi">1</span>] <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_play_episode_end_5">on_play_episode_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_play_episode_end</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by play_implementation at the end of an episode</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_play_episode_end</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by play_implementation at the end of an episode</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">pc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">play</span>

        <span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nv">pc</span>.<span class="nv">num_episodes</span> <span class="nv">and</span> <span class="nv">pc</span>.<span class="nv">episodes_done</span> <span class="o">&gt;=</span> <span class="nv">pc</span>.<span class="nv">num_episodes</span>:

            <span class="nv">pc</span>.<span class="nv">play_done</span> <span class="o">=</span> <span class="nv">True</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_play_episode_end</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_begin_5">on_train_iteration_begin</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_begin</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the begining of a new iteration</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_train_iteration_begin</span><span class="ss">(</span><span class="nv">self</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by train_implementation at the begining of a new iteration</span><span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">tc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">train</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="nv">tc</span>.<span class="nv">steps_done_in_iteration</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">==</span> <span class="mi">0</span>:

            <span class="nv">self</span>.<span class="nv">_eval_current_policy</span><span class="ss">()</span>

        <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_totals</span>.<span class="nv">episodes_done</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="on_train_iteration_end_5">on_train_iteration_end</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">on_train_iteration_end</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</pre></div>


<p>Must be called by train_implementation at the end of an iteration</p>
<p>Evaluates the current policy. Use kwargs to set additional dict values in train context.
Eg for an ActorCriticTrainContext the losses may be set like this:
    on_train_iteration(loss=123,actor_loss=456,critic_loss=789)</p>
<p>Args:
    loss: loss after the training of the model in this iteration or math.nan if the loss is not available
    **kwargs: if a keyword matches a dict property of the TrainContext instance, then
                the dict[episodes_done_in_training] is set to the arg.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">loss</span>: <span class="nv">float</span>, <span class="o">**</span><span class="nv">kwargs</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Must be called by train_implementation at the end of an iteration</span>

        <span class="nv">Evaluates</span> <span class="nv">the</span> <span class="nv">current</span> <span class="nv">policy</span>. <span class="nv">Use</span> <span class="nv">kwargs</span> <span class="nv">to</span> <span class="nv">set</span> <span class="nv">additional</span> <span class="nv">dict</span> <span class="nv">values</span> <span class="nv">in</span> <span class="nv">train</span> <span class="nv">context</span>.

        <span class="nv">Eg</span> <span class="k">for</span> <span class="nv">an</span> <span class="nv">ActorCriticTrainContext</span> <span class="nv">the</span> <span class="nv">losses</span> <span class="nv">may</span> <span class="nv">be</span> <span class="nv">set</span> <span class="nv">like</span> <span class="nv">this</span>:

            <span class="nv">on_train_iteration</span><span class="ss">(</span><span class="nv">loss</span><span class="o">=</span><span class="mi">123</span>,<span class="nv">actor_loss</span><span class="o">=</span><span class="mi">456</span>,<span class="nv">critic_loss</span><span class="o">=</span><span class="mi">789</span><span class="ss">)</span>

        <span class="nv">Args</span>:

            <span class="nv">loss</span>: <span class="nv">loss</span> <span class="nv">after</span> <span class="nv">the</span> <span class="nv">training</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">model</span> <span class="nv">in</span> <span class="nv">this</span> <span class="nv">iteration</span> <span class="nv">or</span> <span class="nv">math</span>.<span class="nv">nan</span> <span class="k">if</span> <span class="nv">the</span> <span class="nv">loss</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">available</span>

            <span class="o">**</span><span class="nv">kwargs</span>: <span class="k">if</span> <span class="nv">a</span> <span class="nv">keyword</span> <span class="nv">matches</span> <span class="nv">a</span> <span class="nv">dict</span> <span class="nv">property</span> <span class="nv">of</span> <span class="nv">the</span> <span class="nv">TrainContext</span> <span class="nv">instance</span>, <span class="k">then</span>

                        <span class="nv">the</span> <span class="nv">dict</span>[<span class="nv">episodes_done_in_training</span>] <span class="nv">is</span> <span class="nv">set</span> <span class="nv">to</span> <span class="nv">the</span> <span class="nv">arg</span>.

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">tc</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">train</span>

        <span class="nv">totals</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent_context</span>.<span class="nv">gym</span>.<span class="nv">_totals</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span> <span class="o">=</span> <span class="ss">(</span><span class="nv">totals</span>.<span class="nv">episodes_done</span> <span class="o">-</span> <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span><span class="ss">)</span>

        <span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span> <span class="o">+=</span> <span class="nv">tc</span>.<span class="nv">episodes_done_in_iteration</span>

        <span class="nv">tc</span>.<span class="nv">loss</span>[<span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span>] <span class="o">=</span> <span class="nv">loss</span>

        # <span class="nv">set</span> <span class="nv">traincontext</span> <span class="nv">dict</span> <span class="nv">from</span> <span class="nv">kwargs</span>:

        <span class="k">for</span> <span class="nv">prop_name</span> <span class="nv">in</span> <span class="nv">kwargs</span>:

            <span class="nv">prop_instance</span> <span class="o">=</span> <span class="nv">getattr</span><span class="ss">(</span><span class="nv">tc</span>, <span class="nv">prop_name</span>, <span class="nv">None</span><span class="ss">)</span>

            <span class="nv">prop_value</span> <span class="o">=</span> <span class="nv">kwargs</span>[<span class="nv">prop_name</span>]

            <span class="k">if</span> <span class="nv">prop_instance</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span> <span class="nv">and</span> <span class="nv">isinstance</span><span class="ss">(</span><span class="nv">prop_instance</span>, <span class="nv">dict</span><span class="ss">)</span>:

                <span class="nv">prop_instance</span>[<span class="nv">tc</span>.<span class="nv">episodes_done_in_training</span>] <span class="o">=</span> <span class="nv">prop_value</span>

        <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">num_iterations</span> <span class="nv">is</span> <span class="nv">not</span> <span class="nv">None</span>:

            <span class="nv">tc</span>.<span class="nv">training_done</span> <span class="o">=</span> <span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">&gt;=</span> <span class="nv">tc</span>.<span class="nv">num_iterations</span>

        <span class="nv">self</span>.<span class="nv">_train_total_episodes_on_iteration_begin</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nv">tc</span>.<span class="nv">num_iterations_between_eval</span> <span class="nv">and</span> <span class="ss">(</span><span class="nv">tc</span>.<span class="nv">iterations_done_in_training</span> <span class="o">%</span> <span class="nv">tc</span>.<span class="nv">num_iterations_between_eval</span> <span class="o">==</span> <span class="mi">0</span><span class="ss">)</span>:

            <span class="nv">self</span>.<span class="nv">_eval_current_policy</span><span class="ss">()</span>

        <span class="k">for</span> <span class="nv">c</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_callbacks</span>:

            <span class="nv">c</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_agent_context</span><span class="ss">)</span>
</pre></div>


</details>
<h5 id="play_5">play</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to play_implementation overriden by the subclass.</p>
<p>Args:
    play_context: play configuration to be used
    callbacks: list of callbacks called during play.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">play</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">play_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">PlayContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to play_implementation overriden by the subclass.</span>

<span class="ss">            Args:</span>

<span class="ss">                play_context: play configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during play.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">play_context</span><span class="p">,</span> <span class="ss">&quot;play_context not set&quot;</span>

        <span class="n">assert</span> <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="k">is</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;play_context already set in agent_context&quot;</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">play_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="n">play_context</span>

        <span class="n">old_callbacks</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">play_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_play_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">old_callbacks</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="play_implementation_5">play_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">play_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">play_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">PlayContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of playing a single episodes with the current policy.</p>
<p>Args:
    play_context: play configuration to be used</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">play_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">play_context</span>: <span class="nv">core</span>.<span class="nv">PlayContext</span><span class="ss">)</span>:

        <span class="s2">&quot;&quot;&quot;</span><span class="s">Agent specific implementation of playing a single episodes with the current policy.</span>

            <span class="nv">Args</span>:

                <span class="nv">play_context</span>: <span class="nv">play</span> <span class="nv">configuration</span> <span class="nv">to</span> <span class="nv">be</span> <span class="nv">used</span>

        <span class="s2">&quot;&quot;&quot;</span>

        <span class="nv">assert</span> <span class="nv">play_context</span>, <span class="s2">&quot;</span><span class="s">play_context not set.</span><span class="s2">&quot;</span>

        <span class="nv">assert</span> <span class="nv">self</span>.<span class="nv">_agent</span>, <span class="s2">&quot;</span><span class="s">_agent not set. call train() first.</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="nv">is</span> <span class="nv">None</span>:

            <span class="nv">self</span>.<span class="nv">_play_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="k">while</span> <span class="nv">True</span>:

            <span class="nv">self</span>.<span class="nv">on_play_episode_begin</span><span class="ss">(</span><span class="nv">env</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_play_env</span><span class="ss">)</span>

            <span class="nv">observation</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">reset</span><span class="ss">()</span>

            <span class="nv">done</span> <span class="o">=</span> <span class="nv">False</span>

            <span class="k">while</span> <span class="nv">not</span> <span class="nv">done</span>:

                <span class="nv">action</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">forward</span><span class="ss">(</span><span class="nv">observation</span><span class="ss">)</span>

                <span class="nv">observation</span>, <span class="nv">reward</span>, <span class="nv">done</span>, <span class="nv">info</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_play_env</span>.<span class="nv">step</span><span class="ss">(</span><span class="nv">action</span><span class="ss">)</span>

            <span class="nv">self</span>.<span class="nv">on_play_episode_end</span><span class="ss">()</span>

            <span class="k">if</span> <span class="nv">play_context</span>.<span class="nv">play_done</span>:

                <span class="k">break</span>
</pre></div>


</details>
<h5 id="train_5">train</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">TrainContext</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">AgentCallback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>


<p>Forwarding to train_implementation overriden by the subclass</p>
<p>Args:
    train_context: training configuration to be used
    callbacks: list of callbacks called during the training and evaluation.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="n">def</span> <span class="n">train</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">train_context</span><span class="p">:</span> <span class="n">core</span><span class="p">.</span><span class="n">TrainContext</span><span class="p">,</span> <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">core</span><span class="p">.</span><span class="n">AgentCallback</span><span class="p">]):</span>

        <span class="ss">&quot;&quot;&quot;Forwarding to train_implementation overriden by the subclass</span>

<span class="ss">            Args:</span>

<span class="ss">                train_context: training configuration to be used</span>

<span class="ss">                callbacks: list of callbacks called during the training and evaluation.</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="n">assert</span> <span class="n">callbacks</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">,</span> <span class="ss">&quot;callbacks not set&quot;</span>

        <span class="n">assert</span> <span class="n">train_context</span><span class="p">,</span> <span class="ss">&quot;train_context not set&quot;</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_reset</span><span class="p">()</span>

        <span class="n">train_context</span><span class="p">.</span><span class="n">_validate</span><span class="p">()</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train_context</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

        <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="n">callbacks</span>

        <span class="n">try</span><span class="p">:</span>

            <span class="k">self</span><span class="p">.</span><span class="n">log_api</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;backend_name&#39;</span><span class="p">,</span> <span class="n">f</span><span class="s1">&#39;{self._backend_name}&#39;</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_set_seed</span><span class="p">()</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">self</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_begin</span><span class="p">()</span>

            <span class="k">self</span><span class="p">.</span><span class="n">train_implementation</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_on_train_end</span><span class="p">()</span>

        <span class="n">finally</span><span class="p">:</span>

            <span class="n">monitor</span><span class="p">.</span><span class="n">_MonitorEnv</span><span class="p">.</span><span class="n">_register_backend_agent</span><span class="p">(</span><span class="k">None</span><span class="p">)</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_callbacks</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">play</span> <span class="o">=</span> <span class="k">None</span>

            <span class="k">self</span><span class="p">.</span><span class="n">_agent_context</span><span class="p">.</span><span class="n">train</span> <span class="o">=</span> <span class="k">None</span>
</pre></div>


</details>
<h5 id="train_implementation_5">train_implementation</h5>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">train_implementation</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train_context</span><span class="p">:</span> <span class="n">easyagents</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">StepsTrainContext</span>
<span class="p">)</span>
</pre></div>


<p>Agent specific implementation of the train loop.</p>
<p>The implementation should have the form:</p>
<p>while True:
    on_iteration_begin
    for e in num_episodes_per_iterations
        play episode and record steps (while steps_in_episode &lt; max_steps_per_episode and)
    train policy for num_epochs_per_iteration epochs
    on_iteration_end( loss )
    if training_done
        break</p>
<p>Args:
    train_context: context configuring the train loop</p>
<p>Hints:
o the subclasses training loss is passed through to BackendAgent by on_iteration_end.
  Thus the subclass must not add the experienced loss to the TrainContext.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span>    <span class="nv">def</span> <span class="nv">train_implementation</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">train_context</span>: <span class="nv">core</span>.<span class="nv">StepsTrainContext</span><span class="ss">)</span>:

        <span class="nv">assert</span> <span class="nv">train_context</span>

        <span class="nv">dc</span>: <span class="nv">core</span>.<span class="nv">StepsTrainContext</span> <span class="o">=</span> <span class="nv">train_context</span>

        <span class="nv">train_env</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_env</span><span class="ss">()</span>

        <span class="nv">keras_model</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_create_model</span><span class="ss">(</span><span class="nv">gym_env</span><span class="o">=</span><span class="nv">train_env</span>, <span class="nv">activation</span><span class="o">=</span><span class="s1">&#39;</span><span class="s">linear</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">SequentialMemory</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(limit={dc.max_steps_in_buffer}, window_length=1)</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">memory</span> <span class="o">=</span> <span class="nv">SequentialMemory</span><span class="ss">(</span><span class="nv">limit</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">max_steps_in_buffer</span>, <span class="nv">window_length</span><span class="o">=</span><span class="mi">1</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">BoltzmannQPolicy</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">()</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">policy</span> <span class="o">=</span> <span class="nv">BoltzmannQPolicy</span><span class="ss">()</span>

        <span class="nv">num_actions</span> <span class="o">=</span> <span class="nv">train_env</span>.<span class="nv">action_space</span>.<span class="nv">n</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">DQNAgent</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(nb_actions={num_actions}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">enable_double_dqn={self._enable_double_dqn}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">enable_dueling_network={self._enable_dueling_network}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">nb_steps_warmup={dc.num_steps_buffer_preload}, target_model_update=1e-2,</span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">gamma={dc.reward_discount_gamma}, batch_size={dc.num_steps_sampled_from_buffer}, </span><span class="s1">&#39;</span> <span class="o">+</span>

                     <span class="nv">f</span><span class="s1">&#39;</span><span class="s">train_interval={dc.num_steps_per_iteration}, model=..., memory=..., policy=...)</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span> <span class="o">=</span> <span class="nv">KerasRlDqnAgent</span>.<span class="nv">DQNAgentWrapper</span><span class="ss">(</span>

            <span class="nv">enable_double_dqn</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_enable_double_dqn</span>,

            <span class="nv">enable_dueling_network</span><span class="o">=</span><span class="nv">self</span>.<span class="nv">_enable_dueling_network</span>,

            <span class="nv">model</span><span class="o">=</span><span class="nv">keras_model</span>,

            <span class="nv">nb_actions</span><span class="o">=</span><span class="nv">num_actions</span>,

            <span class="nv">memory</span><span class="o">=</span><span class="nv">memory</span>,

            <span class="nv">nb_steps_warmup</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">num_steps_buffer_preload</span>,

            <span class="nv">target_model_update</span><span class="o">=</span><span class="mi">1</span><span class="nv">e</span><span class="o">-</span><span class="mi">2</span>,

            <span class="nv">gamma</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">reward_discount_gamma</span>,

            <span class="nv">batch_size</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">num_steps_sampled_from_buffer</span>,

            <span class="nv">train_interval</span><span class="o">=</span><span class="nv">dc</span>.<span class="nv">num_steps_per_iteration</span>,

            <span class="nv">policy</span><span class="o">=</span><span class="nv">policy</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">agent.compile</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(Adam(lr=1e-3), metrics=[&quot;mae&quot;]</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">compile</span><span class="ss">(</span><span class="nv">Adam</span><span class="ss">(</span><span class="nv">lr</span><span class="o">=</span><span class="mi">1</span><span class="nv">e</span><span class="o">-</span><span class="mi">3</span><span class="ss">)</span>, <span class="nv">metrics</span><span class="o">=</span>[<span class="s1">&#39;</span><span class="s">mae</span><span class="s1">&#39;</span>]<span class="ss">)</span>

        <span class="nv">num_steps</span> <span class="o">=</span> <span class="nv">dc</span>.<span class="nv">num_iterations</span> <span class="o">*</span> <span class="nv">dc</span>.<span class="nv">num_steps_per_iteration</span>

        <span class="nv">loss_metric_idx</span> <span class="o">=</span> <span class="nv">None</span>

        <span class="k">if</span> <span class="s1">&#39;</span><span class="s">loss</span><span class="s1">&#39;</span> <span class="nv">in</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">metrics_names</span>:

            <span class="nv">loss_metric_idx</span> <span class="o">=</span> <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">metrics_names</span>.<span class="nv">index</span><span class="ss">(</span><span class="s2">&quot;</span><span class="s">loss</span><span class="s2">&quot;</span><span class="ss">)</span>

        <span class="nv">dqn_callback</span> <span class="o">=</span> <span class="nv">KerasRlDqnAgent</span>.<span class="nv">DqnCallback</span><span class="ss">(</span><span class="nv">self</span>, <span class="nv">dc</span>, <span class="nv">loss_metric_idx</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">on_train_iteration_begin</span><span class="ss">()</span>

        <span class="nv">self</span>.<span class="nv">log_api</span><span class="ss">(</span><span class="nv">f</span><span class="s1">&#39;</span><span class="s">agent.fit</span><span class="s1">&#39;</span>, <span class="nv">f</span><span class="s1">&#39;</span><span class="s">(train_env, nb_steps={num_steps})</span><span class="s1">&#39;</span><span class="ss">)</span>

        <span class="nv">self</span>.<span class="nv">_agent</span>.<span class="nv">fit</span><span class="ss">(</span><span class="nv">train_env</span>, <span class="nv">nb_steps</span><span class="o">=</span><span class="nv">num_steps</span>, <span class="nv">visualize</span><span class="o">=</span><span class="nv">False</span>, <span class="nv">verbose</span><span class="o">=</span><span class="mi">0</span>, <span class="nv">callbacks</span><span class="o">=</span>[<span class="nv">dqn_callback</span>]<span class="ss">)</span>

        <span class="k">if</span> <span class="nv">not</span> <span class="nv">dc</span>.<span class="nv">training_done</span>:

            <span class="nv">self</span>.<span class="nv">on_train_iteration_end</span><span class="ss">(</span><span class="nv">math</span>.<span class="nv">nan</span><span class="ss">)</span>
</pre></div>


</details>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../core/" title="Core" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Core
              </span>
            </div>
          </a>
        
        
          <a href="../tfagents/" title="Tfagents" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Tfagents
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Powered by
        <a href="http://timothycrosley.github.io/portray">portray.</a>
        You too can
        <a href="http://timothycrosley.github.io/portray">
          portray</a>
        your Python project well using automatic documentation.
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../../assets/javascripts/application.ac79c3b0.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../../../.."}})</script>
      
    
  </body>
</html>