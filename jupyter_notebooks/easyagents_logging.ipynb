{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/christianhidber/easyagents/blob/master/jupyter_notebooks/easyagents_logging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Investigating an agent api through logging, seeding & fixing juypter output cell clearing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Install packages (gym, tfagents, tensorflow,....)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### suppress package warnings, in colab: load additional packages for rendering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "if 'google.colab' in sys.modules:\n",
    "    !apt-get install xvfb >/dev/null\n",
    "    !pip install pyvirtualdisplay >/dev/null    \n",
    "    \n",
    "    from pyvirtualdisplay import Display\n",
    "    Display(visible=0, size=(960, 720)).start() \n",
    "else:\n",
    "    #  for local installation\n",
    "    sys.path.append('..')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### install easyagents and rendering for orso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -q easyagents >/dev/null\n",
    "    !pip install -q networkx==2.3.0 >/dev/null"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agent logging \n",
    "\n",
    "Use the log.Agent() callback to investigate how easyagents interacts with a backend:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "Using TensorFlow backend.\nbackend_name             tfagents \n",
      "TFPyEnvironment          ( suite_gym.load( ... ) ) \n",
      "AdamOptimizer            () \n",
      "ActorDistributionNetwork () \n",
      "ValueNetwork             () \n",
      "PpoAgent                 () \n",
      "tf_agent.initialize      () \n",
      "TFUniformReplayBuffer    () \n",
      "DynamicEpisodeDriver     () \n",
      "TFPyEnvironment          ( suite_gym.load( ... ) ) \n",
      "-----                    iteration    0 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=4906.7  [actor=0.0     critic=4906.7 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    1 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=10658.6 [actor=0.0     critic=10658.6] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    2 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=5132.3  [actor=0.1     critic=5132.2 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    3 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=7920.8  [actor=0.0     critic=7920.7 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    4 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=16946.8 [actor=0.0     critic=16946.7] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    5 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=8877.6  [actor=0.0     critic=8877.6 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    6 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=19640.7 [actor=0.0     critic=19640.7] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    7 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=2701.0  [actor=0.0     critic=2701.0 ] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    8 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=11224.1 [actor=0.0     critic=11224.1] \n",
      "replay_buffer.clear      () \n",
      "-----                    iteration    9 of 10        ----- \n",
      "collect_driver.run       () \n",
      "replay_buffer.gather_all () \n",
      "tf_agent.train           (experience=...) \n",
      "                         loss=7043.7  [actor=0.0     critic=7043.7 ] \n",
      "replay_buffer.clear      () \n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:\n\n  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n\n  Please upgrade your code to TensorFlow 2.0:\n    * https://www.tensorflow.org/beta/guide/migration_guide\n\n  Or install the latest stable TensorFlow 1.X release:\n    * `pip install -U \"tensorflow==1.*\"`\n\n  Otherwise your code may be broken by the change.\n\n  \n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorforce\\core\\module.py:31: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.\n\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorforce\\core\\optimizers\\tf_optimizer.py:46: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tf_agents\\specs\\tensor_spec.py:295: SeedStream.__init__ (from tensorflow_probability.python.util.seed_stream) is deprecated and will be removed after 2019-10-01.\nInstructions for updating:\nSeedStream has moved to `tfp.util.SeedStream`.\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tf_agents\\replay_buffers\\tf_uniform_replay_buffer.py:549: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<easyagents.core.PpoTrainContext at 0x21acc8f7a48>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import duration, log\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0')\n",
    "ppoAgent.train([log.Agent(), duration.Fast()], default_plots=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plots clear the jupyter cell ouput before each update thereby clearing the log output as well, thus we turned them off.\n",
    "Typically each call to the backend api during training is logged. \n",
    "Note that the logging starts with 'tfagents' the default backend for the PpoAgent.\n",
    "We then see a sequence of calls performing the Agent initialisation before we enter the train loop.\n",
    "Api calls during play or evaluation are not logged.\n",
    "\n",
    "Let's take a look at the tensorforce backend:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "Using TensorFlow backend.\nbackend_name             tensorforce \n",
      "Creating Environment...  \n",
      "Environment.create       (environment=\"gym\", level=CartPole-v0) \n",
      "Creating network specification...\n",
      "Agent.create             (agent=\"ppo\", environment=..., network=[{'type': 'dense', 'size': 100, 'activation': 'relu'}, {'type': 'dense', 'size': 100, 'activation': 'relu'}]learning_rate=0.001, batch_size=3, optimization_steps=1, discount=1.0) \n",
      "Runner.create            (agent=..., environment=...) \n",
      "runner.run               (num_episodes=None, max_episode_timesteps=50) \n",
      "Environment.create       (environment=\"gym\", level=CartPole-v0) \n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:\n\n  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n\n  Please upgrade your code to TensorFlow 2.0:\n    * https://www.tensorflow.org/beta/guide/migration_guide\n\n  Or install the latest stable TensorFlow 1.X release:\n    * `pip install -U \"tensorflow==1.*\"`\n\n  Otherwise your code may be broken by the change.\n\n  \n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorforce\\core\\module.py:31: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.\n\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorforce\\core\\optimizers\\tf_optimizer.py:46: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorforce\\core\\models\\model.py:694: The name tf.debugging.assert_type is deprecated. Please use tf.compat.v1.debugging.assert_type instead.\n\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorforce\\core\\distributions\\categorical.py:59: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\nInstructions for updating:\n`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.\nInstructions for updating:\nreduction_indices is deprecated, use axis instead\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<easyagents.core.PpoTrainContext at 0x2b4acb78108>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import duration, log\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0', backend='tensorforce')\n",
    "ppoAgent.train([log.Agent(), duration.Fast()], default_plots=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While in tensorforce we also first do a sequence of agent and policy. Note that in contrast to tfagents we do not\n",
    "build up actor and critic policy networks but instead pass a network specification to the Agent.create call.\n",
    "Moreover tensorforce implements already the train loop through its Runner class. \n",
    "Thus we only see 1 call to runner.run instead of the many api calls for tfagents."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Seeding\n",
    "\n",
    "To set a seed use:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "Using TensorFlow backend.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:\n\n  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n\n  Please upgrade your code to TensorFlow 2.0:\n    * https://www.tensorflow.org/beta/guide/migration_guide\n\n  Or install the latest stable TensorFlow 1.X release:\n    * `pip install -U \"tensorflow==1.*\"`\n\n  Otherwise your code may be broken by the change.\n\n  \n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorforce\\core\\module.py:31: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.\n\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorforce\\core\\optimizers\\tf_optimizer.py:46: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import easyagents\n",
    "\n",
    "easyagents.agents.seed = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once set, the seed is applied before each call to train. Let's validate this using our log.Agent callback:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "backend_name             tensorforce \n",
      "tf.compat.v1.set_random_seed(0) \n",
      "tf.random.set_random_seed(seed=0) \n",
      "numpy.random.seed        (0) \n",
      "random.seed              (0) \n",
      "Environment.create       (environment=\"gym\", level=CartPole-v0) \n",
      "Agent.create             (agent=\"ppo\", environment=..., network=[{'type': 'dense', 'size': 100, 'activation': 'relu'}, {'type': 'dense', 'size': 100, 'activation': 'relu'}]learning_rate=0.001, batch_size=3, optimization_steps=1, discount=1.0) \n",
      "Runner.create            (agent=..., environment=...) \n",
      "runner.run               (num_episodes=None, max_episode_timesteps=50) \n",
      "Environment.create       (environment=\"gym\", level=CartPole-v0) \n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Dev\\GitHub\\easyagents\\easyagents\\backends\\core.py:94: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.\n\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorforce\\core\\models\\model.py:694: The name tf.debugging.assert_type is deprecated. Please use tf.compat.v1.debugging.assert_type instead.\n\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorforce\\core\\distributions\\categorical.py:59: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\nInstructions for updating:\n`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.\nInstructions for updating:\nreduction_indices is deprecated, use axis instead\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<easyagents.core.PpoTrainContext at 0x2a14a2c4e88>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    },
    {
     "data": {
      "text/plain": "<Figure size 1224x432 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import duration, log\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0', backend='tensorforce')\n",
    "ppoAgent.train([log.Agent(), duration.Fast()], default_plots=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that at the very beginning the calls to set the seeds for tensorflow, numpy and python.\n",
    "\n",
    "## Gym steps logging\n",
    "Use the log.Step() callback to investigate how the agent interacts with the gym environment:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From c:\\dev\\github\\easyagents\\env\\lib\\site-packages\\tf_agents\\specs\\tensor_spec.py:295: SeedStream.__init__ (from tensorflow_probability.python.util.seed_stream) is deprecated and will be removed after 2019-10-01.\nInstructions for updating:\nSeedStream has moved to `tfp.util.SeedStream`.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[CartPole-v0 3:0  :1  ] train iteration=0  step=0   play  episode=0  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[-0.04363321  0.24146826  0.01284913 -0.30946528]\n",
      "[CartPole-v0 3:0  :2  ] train iteration=0  step=0   play  episode=0  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[-0.03880385  0.04616562  0.00665982 -0.01275795]\n",
      "[CartPole-v0 3:0  :3  ] train iteration=0  step=0   play  episode=0  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[-0.03788053  0.24119143  0.00640466 -0.30333221]\n",
      "[CartPole-v0 3:0  :4  ] train iteration=0  step=0   play  episode=0  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[-0.03305671  0.04597879  0.00033802 -0.0086363 ]\n",
      "[CartPole-v0 3:0  :5  ] train iteration=0  step=0   play  episode=0  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[-3.21371306e-02  2.41095889e-01  1.65294467e-04 -3.01212554e-01]\n",
      "[CartPole-v0 3:0  :6  ] train iteration=0  step=0   play  episode=0  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[-0.02731521  0.04597158 -0.00585896 -0.0084775 ]\n",
      "[CartPole-v0 3:0  :7  ] train iteration=0  step=0   play  episode=0  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[-0.02639578 -0.14906586 -0.00602851  0.28235111]\n",
      "[CartPole-v0 3:0  :8  ] train iteration=0  step=0   play  episode=0  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[-0.0293771   0.04614156 -0.00038148 -0.01222707]\n",
      "[CartPole-v0 3:0  :9  ] train iteration=0  step=0   play  episode=0  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[-0.02845427  0.24126898 -0.00062603 -0.30503033]\n",
      "[CartPole-v0 3:0  :10 ] train iteration=0  step=0   play  episode=0  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[-0.02362889  0.04615596 -0.00672663 -0.0125449 ]\n",
      "[CartPole-v0 3:0  :11 ] train iteration=0  step=0   play  episode=0  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[-0.02270577 -0.14886888 -0.00697753  0.27800812]\n",
      "[CartPole-v0 3:0  :12 ] train iteration=0  step=0   play  episode=0  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[-0.02568315  0.04635191 -0.00141737 -0.01686732]\n",
      "[CartPole-v0 3:0  :13 ] train iteration=0  step=0   play  episode=0  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[-0.02475611 -0.14874968 -0.00175471  0.27536807]\n",
      "[CartPole-v0 3:0  :14 ] train iteration=0  step=0   play  episode=0  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[-0.0277311   0.04639726  0.00375265 -0.01786777]\n",
      "[CartPole-v0 3:0  :15 ] train iteration=0  step=0   play  episode=0  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=0 observation=[-0.02680316 -0.14877831  0.00339529  0.27599679]\n",
      "[CartPole-v0 3:0  :16 ] train iteration=0  step=0   play  episode=0  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=1 observation=[-0.02977872  0.04629504  0.00891523 -0.01561333]\n",
      "[CartPole-v0 3:0  :17 ] train iteration=0  step=0   play  episode=0  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=1 observation=[-0.02885282  0.24128801  0.00860296 -0.30547012]\n",
      "[CartPole-v0 3:0  :18 ] train iteration=0  step=0   play  episode=0  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=0 observation=[-0.02402706  0.04604452  0.00249356 -0.01008649]\n",
      "[CartPole-v0 3:0  :19 ] train iteration=0  step=0   play  episode=0  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=1 observation=[-0.02310617  0.24113063  0.00229183 -0.30198163]\n",
      "[CartPole-v0 3:0  :20 ] train iteration=0  step=0   play  episode=0  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=0 observation=[-0.01828356  0.04597609 -0.0037478  -0.00857679]\n",
      "[CartPole-v0 3:0  :21 ] train iteration=0  step=0   play  episode=0  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[-0.01736404 -0.14909192 -0.00391934  0.28292131]\n",
      "[CartPole-v0 3:0  :22 ] train iteration=0  step=0   play  episode=0  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[-0.02034587  0.04608572  0.00173909 -0.01099517]\n",
      "[CartPole-v0 3:0  :23 ] train iteration=0  step=0   play  episode=0  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[-0.01942416 -0.14906113  0.00151918  0.28223595]\n",
      "[CartPole-v0 3:0  :24 ] train iteration=0  step=0   play  episode=0  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[-0.02240538  0.04603912  0.0071639  -0.00996745]\n",
      "[CartPole-v0 3:0  :25 ] train iteration=0  step=0   play  episode=0  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=1 observation=[-0.0214846   0.2410576   0.00696455 -0.3003815 ]\n",
      "[CartPole-v0 3:0  :26 ] train iteration=0  step=0   play  episode=0  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=0 observation=[-0.01666345  0.04583708  0.00095692 -0.00551025]\n",
      "[CartPole-v0 3:0  :27 ] train iteration=0  step=0   play  episode=0  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[-0.01574671 -0.14929859  0.00084672  0.28747444]\n",
      "[CartPole-v0 3:0  :28 ] train iteration=0  step=0   play  episode=0  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[-0.01873268  0.04581128  0.00659621 -0.00494132]\n",
      "[CartPole-v0 3:0  :29 ] train iteration=0  step=0   play  episode=0  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=1 observation=[-0.01781645  0.24083801  0.00649738 -0.29553578]\n",
      "[CartPole-v0 3:0  :30 ] train iteration=0  step=0   play  episode=0  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=0 observation=[-0.01299969  0.04562404  0.00058667 -0.00081078]\n",
      "[CartPole-v0 3:0  :31 ] train iteration=0  step=0   play  episode=0  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=1 observation=[-0.01208721  0.24073757  0.00057045 -0.29330855]\n",
      "[CartPole-v0 3:0  :32 ] train iteration=0  step=0   play  episode=0  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=0 observation=[-0.00727246  0.04560749 -0.00529572 -0.00044577]\n",
      "[CartPole-v0 3:0  :33 ] train iteration=0  step=0   play  episode=0  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[-0.00636031 -0.14943811 -0.00530464  0.2905616 ]\n",
      "[CartPole-v0 3:0  :34 ] train iteration=0  step=0   play  episode=0  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[-0.00934907  0.04575908  0.0005066  -0.00378962]\n",
      "[CartPole-v0 3:0  :35 ] train iteration=0  step=0   play  episode=0  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[-0.00843389 -0.14937014  0.0004308   0.2890531 ]\n",
      "[CartPole-v0 3:0  :36 ] train iteration=0  step=0   play  episode=0  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=1 observation=[-0.01142129  0.04574567  0.00621186 -0.00349392]\n",
      "[CartPole-v0 3:0  :37 ] train iteration=0  step=0   play  episode=0  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.01050638  0.24077799  0.00614199 -0.29421048]\n",
      "[CartPole-v0 3:0  :38 ] train iteration=0  step=0   play  episode=0  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.00569082  0.04556901  0.00025778  0.0004032 ]\n",
      "[CartPole-v0 3:0  :39 ] train iteration=0  step=0   play  episode=0  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=1 observation=[-4.77944066e-03  2.40687262e-01  2.65840718e-04 -2.92198385e-01]\n",
      "[CartPole-v0 3:0  :40 ] train iteration=0  step=0   play  episode=0  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[ 3.43045783e-05  4.55615213e-02 -5.57812698e-03  5.68372760e-04]\n",
      "[CartPole-v0 3:0  :41 ] train iteration=0  step=0   play  episode=0  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[ 0.00094554 -0.14947999 -0.00556676  0.29148613]\n",
      "[CartPole-v0 3:0  :42 ] train iteration=0  step=0   play  episode=0  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[-0.00204406  0.04572089  0.00026296 -0.00294728]\n",
      "[CartPole-v0 3:0  :43 ] train iteration=0  step=0   play  episode=0  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=0 observation=[-1.12964693e-03 -1.49404829e-01  2.04017434e-04  2.89818605e-01]\n",
      "[CartPole-v0 3:0  :44 ] train iteration=0  step=0   play  episode=0  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=1 observation=[-0.00411774  0.04571421  0.00600039 -0.00279997]\n",
      "[CartPole-v0 3:0  :45 ] train iteration=0  step=0   play  episode=0  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[-0.00320346  0.2407496   0.00594439 -0.29358368]\n",
      "[CartPole-v0 3:0  :46 ] train iteration=0  step=0   play  episode=0  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[1.61153266e-03 4.55434012e-02 7.27166229e-05 9.68084346e-04]\n",
      "[CartPole-v0 3:0  :47 ] train iteration=0  step=0   play  episode=0  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=1 observation=[ 2.52240068e-03  2.40664309e-01  9.20783098e-05 -2.91691899e-01]\n",
      "[CartPole-v0 3:0  :48 ] train iteration=0  step=0   play  episode=0  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=0 observation=[ 0.00733569  0.04554105 -0.00574176  0.00102007]\n",
      "[CartPole-v0 3:0  :49 ] train iteration=0  step=0   play  episode=0  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[ 0.00824651 -0.14949809 -0.00572136  0.29188588]\n",
      "[CartPole-v0 3:1  :50 ] train iteration=0  step=0   play  episode=0  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[ 0.00525655  0.04570497  0.00011636 -0.00259598]\n",
      "[CartPole-v0 3:1  :1  ] train iteration=0  step=0   play  episode=1  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[-0.03940542  0.21258198 -0.01040263 -0.2790682 ]\n",
      "[CartPole-v0 3:1  :2  ] train iteration=0  step=0   play  episode=1  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[-0.03515378  0.01760996 -0.015984    0.01031569]\n",
      "[CartPole-v0 3:1  :3  ] train iteration=0  step=0   play  episode=1  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[-0.03480158  0.21295746 -0.01577768 -0.28736722]\n",
      "[CartPole-v0 3:1  :4  ] train iteration=0  step=0   play  episode=1  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[-0.03054243  0.01806402 -0.02152503  0.0002981 ]\n",
      "[CartPole-v0 3:1  :5  ] train iteration=0  step=0   play  episode=1  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[-0.03018115  0.21348795 -0.02151907 -0.29909776]\n",
      "[CartPole-v0 3:1  :6  ] train iteration=0  step=0   play  episode=1  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[-0.02591139  0.01867924 -0.02750102 -0.01327846]\n",
      "[CartPole-v0 3:1  :7  ] train iteration=0  step=0   play  episode=1  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[-0.02553781 -0.17603773 -0.02776659  0.27060228]\n",
      "[CartPole-v0 3:1  :8  ] train iteration=0  step=0   play  episode=1  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[-0.02905856  0.01946922 -0.02235455 -0.03070743]\n",
      "[CartPole-v0 3:1  :9  ] train iteration=0  step=0   play  episode=1  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=0 observation=[-0.02866918 -0.17532514 -0.02296869  0.25483941]\n",
      "[CartPole-v0 3:1  :10 ] train iteration=0  step=0   play  episode=1  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=1 observation=[-0.03217568  0.0201171  -0.01787191 -0.04499883]\n",
      "[CartPole-v0 3:1  :11 ] train iteration=0  step=0   play  episode=1  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[-0.03177334 -0.17474408 -0.01877188  0.2419922 ]\n",
      "[CartPole-v0 3:1  :12 ] train iteration=0  step=0   play  episode=1  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[-0.03526822  0.02064091 -0.01393204 -0.05655226]\n",
      "[CartPole-v0 3:1  :13 ] train iteration=0  step=0   play  episode=1  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[-0.0348554  -0.17427853 -0.01506308  0.23170265]\n",
      "[CartPole-v0 3:1  :14 ] train iteration=0  step=0   play  episode=1  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[-0.03834097  0.02105538 -0.01042903 -0.06569336]\n",
      "[CartPole-v0 3:1  :15 ] train iteration=0  step=0   play  episode=1  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[-0.03791987  0.21632529 -0.0117429  -0.36164838]\n",
      "[CartPole-v0 3:1  :16 ] train iteration=0  step=0   play  episode=1  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[-0.03359336  0.0213722  -0.01897587 -0.07269124]\n",
      "[CartPole-v0 3:1  :17 ] train iteration=0  step=0   play  episode=1  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[-0.03316592 -0.17347264 -0.02042969  0.21394483]\n",
      "[CartPole-v0 3:1  :18 ] train iteration=0  step=0   play  episode=1  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[-0.03663537  0.02193535 -0.01615079 -0.08511189]\n",
      "[CartPole-v0 3:1  :19 ] train iteration=0  step=0   play  episode=1  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=1 observation=[-0.03619666  0.21728504 -0.01785303 -0.38284634]\n",
      "[CartPole-v0 3:1  :20 ] train iteration=0  step=0   play  episode=1  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=0 observation=[-0.03185096  0.02242107 -0.02550996 -0.09584547]\n",
      "[CartPole-v0 3:1  :21 ] train iteration=0  step=0   play  episode=1  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=1 observation=[-0.03140254  0.21789917 -0.02742687 -0.39646635]\n",
      "[CartPole-v0 3:1  :22 ] train iteration=0  step=0   play  episode=1  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=0 observation=[-0.02704456  0.02317688 -0.03535619 -0.11255524]\n",
      "[CartPole-v0 3:1  :23 ] train iteration=0  step=0   play  episode=1  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=1 observation=[-0.02658102  0.21878714 -0.0376073  -0.41617982]\n",
      "[CartPole-v0 3:1  :24 ] train iteration=0  step=0   play  episode=1  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=0 observation=[-0.02220528  0.0242178  -0.0459309  -0.13558611]\n",
      "[CartPole-v0 3:1  :25 ] train iteration=0  step=0   play  episode=1  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=1 observation=[-0.02172092  0.21996652 -0.04864262 -0.44239846]\n",
      "[CartPole-v0 3:1  :26 ] train iteration=0  step=0   play  episode=1  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=0 observation=[-0.01732159  0.02556542 -0.05749059 -0.16543701]\n",
      "[CartPole-v0 3:1  :27 ] train iteration=0  step=0   play  episode=1  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=1 observation=[-0.01681028  0.2214612  -0.06079933 -0.47568814]\n",
      "[CartPole-v0 3:1  :28 ] train iteration=0  step=0   play  episode=1  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=0 observation=[-0.01238106  0.02724811 -0.07031309 -0.20277076]\n",
      "[CartPole-v0 3:1  :29 ] train iteration=0  step=0   play  episode=1  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[-0.0118361  -0.16680151 -0.07436851  0.06692941]\n",
      "[CartPole-v0 3:1  :30 ] train iteration=0  step=0   play  episode=1  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[-0.01517213  0.02930353 -0.07302992 -0.24825926]\n",
      "[CartPole-v0 3:1  :31 ] train iteration=0  step=0   play  episode=1  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=0 observation=[-0.01458606 -0.1647036  -0.0779951   0.02052402]\n",
      "[CartPole-v0 3:1  :32 ] train iteration=0  step=0   play  episode=1  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=1 observation=[-0.01788013  0.03144522 -0.07758462 -0.29571207]\n",
      "[CartPole-v0 3:1  :33 ] train iteration=0  step=0   play  episode=1  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[-0.01725122 -0.16248988 -0.08349886 -0.0284715 ]\n",
      "[CartPole-v0 3:1  :34 ] train iteration=0  step=0   play  episode=1  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=0 observation=[-0.02050102 -0.3563213  -0.08406829  0.23674252]\n",
      "[CartPole-v0 3:1  :35 ] train iteration=0  step=0   play  episode=1  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=1 observation=[-0.02762745 -0.16010519 -0.07933344 -0.08122918]\n",
      "[CartPole-v0 3:1  :36 ] train iteration=0  step=0   play  episode=1  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=0 observation=[-0.03082955 -0.35400555 -0.08095803  0.18540699]\n",
      "[CartPole-v0 3:1  :37 ] train iteration=0  step=0   play  episode=1  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.03790966 -0.1578242  -0.07724989 -0.13167687]\n",
      "[CartPole-v0 3:1  :38 ] train iteration=0  step=0   play  episode=1  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.04106615 -0.35175947 -0.07988342  0.1356696 ]\n",
      "[CartPole-v0 3:1  :39 ] train iteration=0  step=0   play  episode=1  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=1 observation=[-0.04810133 -0.15558958 -0.07717003 -0.18110763]\n",
      "[CartPole-v0 3:1  :40 ] train iteration=0  step=0   play  episode=1  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[-0.05121313 -0.34952731 -0.08079218  0.08626772]\n",
      "[CartPole-v0 3:1  :41 ] train iteration=0  step=0   play  episode=1  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=1 observation=[-0.05820367 -0.1533458  -0.07906683 -0.23077172]\n",
      "[CartPole-v0 3:1  :42 ] train iteration=0  step=0   play  episode=1  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=0 observation=[-0.06127059 -0.34725412 -0.08368226  0.03596063]\n",
      "[CartPole-v0 3:1  :43 ] train iteration=0  step=0   play  episode=1  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=1 observation=[-0.06821567 -0.15103805 -0.08296305 -0.28190743]\n",
      "[CartPole-v0 3:1  :44 ] train iteration=0  step=0   play  episode=1  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=0 observation=[-0.07123643 -0.34488467 -0.0886012  -0.01650076]\n",
      "[CartPole-v0 3:1  :45 ] train iteration=0  step=0   play  episode=1  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[-0.07813413 -0.14861115 -0.08893122 -0.33577089]\n",
      "[CartPole-v0 3:1  :46 ] train iteration=0  step=0   play  episode=1  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[-0.08110635 -0.34236236 -0.09564663 -0.0724039 ]\n",
      "[CartPole-v0 3:1  :47 ] train iteration=0  step=0   play  episode=1  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=0 observation=[-0.0879536  -0.53599222 -0.09709471  0.18863611]\n",
      "[CartPole-v0 3:1  :48 ] train iteration=0  step=0   play  episode=1  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=1 observation=[-0.09867344 -0.33962492 -0.09332199 -0.13302852]\n",
      "[CartPole-v0 3:1  :49 ] train iteration=0  step=0   play  episode=1  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[-0.10546594 -0.5332948  -0.09598256  0.12881536]\n",
      "[CartPole-v0 3:2  :50 ] train iteration=0  step=0   play  episode=1  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[-0.11613183 -0.33693827 -0.09340625 -0.19253932]\n",
      "[CartPole-v0 3:2  :1  ] train iteration=0  step=0   play  episode=2  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[-0.04396213  0.19844869 -0.04501504 -0.25903102]\n",
      "[CartPole-v0 3:2  :2  ] train iteration=0  step=0   play  episode=2  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[-0.03999315  0.00399731 -0.05019566  0.01912062]\n",
      "[CartPole-v0 3:2  :3  ] train iteration=0  step=0   play  episode=2  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[-0.03991321  0.19980185 -0.04981325 -0.28896758]\n",
      "[CartPole-v0 3:2  :4  ] train iteration=0  step=0   play  episode=2  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[-0.03591717  0.00542432 -0.0555926  -0.01240199]\n",
      "[CartPole-v0 3:2  :5  ] train iteration=0  step=0   play  episode=2  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=0 observation=[-0.03580869 -0.18885812 -0.05584064  0.26223564]\n",
      "[CartPole-v0 3:2  :6  ] train iteration=0  step=0   play  episode=2  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=1 observation=[-0.03958585  0.00701462 -0.05059593 -0.04752413]\n",
      "[CartPole-v0 3:2  :7  ] train iteration=0  step=0   play  episode=2  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[-0.03944556 -0.18734669 -0.05154641  0.22877589]\n",
      "[CartPole-v0 3:2  :8  ] train iteration=0  step=0   play  episode=2  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[-0.04319249  0.00847254 -0.04697089 -0.07971075]\n",
      "[CartPole-v0 3:2  :9  ] train iteration=0  step=0   play  episode=2  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=0 observation=[-0.04302304 -0.1859457  -0.04856511  0.1977906 ]\n",
      "[CartPole-v0 3:2  :10 ] train iteration=0  step=0   play  episode=2  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=1 observation=[-0.04674195  0.00983604 -0.0446093  -0.10980828]\n",
      "[CartPole-v0 3:2  :11 ] train iteration=0  step=0   play  episode=2  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[-0.04654523 -0.18461923 -0.04680546  0.16847366]\n",
      "[CartPole-v0 3:2  :12 ] train iteration=0  step=0   play  episode=2  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[-0.05023762  0.01114035 -0.04343599 -0.1385999 ]\n",
      "[CartPole-v0 3:2  :13 ] train iteration=0  step=0   play  episode=2  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[-0.05001481 -0.18333343 -0.04620799  0.14006947]\n",
      "[CartPole-v0 3:2  :14 ] train iteration=0  step=0   play  episode=2  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[-0.05368148  0.01241882 -0.0434066  -0.16682581]\n",
      "[CartPole-v0 3:2  :15 ] train iteration=0  step=0   play  episode=2  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[-0.0534331   0.20813436 -0.04674311 -0.47288013]\n",
      "[CartPole-v0 3:2  :16 ] train iteration=0  step=0   play  episode=2  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[-0.04927041  0.01370267 -0.05620072 -0.19528861]\n",
      "[CartPole-v0 3:2  :17 ] train iteration=0  step=0   play  episode=2  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[-0.04899636 -0.18057222 -0.06010649  0.0791493 ]\n",
      "[CartPole-v0 3:2  :18 ] train iteration=0  step=0   play  episode=2  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[-0.05260781  0.01535757 -0.0585235  -0.23187532]\n",
      "[CartPole-v0 3:2  :19 ] train iteration=0  step=0   play  episode=2  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[-0.05230065 -0.17888143 -0.06316101  0.04178828]\n",
      "[CartPole-v0 3:2  :20 ] train iteration=0  step=0   play  episode=2  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[-0.05587828  0.0170867  -0.06232524 -0.27013477]\n",
      "[CartPole-v0 3:2  :21 ] train iteration=0  step=0   play  episode=2  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[-0.05553655 -0.17709304 -0.06772794  0.00225755]\n",
      "[CartPole-v0 3:2  :22 ] train iteration=0  step=0   play  episode=2  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[-0.05907841  0.01893157 -0.06768279 -0.31100203]\n",
      "[CartPole-v0 3:2  :23 ] train iteration=0  step=0   play  episode=2  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[-0.05869978 -0.1751641  -0.07390283 -0.04040868]\n",
      "[CartPole-v0 3:2  :24 ] train iteration=0  step=0   play  episode=2  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=0 observation=[-0.06220306 -0.36915276 -0.074711    0.2280724 ]\n",
      "[CartPole-v0 3:2  :25 ] train iteration=0  step=0   play  episode=2  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=1 observation=[-0.06958611 -0.17304706 -0.07014955 -0.08721018]\n",
      "[CartPole-v0 3:2  :26 ] train iteration=0  step=0   play  episode=2  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=0 observation=[-0.07304706 -0.36709702 -0.07189376  0.18254181]\n",
      "[CartPole-v0 3:2  :27 ] train iteration=0  step=0   play  episode=2  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=1 observation=[-0.080389   -0.17102392 -0.06824292 -0.13192664]\n",
      "[CartPole-v0 3:2  :28 ] train iteration=0  step=0   play  episode=2  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=0 observation=[-0.08380947 -0.36510533 -0.07088145  0.13846999]\n",
      "[CartPole-v0 3:2  :29 ] train iteration=0  step=0   play  episode=2  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=1 observation=[-0.09111158 -0.16904352 -0.06811205 -0.17570595]\n",
      "[CartPole-v0 3:2  :30 ] train iteration=0  step=0   play  episode=2  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=0 observation=[-0.09449245 -0.36312793 -0.07162617  0.09473616]\n",
      "[CartPole-v0 3:2  :31 ] train iteration=0  step=0   play  episode=2  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=1 observation=[-0.10175501 -0.16705637 -0.06973145 -0.21965717]\n",
      "[CartPole-v0 3:2  :32 ] train iteration=0  step=0   play  episode=2  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=0 observation=[-0.10509614 -0.36111585 -0.07412459  0.0502402 ]\n",
      "[CartPole-v0 3:2  :33 ] train iteration=0  step=0   play  episode=2  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=1 observation=[-0.11231845 -0.16501361 -0.07311979 -0.2648781 ]\n",
      "[CartPole-v0 3:2  :34 ] train iteration=0  step=0   play  episode=2  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=0 observation=[-0.11561873 -0.35901989 -0.07841735  0.00387565]\n",
      "[CartPole-v0 3:2  :35 ] train iteration=0  step=0   play  episode=2  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=1 observation=[-0.12279912 -0.16286601 -0.07833984 -0.31248207]\n",
      "[CartPole-v0 3:2  :36 ] train iteration=0  step=0   play  episode=2  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=0 observation=[-0.12605645 -0.35678959 -0.08458948 -0.0454972 ]\n",
      "[CartPole-v0 3:2  :37 ] train iteration=0  step=0   play  episode=2  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.13319224 -0.16056295 -0.08549942 -0.3636244 ]\n",
      "[CartPole-v0 3:2  :38 ] train iteration=0  step=0   play  episode=2  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.1364035  -0.35437228 -0.09277191 -0.09907855]\n",
      "[CartPole-v0 3:2  :39 ] train iteration=0  step=0   play  episode=2  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=0 observation=[-0.14349094 -0.54805063 -0.09475348  0.16295386]\n",
      "[CartPole-v0 3:2  :40 ] train iteration=0  step=0   play  episode=2  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=1 observation=[-0.15445195 -0.35170895 -0.09149441 -0.15805342]\n",
      "[CartPole-v0 3:2  :41 ] train iteration=0  step=0   play  episode=2  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[-0.16148613 -0.54540996 -0.09465547  0.10442097]\n",
      "[CartPole-v0 3:2  :42 ] train iteration=0  step=0   play  episode=2  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[-0.17239433 -0.34906794 -0.09256706 -0.21656084]\n",
      "[CartPole-v0 3:2  :43 ] train iteration=0  step=0   play  episode=2  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=0 observation=[-0.17937569 -0.54275306 -0.09689827  0.04554713]\n",
      "[CartPole-v0 3:2  :44 ] train iteration=0  step=0   play  episode=2  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=1 observation=[-0.19023075 -0.34638481 -0.09598733 -0.27606704]\n",
      "[CartPole-v0 3:2  :45 ] train iteration=0  step=0   play  episode=2  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=0 observation=[-0.19715845 -0.54001559 -0.10150867 -0.01513482]\n",
      "[CartPole-v0 3:2  :46 ] train iteration=0  step=0   play  episode=2  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=1 observation=[-0.20795876 -0.34359544 -0.10181137 -0.33804074]\n",
      "[CartPole-v0 3:2  :47 ] train iteration=0  step=0   play  episode=2  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=0 observation=[-0.21483067 -0.53713238 -0.10857218 -0.07911946]\n",
      "[CartPole-v0 3:2  :48 ] train iteration=0  step=0   play  episode=2  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=1 observation=[-0.22557332 -0.34063504 -0.11015457 -0.40398751]\n",
      "[CartPole-v0 3:2  :49 ] train iteration=0  step=0   play  episode=2  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[-0.23238602 -0.53403644 -0.11823432 -0.14796367]\n",
      "[CartPole-v0 3:3  :50 ] train iteration=0  step=0   play  episode=2  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=0 observation=[-0.24306675 -0.72728427 -0.12119359  0.10520436]\n",
      "[CartPole-v0 2:0  :1  ] train iteration=0  step=1    reward=1.0   done=False action=1 observation=[-0.04363321  0.24146826  0.01284913 -0.30946528]\n",
      "[CartPole-v0 2:0  :2  ] train iteration=0  step=2    reward=1.0   done=False action=0 observation=[-0.03880385  0.04616562  0.00665982 -0.01275795]\n",
      "[CartPole-v0 2:0  :3  ] train iteration=0  step=3    reward=1.0   done=False action=0 observation=[-0.03788053 -0.14905121  0.00640466  0.28201876]\n",
      "[CartPole-v0 2:0  :4  ] train iteration=0  step=4    reward=1.0   done=False action=0 observation=[-0.04086156 -0.34426393  0.01204504  0.57671479]\n",
      "[CartPole-v0 2:0  :5  ] train iteration=0  step=5    reward=1.0   done=False action=1 observation=[-0.04774684 -0.14931286  0.02357934  0.28785057]\n",
      "[CartPole-v0 2:0  :6  ] train iteration=0  step=6    reward=1.0   done=False action=0 observation=[-0.05073309 -0.344763    0.02933635  0.58787595]\n",
      "[CartPole-v0 2:0  :7  ] train iteration=0  step=7    reward=1.0   done=False action=1 observation=[-0.05762835 -0.1500639   0.04109387  0.30457661]\n",
      "[CartPole-v0 2:0  :8  ] train iteration=0  step=8    reward=1.0   done=False action=0 observation=[-0.06062963 -0.34574665  0.0471854   0.60993113]\n",
      "[CartPole-v0 2:0  :9  ] train iteration=0  step=9    reward=1.0   done=False action=1 observation=[-0.06754457 -0.15131493  0.05938402  0.33247553]\n",
      "[CartPole-v0 2:0  :10 ] train iteration=0  step=10   reward=1.0   done=False action=0 observation=[-0.07057086 -0.34722964  0.06603353  0.64327823]\n",
      "[CartPole-v0 2:0  :11 ] train iteration=0  step=11   reward=1.0   done=False action=0 observation=[-0.07751546 -0.54320678  0.0788991   0.95600302]\n",
      "[CartPole-v0 2:0  :12 ] train iteration=0  step=12   reward=1.0   done=False action=0 observation=[-0.08837959 -0.73929616  0.09801916  1.27239434]\n",
      "[CartPole-v0 2:0  :13 ] train iteration=0  step=13   reward=1.0   done=False action=1 observation=[-0.10316552 -0.54555216  0.12346704  1.0119448 ]\n",
      "[CartPole-v0 2:0  :14 ] train iteration=0  step=14   reward=1.0   done=False action=0 observation=[-0.11407656 -0.74208572  0.14370594  1.34070818]\n",
      "[CartPole-v0 2:0  :15 ] train iteration=0  step=15   reward=1.0   done=False action=1 observation=[-0.12891827 -0.54903504  0.1705201   1.09622135]\n",
      "[CartPole-v0 2:0  :16 ] train iteration=0  step=16   reward=1.0   done=False action=1 observation=[-0.13989897 -0.35651816  0.19244453  0.86152456]\n",
      "[CartPole-v0 2:1  :17 ] train iteration=0  step=17   reward=1.0   done=True  action=0 observation=[-0.14702934 -0.55366623  0.20967502  1.20801763]\n",
      "[CartPole-v0 2:1  :1  ] train iteration=0  step=18   reward=1.0   done=False action=1 observation=[-0.03940542  0.21258198 -0.01040263 -0.2790682 ]\n",
      "[CartPole-v0 2:1  :2  ] train iteration=0  step=19   reward=1.0   done=False action=0 observation=[-0.03515378  0.01760996 -0.015984    0.01031569]\n",
      "[CartPole-v0 2:1  :3  ] train iteration=0  step=20   reward=1.0   done=False action=1 observation=[-0.03480158  0.21295746 -0.01577768 -0.28736722]\n",
      "[CartPole-v0 2:1  :4  ] train iteration=0  step=21   reward=1.0   done=False action=0 observation=[-0.03054243  0.01806402 -0.02152503  0.0002981 ]\n",
      "[CartPole-v0 2:1  :5  ] train iteration=0  step=22   reward=1.0   done=False action=0 observation=[-0.03018115 -0.17674272 -0.02151907  0.28611266]\n",
      "[CartPole-v0 2:1  :6  ] train iteration=0  step=23   reward=1.0   done=False action=1 observation=[-0.03371601  0.01867941 -0.01579681 -0.01327879]\n",
      "[CartPole-v0 2:1  :7  ] train iteration=0  step=24   reward=1.0   done=False action=1 observation=[-0.03334242  0.2140243  -0.01606239 -0.31090364]\n",
      "[CartPole-v0 2:1  :8  ] train iteration=0  step=25   reward=1.0   done=False action=0 observation=[-0.02906193  0.01913484 -0.02228046 -0.02332929]\n",
      "[CartPole-v0 2:1  :9  ] train iteration=0  step=26   reward=1.0   done=False action=1 observation=[-0.02867924  0.21456911 -0.02274705 -0.32295785]\n",
      "[CartPole-v0 2:1  :10 ] train iteration=0  step=27   reward=1.0   done=False action=1 observation=[-0.02438785  0.41000746 -0.0292062  -0.62272659]\n",
      "[CartPole-v0 2:1  :11 ] train iteration=0  step=28   reward=1.0   done=False action=0 observation=[-0.01618771  0.21530523 -0.04166074 -0.3393832 ]\n",
      "[CartPole-v0 2:1  :12 ] train iteration=0  step=29   reward=1.0   done=False action=1 observation=[-0.0118816   0.41099445 -0.0484484  -0.64490705]\n",
      "[CartPole-v0 2:1  :13 ] train iteration=0  step=30   reward=1.0   done=False action=0 observation=[-0.00366171  0.21657994 -0.06134654 -0.36786574]\n",
      "[CartPole-v0 2:1  :14 ] train iteration=0  step=31   reward=1.0   done=False action=0 observation=[ 0.00066989  0.0223809  -0.06870386 -0.09513971]\n",
      "[CartPole-v0 2:1  :15 ] train iteration=0  step=32   reward=1.0   done=False action=0 observation=[ 0.00111751 -0.17169252 -0.07060665  0.17510058]\n",
      "[CartPole-v0 2:1  :16 ] train iteration=0  step=33   reward=1.0   done=False action=1 observation=[-0.00231635  0.02436517 -0.06710464 -0.1389943 ]\n",
      "[CartPole-v0 2:1  :17 ] train iteration=0  step=34   reward=1.0   done=False action=0 observation=[-0.00182904 -0.1697347  -0.06988452  0.13178625]\n",
      "[CartPole-v0 2:1  :18 ] train iteration=0  step=35   reward=1.0   done=False action=0 observation=[-0.00522374 -0.36378961 -0.0672488   0.40162878]\n",
      "[CartPole-v0 2:1  :19 ] train iteration=0  step=36   reward=1.0   done=False action=1 observation=[-0.01249953 -0.16778146 -0.05921622  0.08852487]\n",
      "[CartPole-v0 2:1  :20 ] train iteration=0  step=37   reward=1.0   done=False action=1 observation=[-0.01585516  0.0281371  -0.05744573 -0.22223726]\n",
      "[CartPole-v0 2:1  :21 ] train iteration=0  step=38   reward=1.0   done=False action=1 observation=[-0.01529242  0.22403108 -0.06189047 -0.53247328]\n",
      "[CartPole-v0 2:1  :22 ] train iteration=0  step=39   reward=1.0   done=False action=0 observation=[-0.01081179  0.02983171 -0.07253994 -0.25991613]\n",
      "[CartPole-v0 2:1  :23 ] train iteration=0  step=40   reward=1.0   done=False action=1 observation=[-0.01021516  0.2259102  -0.07773826 -0.57456843]\n",
      "[CartPole-v0 2:1  :24 ] train iteration=0  step=41   reward=1.0   done=False action=1 observation=[-0.00569696  0.42203099 -0.08922963 -0.89069319]\n",
      "[CartPole-v0 2:1  :25 ] train iteration=0  step=42   reward=1.0   done=False action=0 observation=[ 0.00274366  0.22822558 -0.10704349 -0.62734031]\n",
      "[CartPole-v0 2:1  :26 ] train iteration=0  step=43   reward=1.0   done=False action=1 observation=[ 0.00730818  0.4246659  -0.1195903  -0.95172497]\n",
      "[CartPole-v0 2:1  :27 ] train iteration=0  step=44   reward=1.0   done=False action=1 observation=[ 0.01580149  0.62117655 -0.1386248  -1.27946141]\n",
      "[CartPole-v0 2:1  :28 ] train iteration=0  step=45   reward=1.0   done=False action=0 observation=[ 0.02822502  0.42806642 -0.16421403 -1.03320027]\n",
      "[CartPole-v0 2:1  :29 ] train iteration=0  step=46   reward=1.0   done=False action=0 observation=[ 0.03678635  0.2354638  -0.18487803 -0.79624515]\n",
      "[CartPole-v0 2:1  :30 ] train iteration=0  step=47   reward=1.0   done=False action=0 observation=[ 0.04149563  0.04329472 -0.20080293 -0.56694878]\n",
      "[CartPole-v0 2:2  :31 ] train iteration=0  step=48   reward=1.0   done=True  action=1 observation=[ 0.04236152  0.24058284 -0.21214191 -0.91557486]\n",
      "[CartPole-v0 2:2  :1  ] train iteration=0  step=49   reward=1.0   done=False action=1 observation=[-0.04396213  0.19844869 -0.04501504 -0.25903102]\n",
      "[CartPole-v0 2:2  :2  ] train iteration=0  step=50   reward=1.0   done=False action=1 observation=[-0.03999315  0.3941834  -0.05019566 -0.56556562]\n",
      "[CartPole-v0 2:2  :3  ] train iteration=0  step=51   reward=1.0   done=False action=1 observation=[-0.03210949  0.5899723  -0.06150698 -0.8736304 ]\n",
      "[CartPole-v0 2:2  :4  ] train iteration=0  step=52   reward=1.0   done=False action=1 observation=[-0.02031004  0.7858742  -0.07897958 -1.18499923]\n",
      "[CartPole-v0 2:2  :5  ] train iteration=0  step=53   reward=1.0   done=False action=0 observation=[-0.00459256  0.59186051 -0.10267957 -0.91808175]\n",
      "[CartPole-v0 2:2  :6  ] train iteration=0  step=54   reward=1.0   done=False action=0 observation=[ 0.00724465  0.39826534 -0.1210412  -0.65935325]\n",
      "[CartPole-v0 2:2  :7  ] train iteration=0  step=55   reward=1.0   done=False action=1 observation=[ 0.01520996  0.59484537 -0.13422827 -0.98756514]\n",
      "[CartPole-v0 2:2  :8  ] train iteration=0  step=56   reward=1.0   done=False action=1 observation=[ 0.02710687  0.79148429 -0.15397957 -1.31921506]\n",
      "[CartPole-v0 2:2  :9  ] train iteration=0  step=57   reward=1.0   done=False action=0 observation=[ 0.04293655  0.59860746 -0.18036387 -1.07841416]\n",
      "[CartPole-v0 2:2  :10 ] train iteration=0  step=58   reward=1.0   done=False action=1 observation=[ 0.0549087   0.795593   -0.20193216 -1.42183929]\n",
      "[CartPole-v0 2:3  :11 ] train iteration=0  step=59   reward=1.0   done=True  action=1 observation=[ 0.07082056  0.99255756 -0.23036894 -1.77024833]\n",
      "[CartPole-v0 2:3  :1  ] train iteration=1  step=1    reward=1.0   done=False action=1 observation=[-0.00384741  0.23602739 -0.04506642 -0.26458976]\n",
      "[CartPole-v0 2:3  :2  ] train iteration=1  step=2    reward=1.0   done=False action=0 observation=[ 0.00087314  0.04157668 -0.05035822  0.01354511]\n",
      "[CartPole-v0 2:3  :3  ] train iteration=1  step=3    reward=1.0   done=False action=0 observation=[ 0.00170468 -0.15278825 -0.05008731  0.28992386]\n",
      "[CartPole-v0 2:3  :4  ] train iteration=1  step=4    reward=1.0   done=False action=1 observation=[-0.00135109  0.04301081 -0.04428884 -0.01812591]\n",
      "[CartPole-v0 2:3  :5  ] train iteration=1  step=5    reward=1.0   done=False action=1 observation=[-0.00049087  0.23873901 -0.04465135 -0.32444698]\n",
      "[CartPole-v0 2:3  :6  ] train iteration=1  step=6    reward=1.0   done=False action=0 observation=[ 0.00428391  0.04428034 -0.05114029 -0.04617284]\n",
      "[CartPole-v0 2:3  :7  ] train iteration=1  step=7    reward=1.0   done=False action=1 observation=[ 0.00516951  0.24009689 -0.05206375 -0.35454235]\n",
      "[CartPole-v0 2:3  :8  ] train iteration=1  step=8    reward=1.0   done=False action=1 observation=[ 0.00997145  0.43591898 -0.0591546  -0.6631773 ]\n",
      "[CartPole-v0 2:3  :9  ] train iteration=1  step=9    reward=1.0   done=False action=1 observation=[ 0.01868983  0.63181185 -0.07241814 -0.97388395]\n",
      "[CartPole-v0 2:3  :10 ] train iteration=1  step=10   reward=1.0   done=False action=1 observation=[ 0.03132607  0.82782672 -0.09189582 -1.28840794]\n",
      "[CartPole-v0 2:3  :11 ] train iteration=1  step=11   reward=1.0   done=False action=0 observation=[ 0.0478826   0.6339861  -0.11766398 -1.02585323]\n",
      "[CartPole-v0 2:3  :12 ] train iteration=1  step=12   reward=1.0   done=False action=1 observation=[ 0.06056232  0.83046135 -0.13818105 -1.35304177]\n",
      "[CartPole-v0 2:3  :13 ] train iteration=1  step=13   reward=1.0   done=False action=0 observation=[ 0.07717155  0.6373181  -0.16524188 -1.10658448]\n",
      "[CartPole-v0 2:3  :14 ] train iteration=1  step=14   reward=1.0   done=False action=0 observation=[ 0.08991791  0.44470787 -0.18737357 -0.8699649 ]\n",
      "[CartPole-v0 2:3  :15 ] train iteration=1  step=15   reward=1.0   done=False action=1 observation=[ 0.09881207  0.64181657 -0.20477287 -1.21521897]\n",
      "[CartPole-v0 2:4  :16 ] train iteration=1  step=16   reward=1.0   done=True  action=1 observation=[ 0.1116484   0.83890459 -0.22907725 -1.56445778]\n",
      "[CartPole-v0 2:4  :1  ] train iteration=1  step=17   reward=1.0   done=False action=1 observation=[ 0.02719217  0.14678731 -0.00691121 -0.27544406]\n",
      "[CartPole-v0 2:4  :2  ] train iteration=1  step=18   reward=1.0   done=False action=1 observation=[ 0.03012792  0.34200718 -0.0124201  -0.57029875]\n",
      "[CartPole-v0 2:4  :3  ] train iteration=1  step=19   reward=1.0   done=False action=0 observation=[ 0.03696806  0.14706159 -0.02382607 -0.28155434]\n",
      "[CartPole-v0 2:4  :4  ] train iteration=1  step=20   reward=1.0   done=False action=0 observation=[ 0.03990929 -0.04771254 -0.02945716  0.00351974]\n",
      "[CartPole-v0 2:4  :5  ] train iteration=1  step=21   reward=1.0   done=False action=0 observation=[ 0.03895504 -0.24239992 -0.02938676  0.28676496]\n",
      "[CartPole-v0 2:4  :6  ] train iteration=1  step=22   reward=1.0   done=False action=1 observation=[ 0.03410704 -0.04687147 -0.02365146 -0.01503955]\n",
      "[CartPole-v0 2:4  :7  ] train iteration=1  step=23   reward=1.0   done=False action=1 observation=[ 0.03316961  0.14858155 -0.02395225 -0.31508996]\n",
      "[CartPole-v0 2:4  :8  ] train iteration=1  step=24   reward=1.0   done=False action=1 observation=[ 0.03614124  0.34403635 -0.03025405 -0.61522936]\n",
      "[CartPole-v0 2:4  :9  ] train iteration=1  step=25   reward=1.0   done=False action=1 observation=[ 0.04302197  0.53956767 -0.04255864 -0.91728544]\n",
      "[CartPole-v0 2:4  :10 ] train iteration=1  step=26   reward=1.0   done=False action=0 observation=[ 0.05381332  0.34504617 -0.06090435 -0.63827587]\n",
      "[CartPole-v0 2:4  :11 ] train iteration=1  step=27   reward=1.0   done=False action=0 observation=[ 0.06071425  0.15082398 -0.07366987 -0.36537755]\n",
      "[CartPole-v0 2:4  :12 ] train iteration=1  step=28   reward=1.0   done=False action=1 observation=[ 0.06373073  0.34691133 -0.08097742 -0.68035013]\n",
      "[CartPole-v0 2:4  :13 ] train iteration=1  step=29   reward=1.0   done=False action=1 observation=[ 0.07066895  0.54305911 -0.09458442 -0.99738902]\n",
      "[CartPole-v0 2:4  :14 ] train iteration=1  step=30   reward=1.0   done=False action=1 observation=[ 0.08153014  0.73930972 -0.1145322  -1.31821552]\n",
      "[CartPole-v0 2:4  :15 ] train iteration=1  step=31   reward=1.0   done=False action=0 observation=[ 0.09631633  0.54580718 -0.14089651 -1.06346224]\n",
      "[CartPole-v0 2:4  :16 ] train iteration=1  step=32   reward=1.0   done=False action=1 observation=[ 0.10723247  0.7424844  -0.16216576 -1.39684128]\n",
      "[CartPole-v0 2:4  :17 ] train iteration=1  step=33   reward=1.0   done=False action=1 observation=[ 0.12208216  0.93920891 -0.19010258 -1.73552452]\n",
      "[CartPole-v0 2:5  :18 ] train iteration=1  step=34   reward=1.0   done=True  action=0 observation=[ 0.14086634  0.74669578 -0.22481307 -1.50751119]\n",
      "[CartPole-v0 2:5  :1  ] train iteration=1  step=35   reward=1.0   done=False action=1 observation=[ 0.03702274  0.22412742  0.02434186 -0.32344455]\n",
      "[CartPole-v0 2:5  :2  ] train iteration=1  step=36   reward=1.0   done=False action=0 observation=[ 0.04150529  0.02866746  0.01787297 -0.02318568]\n",
      "[CartPole-v0 2:5  :3  ] train iteration=1  step=37   reward=1.0   done=False action=1 observation=[ 0.04207864  0.2235286   0.01740926 -0.31017632]\n",
      "[CartPole-v0 2:5  :4  ] train iteration=1  step=38   reward=1.0   done=False action=0 observation=[ 0.04654921  0.02816299  0.01120573 -0.01205425]\n",
      "[CartPole-v0 2:5  :5  ] train iteration=1  step=39   reward=1.0   done=False action=1 observation=[ 0.04711247  0.22312246  0.01096465 -0.30118068]\n",
      "[CartPole-v0 2:5  :6  ] train iteration=1  step=40   reward=1.0   done=False action=1 observation=[ 0.05157492  0.41808643  0.00494103 -0.59038551]\n",
      "[CartPole-v0 2:5  :7  ] train iteration=1  step=41   reward=1.0   done=False action=0 observation=[ 0.05993665  0.22289564 -0.00686668 -0.29615026]\n",
      "[CartPole-v0 2:5  :8  ] train iteration=1  step=42   reward=1.0   done=False action=1 observation=[ 0.06439456  0.41811481 -0.01278968 -0.59099089]\n",
      "[CartPole-v0 2:5  :9  ] train iteration=1  step=43   reward=1.0   done=False action=0 observation=[ 0.07275686  0.22317424 -0.0246095  -0.30236401]\n",
      "[CartPole-v0 2:5  :10 ] train iteration=1  step=44   reward=1.0   done=False action=0 observation=[ 0.07722034  0.02841151 -0.03065678 -0.01754285]\n",
      "[CartPole-v0 2:5  :11 ] train iteration=1  step=45   reward=1.0   done=False action=1 observation=[ 0.07778857  0.2239594  -0.03100764 -0.31973853]\n",
      "[CartPole-v0 2:5  :12 ] train iteration=1  step=46   reward=1.0   done=False action=1 observation=[ 0.08226776  0.41950892 -0.03740241 -0.62203659]\n",
      "[CartPole-v0 2:5  :13 ] train iteration=1  step=47   reward=1.0   done=False action=1 observation=[ 0.09065794  0.61513264 -0.04984314 -0.9262607 ]\n",
      "[CartPole-v0 2:5  :14 ] train iteration=1  step=48   reward=1.0   done=False action=0 observation=[ 0.10296059  0.42071794 -0.06836835 -0.64964863]\n",
      "[CartPole-v0 2:5  :15 ] train iteration=1  step=49   reward=1.0   done=False action=1 observation=[ 0.11137495  0.61672228 -0.08136133 -0.96305292]\n",
      "[CartPole-v0 2:5  :16 ] train iteration=1  step=50   reward=1.0   done=False action=1 observation=[ 0.1237094   0.81283761 -0.10062238 -1.28014663]\n",
      "[CartPole-v0 2:5  :17 ] train iteration=1  step=51   reward=1.0   done=False action=0 observation=[ 0.13996615  0.61913143 -0.12622532 -1.02059014]\n",
      "[CartPole-v0 2:5  :18 ] train iteration=1  step=52   reward=1.0   done=False action=0 observation=[ 0.15234878  0.42589672 -0.14663712 -0.77005587]\n",
      "[CartPole-v0 2:5  :19 ] train iteration=1  step=53   reward=1.0   done=False action=1 observation=[ 0.16086671  0.62269968 -0.16203824 -1.10504918]\n",
      "[CartPole-v0 2:5  :20 ] train iteration=1  step=54   reward=1.0   done=False action=1 observation=[ 0.1733207   0.81953797 -0.18413922 -1.44386992]\n",
      "[CartPole-v0 2:6  :21 ] train iteration=1  step=55   reward=1.0   done=True  action=0 observation=[ 0.18971146  0.62709722 -0.21301662 -1.21392035]\n",
      "[CartPole-v0 2:6  :1  ] train iteration=2  step=1    reward=1.0   done=False action=1 observation=[ 0.00256538  0.23563461 -0.00928383 -0.30537031]\n",
      "[CartPole-v0 2:6  :2  ] train iteration=2  step=2    reward=1.0   done=False action=0 observation=[ 0.00727807  0.04064618 -0.01539124 -0.01562968]\n",
      "[CartPole-v0 2:6  :3  ] train iteration=2  step=3    reward=1.0   done=False action=0 observation=[ 0.00809099 -0.1542517  -0.01570383  0.27215767]\n",
      "[CartPole-v0 2:6  :4  ] train iteration=2  step=4    reward=1.0   done=False action=1 observation=[ 0.00500596  0.04109077 -0.01026068 -0.02543664]\n",
      "[CartPole-v0 2:6  :5  ] train iteration=2  step=5    reward=1.0   done=False action=0 observation=[ 0.00582777 -0.15388254 -0.01076941  0.26399135]\n",
      "[CartPole-v0 2:6  :6  ] train iteration=2  step=6    reward=1.0   done=False action=1 observation=[ 0.00275012  0.04139146 -0.00548958 -0.03206881]\n",
      "[CartPole-v0 2:6  :7  ] train iteration=2  step=7    reward=1.0   done=False action=0 observation=[ 0.00357795 -0.15365134 -0.00613096  0.25887705]\n",
      "[CartPole-v0 2:6  :8  ] train iteration=2  step=8    reward=1.0   done=False action=0 observation=[ 5.04925683e-04 -3.48685234e-01 -9.53416337e-04  5.49619899e-01]\n",
      "[CartPole-v0 2:6  :9  ] train iteration=2  step=9    reward=1.0   done=False action=1 observation=[-0.00646878 -0.1535499   0.01003898  0.25663673]\n",
      "[CartPole-v0 2:6  :10 ] train iteration=2  step=10   reward=1.0   done=False action=1 observation=[-0.00953978  0.04142729  0.01517172 -0.03286291]\n",
      "[CartPole-v0 2:6  :11 ] train iteration=2  step=11   reward=1.0   done=False action=0 observation=[-0.00871123 -0.15390891  0.01451446  0.26456798]\n",
      "[CartPole-v0 2:6  :12 ] train iteration=2  step=12   reward=1.0   done=False action=1 observation=[-0.01178941  0.0410029   0.01980582 -0.02350184]\n",
      "[CartPole-v0 2:6  :13 ] train iteration=2  step=13   reward=1.0   done=False action=0 observation=[-0.01096935 -0.1543974   0.01933578  0.27536366]\n",
      "[CartPole-v0 2:6  :14 ] train iteration=2  step=14   reward=1.0   done=False action=1 observation=[-0.0140573   0.04044342  0.02484305 -0.01115857]\n",
      "[CartPole-v0 2:6  :15 ] train iteration=2  step=15   reward=1.0   done=False action=0 observation=[-0.01324843 -0.15502584  0.02461988  0.28925795]\n",
      "[CartPole-v0 2:6  :16 ] train iteration=2  step=16   reward=1.0   done=False action=0 observation=[-0.01634895 -0.35049006  0.03040504  0.58960294]\n",
      "[CartPole-v0 2:6  :17 ] train iteration=2  step=17   reward=1.0   done=False action=1 observation=[-0.02335875 -0.15580675  0.0421971   0.30665065]\n",
      "[CartPole-v0 2:6  :18 ] train iteration=2  step=18   reward=1.0   done=False action=0 observation=[-0.02647488 -0.3515038   0.04833011  0.61233719]\n",
      "[CartPole-v0 2:6  :19 ] train iteration=2  step=19   reward=1.0   done=False action=0 observation=[-0.03350496 -0.54726669  0.06057686  0.91984217]\n",
      "[CartPole-v0 2:6  :20 ] train iteration=2  step=20   reward=1.0   done=False action=0 observation=[-0.04445029 -0.74315277  0.0789737   1.23093105]\n",
      "[CartPole-v0 2:6  :21 ] train iteration=2  step=21   reward=1.0   done=False action=1 observation=[-0.05931335 -0.54913045  0.10359232  0.96399881]\n",
      "[CartPole-v0 2:6  :22 ] train iteration=2  step=22   reward=1.0   done=False action=0 observation=[-0.07029596 -0.74548009  0.1228723   1.28734604]\n",
      "[CartPole-v0 2:6  :23 ] train iteration=2  step=23   reward=1.0   done=False action=0 observation=[-0.08520556 -0.94193243  0.14861922  1.6158365 ]\n",
      "[CartPole-v0 2:6  :24 ] train iteration=2  step=24   reward=1.0   done=False action=0 observation=[-0.10404421 -1.13846208  0.18093595  1.95091468]\n",
      "[CartPole-v0 2:7  :25 ] train iteration=2  step=25   reward=1.0   done=True  action=0 observation=[-0.12681345 -1.3349888   0.21995424  2.29379792]\n",
      "[CartPole-v0 2:7  :1  ] train iteration=2  step=26   reward=1.0   done=False action=0 observation=[ 0.0404217  -0.21039115 -0.0010204   0.26814947]\n",
      "[CartPole-v0 2:7  :2  ] train iteration=2  step=27   reward=1.0   done=False action=1 observation=[ 0.03621387 -0.01525465  0.00434259 -0.02485513]\n",
      "[CartPole-v0 2:7  :3  ] train iteration=2  step=28   reward=1.0   done=False action=1 observation=[ 0.03590878  0.17980475  0.00384548 -0.31616476]\n",
      "[CartPole-v0 2:7  :4  ] train iteration=2  step=29   reward=1.0   done=False action=1 observation=[ 0.03950488  0.37487172 -0.00247781 -0.60763248]\n",
      "[CartPole-v0 2:7  :5  ] train iteration=2  step=30   reward=1.0   done=False action=0 observation=[ 0.04700231  0.1797845  -0.01463046 -0.31573102]\n",
      "[CartPole-v0 2:7  :6  ] train iteration=2  step=31   reward=1.0   done=False action=0 observation=[ 0.050598   -0.01512603 -0.02094508 -0.02769772]\n",
      "[CartPole-v0 2:7  :7  ] train iteration=2  step=32   reward=1.0   done=False action=0 observation=[ 0.05029548 -0.20994145 -0.02149904  0.25830391]\n",
      "[CartPole-v0 2:7  :8  ] train iteration=2  step=33   reward=1.0   done=False action=0 observation=[ 0.04609665 -0.40474998 -0.01633296  0.54412895]\n",
      "[CartPole-v0 2:7  :9  ] train iteration=2  step=34   reward=1.0   done=False action=0 observation=[ 0.03800165 -0.59963865 -0.00545038  0.83162128]\n",
      "[CartPole-v0 2:7  :10 ] train iteration=2  step=35   reward=1.0   done=False action=1 observation=[ 0.02600888 -0.40444263  0.01118205  0.53722921]\n",
      "[CartPole-v0 2:7  :11 ] train iteration=2  step=36   reward=1.0   done=False action=0 observation=[ 0.01792003 -0.59972     0.02192663  0.8334144 ]\n",
      "[CartPole-v0 2:7  :12 ] train iteration=2  step=37   reward=1.0   done=False action=1 observation=[ 0.00592563 -0.40490441  0.03859492  0.54770716]\n",
      "[CartPole-v0 2:7  :13 ] train iteration=2  step=38   reward=1.0   done=False action=1 observation=[-0.00217246 -0.21034532  0.04954906  0.26742995]\n",
      "[CartPole-v0 2:7  :14 ] train iteration=2  step=39   reward=1.0   done=False action=1 observation=[-0.00637937 -0.01596424  0.05489766 -0.00922235]\n",
      "[CartPole-v0 2:7  :15 ] train iteration=2  step=40   reward=1.0   done=False action=0 observation=[-0.00669865 -0.21182877  0.05471321  0.30026364]\n",
      "[CartPole-v0 2:7  :16 ] train iteration=2  step=41   reward=1.0   done=False action=1 observation=[-0.01093523 -0.01752763  0.06071849  0.02532572]\n",
      "[CartPole-v0 2:7  :17 ] train iteration=2  step=42   reward=1.0   done=False action=1 observation=[-0.01128578  0.17667338  0.061225   -0.24759872]\n",
      "[CartPole-v0 2:7  :18 ] train iteration=2  step=43   reward=1.0   done=False action=0 observation=[-0.00775231 -0.0192671   0.05627303  0.06375022]\n",
      "[CartPole-v0 2:7  :19 ] train iteration=2  step=44   reward=1.0   done=False action=1 observation=[-0.00813766  0.17500477  0.05754803 -0.21066078]\n",
      "[CartPole-v0 2:7  :20 ] train iteration=2  step=45   reward=1.0   done=False action=0 observation=[-0.00463756 -0.02089077  0.05333482  0.09960588]\n",
      "[CartPole-v0 2:7  :21 ] train iteration=2  step=46   reward=1.0   done=False action=0 observation=[-0.00505538 -0.21673493  0.05532693  0.4086274 ]\n",
      "[CartPole-v0 2:7  :22 ] train iteration=2  step=47   reward=1.0   done=False action=0 observation=[-0.00939007 -0.4125959   0.06349948  0.71822713]\n",
      "[CartPole-v0 2:7  :23 ] train iteration=2  step=48   reward=1.0   done=False action=0 observation=[-0.01764199 -0.60853641  0.07786402  1.03020185]\n",
      "[CartPole-v0 2:7  :24 ] train iteration=2  step=49   reward=1.0   done=False action=0 observation=[-0.02981272 -0.8046032   0.09846806  1.34627984]\n",
      "[CartPole-v0 2:7  :25 ] train iteration=2  step=50   reward=1.0   done=False action=0 observation=[-0.04590478 -1.00081562  0.12539366  1.66807563]\n",
      "[CartPole-v0 2:7  :26 ] train iteration=2  step=51   reward=1.0   done=False action=0 observation=[-0.0659211  -1.1971529   0.15875517  1.99703844]\n",
      "[CartPole-v0 2:7  :27 ] train iteration=2  step=52   reward=1.0   done=False action=0 observation=[-0.08986416 -1.39353933  0.19869594  2.33439191]\n",
      "[CartPole-v0 2:8  :28 ] train iteration=2  step=53   reward=1.0   done=True  action=1 observation=[-0.11773494 -1.20069293  0.24538378  2.10884673]\n",
      "[CartPole-v0 2:8  :1  ] train iteration=2  step=54   reward=1.0   done=False action=1 observation=[-0.01310465  0.24140094 -0.05026826 -0.33018624]\n",
      "[CartPole-v0 2:8  :2  ] train iteration=2  step=55   reward=1.0   done=False action=1 observation=[-0.00827663  0.43720108 -0.05687199 -0.63828811]\n",
      "[CartPole-v0 2:8  :3  ] train iteration=2  step=56   reward=1.0   done=False action=1 observation=[ 4.67389353e-04  6.33068003e-01 -6.96377488e-02 -9.48324833e-01]\n",
      "[CartPole-v0 2:8  :4  ] train iteration=2  step=57   reward=1.0   done=False action=0 observation=[ 0.01312875  0.43894925 -0.08860425 -0.6783094 ]\n",
      "[CartPole-v0 2:8  :5  ] train iteration=2  step=58   reward=1.0   done=False action=0 observation=[ 0.02190773  0.24516268 -0.10217043 -0.4147854 ]\n",
      "[CartPole-v0 2:8  :6  ] train iteration=2  step=59   reward=1.0   done=False action=1 observation=[ 0.02681099  0.44157311 -0.11046614 -0.73785054]\n",
      "[CartPole-v0 2:8  :7  ] train iteration=2  step=60   reward=1.0   done=False action=1 observation=[ 0.03564245  0.63803319 -0.12522315 -1.0631555 ]\n",
      "[CartPole-v0 2:8  :8  ] train iteration=2  step=61   reward=1.0   done=False action=1 observation=[ 0.04840311  0.83457026 -0.14648626 -1.39237219]\n",
      "[CartPole-v0 2:8  :9  ] train iteration=2  step=62   reward=1.0   done=False action=0 observation=[ 0.06509452  0.64154405 -0.17433371 -1.14884692]\n",
      "[CartPole-v0 2:8  :10 ] train iteration=2  step=63   reward=1.0   done=False action=1 observation=[ 0.0779254   0.83845902 -0.19731064 -1.4907371 ]\n",
      "[CartPole-v0 2:9  :11 ] train iteration=2  step=64   reward=1.0   done=True  action=0 observation=[ 0.09469458  0.64620948 -0.22712539 -1.26559168]\n",
      "[CartPole-v0 2:9  :1  ] train iteration=3  step=1    reward=1.0   done=False action=0 observation=[ 0.00529372 -0.1528915  -0.04368514  0.24099938]\n",
      "[CartPole-v0 2:9  :2  ] train iteration=3  step=2    reward=1.0   done=False action=1 observation=[ 0.00223589  0.04282638 -0.03886516 -0.0651367 ]\n",
      "[CartPole-v0 2:9  :3  ] train iteration=3  step=3    reward=1.0   done=False action=1 observation=[ 0.00309242  0.23848338 -0.04016789 -0.36982405]\n",
      "[CartPole-v0 2:9  :4  ] train iteration=3  step=4    reward=1.0   done=False action=1 observation=[ 0.00786208  0.43415233 -0.04756437 -0.67489691]\n",
      "[CartPole-v0 2:9  :5  ] train iteration=3  step=5    reward=1.0   done=False action=1 observation=[ 0.01654513  0.62990189 -0.06106231 -0.98216782]\n",
      "[CartPole-v0 2:9  :6  ] train iteration=3  step=6    reward=1.0   done=False action=0 observation=[ 0.02914317  0.43564898 -0.08070567 -0.70927268]\n",
      "[CartPole-v0 2:9  :7  ] train iteration=3  step=7    reward=1.0   done=False action=0 observation=[ 0.03785615  0.2417321  -0.09489112 -0.44304586]\n",
      "[CartPole-v0 2:9  :8  ] train iteration=3  step=8    reward=1.0   done=False action=0 observation=[ 0.04269079  0.04807194 -0.10375204 -0.18171861]\n",
      "[CartPole-v0 2:9  :9  ] train iteration=3  step=9    reward=1.0   done=False action=0 observation=[ 0.04365223 -0.14542419 -0.10738641  0.07651642]\n",
      "[CartPole-v0 2:9  :10 ] train iteration=3  step=10   reward=1.0   done=False action=1 observation=[ 0.04074374  0.05106026 -0.10585608 -0.24802348]\n",
      "[CartPole-v0 2:9  :11 ] train iteration=3  step=11   reward=1.0   done=False action=0 observation=[ 0.04176495 -0.14240318 -0.11081655  0.00948372]\n",
      "[CartPole-v0 2:9  :12 ] train iteration=3  step=12   reward=1.0   done=False action=0 observation=[ 0.03891689 -0.33577581 -0.11062688  0.26525004]\n",
      "[CartPole-v0 2:9  :13 ] train iteration=3  step=13   reward=1.0   done=False action=1 observation=[ 0.03220137 -0.13926305 -0.10532187 -0.06017519]\n",
      "[CartPole-v0 2:9  :14 ] train iteration=3  step=14   reward=1.0   done=False action=0 observation=[ 0.02941611 -0.3327296  -0.10652538  0.19750915]\n",
      "[CartPole-v0 2:9  :15 ] train iteration=3  step=15   reward=1.0   done=False action=0 observation=[ 0.02276152 -0.52617938 -0.1025752   0.45477972]\n",
      "[CartPole-v0 2:9  :16 ] train iteration=3  step=16   reward=1.0   done=False action=1 observation=[ 0.01223793 -0.32976799 -0.0934796   0.13160696]\n",
      "[CartPole-v0 2:9  :17 ] train iteration=3  step=17   reward=1.0   done=False action=0 observation=[ 0.00564257 -0.52343521 -0.09084746  0.39339646]\n",
      "[CartPole-v0 2:9  :18 ] train iteration=3  step=18   reward=1.0   done=False action=1 observation=[-0.00482613 -0.32714944 -0.08297953  0.07350953]\n",
      "[CartPole-v0 2:9  :19 ] train iteration=3  step=19   reward=1.0   done=False action=0 observation=[-0.01136912 -0.5209898  -0.08150934  0.33890162]\n",
      "[CartPole-v0 2:9  :20 ] train iteration=3  step=20   reward=1.0   done=False action=1 observation=[-0.02178892 -0.32480834 -0.07473131  0.0216692 ]\n",
      "[CartPole-v0 2:9  :21 ] train iteration=3  step=21   reward=1.0   done=False action=0 observation=[-0.02828509 -0.51878343 -0.07429793  0.28986919]\n",
      "[CartPole-v0 2:9  :22 ] train iteration=3  step=22   reward=1.0   done=False action=1 observation=[-0.03866076 -0.32268501 -0.06850054 -0.02529046]\n",
      "[CartPole-v0 2:9  :23 ] train iteration=3  step=23   reward=1.0   done=False action=1 observation=[-0.04511446 -0.12665097 -0.06900635 -0.3387753 ]\n",
      "[CartPole-v0 2:9  :24 ] train iteration=3  step=24   reward=1.0   done=False action=0 observation=[-0.04764747 -0.32072662 -0.07578186 -0.06862645]\n",
      "[CartPole-v0 2:9  :25 ] train iteration=3  step=25   reward=1.0   done=False action=0 observation=[-0.05406201 -0.5146849  -0.07715439  0.19921742]\n",
      "[CartPole-v0 2:9  :26 ] train iteration=3  step=26   reward=1.0   done=False action=1 observation=[-0.0643557  -0.31854907 -0.07317004 -0.11677198]\n",
      "[CartPole-v0 2:9  :27 ] train iteration=3  step=27   reward=1.0   done=False action=1 observation=[-0.07072669 -0.12245915 -0.07550548 -0.43161264]\n",
      "[CartPole-v0 2:9  :28 ] train iteration=3  step=28   reward=1.0   done=False action=1 observation=[-0.07317587  0.07364619 -0.08413773 -0.74711006]\n",
      "[CartPole-v0 2:9  :29 ] train iteration=3  step=29   reward=1.0   done=False action=1 observation=[-0.07170295  0.26982197 -0.09907993 -1.06504009]\n",
      "[CartPole-v0 2:9  :30 ] train iteration=3  step=30   reward=1.0   done=False action=1 observation=[-0.06630651  0.46610559 -0.12038073 -1.38710341]\n",
      "[CartPole-v0 2:9  :31 ] train iteration=3  step=31   reward=1.0   done=False action=1 observation=[-0.05698439  0.66250468 -0.1481228  -1.71487654]\n",
      "[CartPole-v0 2:9  :32 ] train iteration=3  step=32   reward=1.0   done=False action=1 observation=[-0.0437343   0.85898344 -0.18242033 -2.04975651]\n",
      "[CartPole-v0 2:10 :33 ] train iteration=3  step=33   reward=1.0   done=True  action=1 observation=[-0.02655463  1.05544722 -0.22341546 -2.39289706]\n",
      "[CartPole-v0 2:10 :1  ] train iteration=3  step=34   reward=1.0   done=False action=0 observation=[ 0.0389085  -0.21310224 -0.01856664  0.26851371]\n",
      "[CartPole-v0 2:10 :2  ] train iteration=3  step=35   reward=1.0   done=False action=0 observation=[ 0.03464646 -0.40795437 -0.01319637  0.55528325]\n",
      "[CartPole-v0 2:10 :3  ] train iteration=3  step=36   reward=1.0   done=False action=1 observation=[ 0.02648737 -0.21264964 -0.0020907   0.25847205]\n",
      "[CartPole-v0 2:10 :4  ] train iteration=3  step=37   reward=1.0   done=False action=0 observation=[ 0.02223438 -0.40774169  0.00307874  0.55049481]\n",
      "[CartPole-v0 2:10 :5  ] train iteration=3  step=38   reward=1.0   done=False action=1 observation=[ 0.01407954 -0.21266311  0.01408863  0.25878348]\n",
      "[CartPole-v0 2:10 :6  ] train iteration=3  step=39   reward=1.0   done=False action=0 observation=[ 0.00982628 -0.40798333  0.0192643   0.55587666]\n",
      "[CartPole-v0 2:10 :7  ] train iteration=3  step=40   reward=1.0   done=False action=0 observation=[ 0.00166662 -0.60337038  0.03038184  0.8545662 ]\n",
      "[CartPole-v0 2:10 :8  ] train iteration=3  step=41   reward=1.0   done=False action=1 observation=[-0.01040079 -0.40867539  0.04747316  0.57158937]\n",
      "[CartPole-v0 2:10 :9  ] train iteration=3  step=42   reward=1.0   done=False action=0 observation=[-0.0185743  -0.60442977  0.05890495  0.87884199]\n",
      "[CartPole-v0 2:10 :10 ] train iteration=3  step=43   reward=1.0   done=False action=1 observation=[-0.0306629  -0.41015555  0.07648179  0.60524413]\n",
      "[CartPole-v0 2:10 :11 ] train iteration=3  step=44   reward=1.0   done=False action=1 observation=[-0.03886601 -0.21618174  0.08858667  0.33759772]\n",
      "[CartPole-v0 2:10 :12 ] train iteration=3  step=45   reward=1.0   done=False action=1 observation=[-0.04318964 -0.02242475  0.09533862  0.0741123 ]\n",
      "[CartPole-v0 2:10 :13 ] train iteration=3  step=46   reward=1.0   done=False action=0 observation=[-0.04363814 -0.21877502  0.09682087  0.3952873 ]\n",
      "[CartPole-v0 2:10 :14 ] train iteration=3  step=47   reward=1.0   done=False action=0 observation=[-0.04801364 -0.41512786  0.10472662  0.71685803]\n",
      "[CartPole-v0 2:10 :15 ] train iteration=3  step=48   reward=1.0   done=False action=0 observation=[-0.05631619 -0.61153134  0.11906378  1.04058253]\n",
      "[CartPole-v0 2:10 :16 ] train iteration=3  step=49   reward=1.0   done=False action=1 observation=[-0.06854682 -0.41817498  0.13987543  0.78752346]\n",
      "[CartPole-v0 2:10 :17 ] train iteration=3  step=50   reward=1.0   done=False action=1 observation=[-0.07691032 -0.22522306  0.1556259   0.54191172]\n",
      "[CartPole-v0 2:10 :18 ] train iteration=3  step=51   reward=1.0   done=False action=0 observation=[-0.08141478 -0.42215047  0.16646413  0.87930249]\n",
      "[CartPole-v0 2:10 :19 ] train iteration=3  step=52   reward=1.0   done=False action=0 observation=[-0.08985779 -0.61909526  0.18405018  1.21935082]\n",
      "[CartPole-v0 2:10 :20 ] train iteration=3  step=53   reward=1.0   done=False action=0 observation=[-0.1022397  -0.8160494   0.2084372   1.56359812]\n",
      "[CartPole-v0 2:11 :21 ] train iteration=3  step=54   reward=1.0   done=True  action=1 observation=[-0.11856068 -0.62393926  0.23970916  1.34250786]\n",
      "[CartPole-v0 2:11 :1  ] train iteration=3  step=55   reward=1.0   done=False action=0 observation=[ 0.01928599 -0.15215952  0.04925264  0.28219978]\n",
      "[CartPole-v0 2:11 :2  ] train iteration=3  step=56   reward=1.0   done=False action=0 observation=[ 0.0162428  -0.34794814  0.05489664  0.59000099]\n",
      "[CartPole-v0 2:11 :3  ] train iteration=3  step=57   reward=1.0   done=False action=1 observation=[ 0.00928384 -0.15363607  0.06669666  0.31510348]\n",
      "[CartPole-v0 2:11 :4  ] train iteration=3  step=58   reward=1.0   done=False action=0 observation=[ 0.00621112 -0.34964156  0.07299873  0.62805229]\n",
      "[CartPole-v0 2:11 :5  ] train iteration=3  step=59   reward=1.0   done=False action=0 observation=[-7.81715258e-04 -5.45702323e-01  8.55597734e-02  9.42802782e-01]\n",
      "[CartPole-v0 2:11 :6  ] train iteration=3  step=60   reward=1.0   done=False action=1 observation=[-0.01169576 -0.35183093  0.10441583  0.67818336]\n",
      "[CartPole-v0 2:11 :7  ] train iteration=3  step=61   reward=1.0   done=False action=0 observation=[-0.01873238 -0.54823661  0.1179795   1.00182984]\n",
      "[CartPole-v0 2:11 :8  ] train iteration=3  step=62   reward=1.0   done=False action=1 observation=[-0.02969711 -0.35487177  0.13801609  0.74840441]\n",
      "[CartPole-v0 2:11 :9  ] train iteration=3  step=63   reward=1.0   done=False action=0 observation=[-0.03679455 -0.5516004   0.15298418  1.0811393 ]\n",
      "[CartPole-v0 2:11 :10 ] train iteration=3  step=64   reward=1.0   done=False action=0 observation=[-0.04782656 -0.74837416  0.17460697  1.4176548 ]\n",
      "[CartPole-v0 2:11 :11 ] train iteration=3  step=65   reward=1.0   done=False action=0 observation=[-0.06279404 -0.94517445  0.20296006  1.75944068]\n",
      "[CartPole-v0 2:12 :12 ] train iteration=3  step=66   reward=1.0   done=True  action=0 observation=[-0.08169753 -1.14193414  0.23814888  2.10778368]\n",
      "[CartPole-v0 3:3  :1  ] train iteration=4  step=66  play  episode=0  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[-0.00344703  0.20741807  0.0451034  -0.25832186]\n",
      "[CartPole-v0 3:3  :2  ] train iteration=4  step=66  play  episode=0  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[0.00070133 0.01168219 0.03993696 0.04823926]\n",
      "[CartPole-v0 3:3  :3  ] train iteration=4  step=66  play  episode=0  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 0.00093498  0.2062094   0.04090175 -0.23158054]\n",
      "[CartPole-v0 3:3  :4  ] train iteration=4  step=66  play  episode=0  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[0.00505916 0.01052759 0.03627014 0.07371844]\n",
      "[CartPole-v0 3:3  :5  ] train iteration=4  step=66  play  episode=0  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[ 0.00526972  0.2051113   0.0377445  -0.20730408]\n",
      "[CartPole-v0 3:3  :6  ] train iteration=4  step=66  play  episode=0  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[0.00937194 0.00947052 0.03359842 0.09704233]\n",
      "[CartPole-v0 3:3  :7  ] train iteration=4  step=66  play  episode=0  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=1 observation=[ 0.00956135  0.20409522  0.03553927 -0.18485388]\n",
      "[CartPole-v0 3:3  :8  ] train iteration=4  step=66  play  episode=0  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=0 observation=[0.01364326 0.00848327 0.03184219 0.11882511]\n",
      "[CartPole-v0 3:3  :9  ] train iteration=4  step=66  play  episode=0  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[ 0.01381292  0.20313487  0.03421869 -0.16364426]\n",
      "[CartPole-v0 3:3  :10 ] train iteration=4  step=66  play  episode=0  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[0.01787562 0.0075402  0.03094581 0.13963433]\n",
      "[CartPole-v0 3:3  :11 ] train iteration=4  step=66  play  episode=0  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=1 observation=[ 0.01802642  0.20220558  0.0337385  -0.14312732]\n",
      "[CartPole-v0 3:3  :12 ] train iteration=4  step=66  play  episode=0  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=0 observation=[0.02207053 0.00661709 0.03087595 0.16000568]\n",
      "[CartPole-v0 3:3  :13 ] train iteration=4  step=66  play  episode=0  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=1 observation=[ 0.02220288  0.20128372  0.03407606 -0.12277899]\n",
      "[CartPole-v0 3:3  :14 ] train iteration=4  step=66  play  episode=0  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=0 observation=[0.02622855 0.00569056 0.03162048 0.18045685]\n",
      "[CartPole-v0 3:3  :15 ] train iteration=4  step=66  play  episode=0  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[ 0.02634236  0.20034609  0.03522962 -0.10208562]\n",
      "[CartPole-v0 3:3  :16 ] train iteration=4  step=66  play  episode=0  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[0.03034928 0.00473743 0.03318791 0.20150068]\n",
      "[CartPole-v0 3:3  :17 ] train iteration=4  step=66  play  episode=0  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=1 observation=[ 0.03044403  0.1993694   0.03721792 -0.08053106]\n",
      "[CartPole-v0 3:3  :18 ] train iteration=4  step=66  play  episode=0  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=0 observation=[0.03443142 0.00373424 0.0356073  0.22365801]\n",
      "[CartPole-v0 3:3  :19 ] train iteration=4  step=66  play  episode=0  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=1 observation=[ 0.03450611  0.19832965  0.04008046 -0.05758376]\n",
      "[CartPole-v0 3:3  :20 ] train iteration=4  step=66  play  episode=0  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=0 observation=[0.0384727  0.00265662 0.03892878 0.24747057]\n",
      "[CartPole-v0 3:3  :21 ] train iteration=4  step=66  play  episode=0  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=1 observation=[ 0.03852583  0.19720161  0.0438782  -0.03268364]\n",
      "[CartPole-v0 3:3  :22 ] train iteration=4  step=66  play  episode=0  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=0 observation=[0.04246986 0.00147878 0.04322452 0.27351406]\n",
      "[CartPole-v0 3:3  :23 ] train iteration=4  step=66  play  episode=0  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=1 observation=[ 0.04249944  0.19595819  0.0486948  -0.00522851]\n",
      "[CartPole-v0 3:3  :24 ] train iteration=4  step=66  play  episode=0  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=0 observation=[4.64186021e-02 1.72929076e-04 4.85902346e-02 3.02411879e-01]\n",
      "[CartPole-v0 3:3  :25 ] train iteration=4  step=66  play  episode=0  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=1 observation=[0.04642206 0.1945699  0.05463847 0.0254405 ]\n",
      "[CartPole-v0 3:3  :26 ] train iteration=4  step=66  play  episode=0  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=0 observation=[ 0.05031346 -0.00129131  0.05514728  0.33484961]\n",
      "[CartPole-v0 3:3  :27 ] train iteration=4  step=66  play  episode=0  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=1 observation=[0.05028763 0.19300418 0.06184427 0.0600545 ]\n",
      "[CartPole-v0 3:3  :28 ] train iteration=4  step=66  play  episode=0  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=0 observation=[ 0.05414772 -0.00294746  0.06304536  0.37159068]\n",
      "[CartPole-v0 3:3  :29 ] train iteration=4  step=66  play  episode=0  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=1 observation=[0.05408877 0.19122481 0.07047718 0.09943397]\n",
      "[CartPole-v0 3:3  :30 ] train iteration=4  step=66  play  episode=0  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=0 observation=[ 0.05791326 -0.00483272  0.07246586  0.41349336]\n",
      "[CartPole-v0 3:3  :31 ] train iteration=4  step=66  play  episode=0  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=1 observation=[0.05781661 0.18919125 0.08073572 0.14450754]\n",
      "[CartPole-v0 3:3  :32 ] train iteration=4  step=66  play  episode=0  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=1 observation=[ 0.06160043  0.38306973  0.08362588 -0.12165236]\n",
      "[CartPole-v0 3:3  :33 ] train iteration=4  step=66  play  episode=0  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[0.06926183 0.18685543 0.08119283 0.19619792]\n",
      "[CartPole-v0 3:3  :34 ] train iteration=4  step=66  play  episode=0  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[ 0.07299894  0.3807278   0.08511679 -0.06980814]\n",
      "[CartPole-v0 3:3  :35 ] train iteration=4  step=66  play  episode=0  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[0.08061349 0.18449521 0.08372062 0.24846925]\n",
      "[CartPole-v0 3:3  :36 ] train iteration=4  step=66  play  episode=0  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=1 observation=[ 0.0843034   0.37832795  0.08869001 -0.01667638]\n",
      "[CartPole-v0 3:3  :37 ] train iteration=4  step=66  play  episode=0  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=0 observation=[0.09186996 0.18205341 0.08835648 0.30261897]\n",
      "[CartPole-v0 3:3  :38 ] train iteration=4  step=66  play  episode=0  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=1 observation=[0.09551102 0.37581227 0.09440886 0.03905744]\n",
      "[CartPole-v0 3:3  :39 ] train iteration=4  step=66  play  episode=0  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=0 observation=[0.10302727 0.1794722  0.09519001 0.35997103]\n",
      "[CartPole-v0 3:3  :40 ] train iteration=4  step=66  play  episode=0  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=1 observation=[0.10661671 0.37312123 0.10238943 0.09875612]\n",
      "[CartPole-v0 3:3  :41 ] train iteration=4  step=66  play  episode=0  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[0.11407914 0.17669223 0.10436455 0.42190643]\n",
      "[CartPole-v0 3:3  :42 ] train iteration=4  step=66  play  episode=0  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[0.11761298 0.37019272 0.11280268 0.16386246]\n",
      "[CartPole-v0 3:3  :43 ] train iteration=4  step=66  play  episode=0  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=1 observation=[ 0.12501684  0.56353431  0.11607993 -0.09121304]\n",
      "[CartPole-v0 3:3  :44 ] train iteration=4  step=66  play  episode=0  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=0 observation=[0.13628752 0.3669564  0.11425567 0.23572036]\n",
      "[CartPole-v0 3:3  :45 ] train iteration=4  step=66  play  episode=0  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[ 0.14362665  0.5602763   0.11897008 -0.01885068]\n",
      "[CartPole-v0 3:3  :46 ] train iteration=4  step=66  play  episode=0  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[0.15483218 0.3636669  0.11859306 0.30887355]\n",
      "[CartPole-v0 3:3  :47 ] train iteration=4  step=66  play  episode=0  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=1 observation=[0.16210552 0.55691703 0.12477053 0.05581911]\n",
      "[CartPole-v0 3:3  :48 ] train iteration=4  step=66  play  episode=0  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=0 observation=[0.17324386 0.36024744 0.12588692 0.38511763]\n",
      "[CartPole-v0 3:3  :49 ] train iteration=4  step=66  play  episode=0  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=1 observation=[0.18044881 0.5533784  0.13358927 0.13462672]\n",
      "[CartPole-v0 3:4  :50 ] train iteration=4  step=66  play  episode=0  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[ 0.19151637  0.74635906  0.1362818  -0.11310661]\n",
      "[CartPole-v0 3:4  :1  ] train iteration=4  step=66  play  episode=1  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[-0.00384741  0.23602739 -0.04506642 -0.26458976]\n",
      "[CartPole-v0 3:4  :2  ] train iteration=4  step=66  play  episode=1  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[ 0.00087314  0.04157668 -0.05035822  0.01354511]\n",
      "[CartPole-v0 3:4  :3  ] train iteration=4  step=66  play  episode=1  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=0 observation=[ 0.00170468 -0.15278825 -0.05008731  0.28992386]\n",
      "[CartPole-v0 3:4  :4  ] train iteration=4  step=66  play  episode=1  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=1 observation=[-0.00135109  0.04301081 -0.04428884 -0.01812591]\n",
      "[CartPole-v0 3:4  :5  ] train iteration=4  step=66  play  episode=1  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=0 observation=[-0.00049087 -0.15144893 -0.04465135  0.26026101]\n",
      "[CartPole-v0 3:4  :6  ] train iteration=4  step=66  play  episode=1  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=1 observation=[-0.00351985  0.04428105 -0.03944613 -0.04616447]\n",
      "[CartPole-v0 3:4  :7  ] train iteration=4  step=66  play  episode=1  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[-0.00263423 -0.15025372 -0.04036942  0.23381653]\n",
      "[CartPole-v0 3:4  :8  ] train iteration=4  step=66  play  episode=1  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[-0.00563931  0.04542109 -0.03569309 -0.07132193]\n",
      "[CartPole-v0 3:4  :9  ] train iteration=4  step=66  play  episode=1  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=0 observation=[-0.00473088 -0.14917145 -0.03711953  0.20988942]\n",
      "[CartPole-v0 3:4  :10 ] train iteration=4  step=66  play  episode=1  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=1 observation=[-0.00771431  0.04646105 -0.03292174 -0.09426782]\n",
      "[CartPole-v0 3:4  :11 ] train iteration=4  step=66  play  episode=1  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[-0.00678509 -0.14817395 -0.0348071   0.18784923]\n",
      "[CartPole-v0 3:4  :12 ] train iteration=4  step=66  play  episode=1  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[-0.00974857  0.04742825 -0.03105011 -0.11560757]\n",
      "[CartPole-v0 3:4  :13 ] train iteration=4  step=66  play  episode=1  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[-0.00880001 -0.14723536 -0.03336227  0.16711983]\n",
      "[CartPole-v0 3:4  :14 ] train iteration=4  step=66  play  episode=1  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[-0.01174471  0.04834787 -0.03001987 -0.13589845]\n",
      "[CartPole-v0 3:4  :15 ] train iteration=4  step=66  play  episode=1  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=0 observation=[-0.01077776 -0.14633152 -0.03273784  0.14716455]\n",
      "[CartPole-v0 3:4  :16 ] train iteration=4  step=66  play  episode=1  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=1 observation=[-0.01370439  0.04924358 -0.02979455 -0.15566412]\n",
      "[CartPole-v0 3:4  :17 ] train iteration=4  step=66  play  episode=1  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[-0.01271951 -0.14543939 -0.03290783  0.12747243]\n",
      "[CartPole-v0 3:4  :18 ] train iteration=4  step=66  play  episode=1  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[-0.0156283   0.05013816 -0.03035838 -0.17540821]\n",
      "[CartPole-v0 3:4  :19 ] train iteration=4  step=66  play  episode=1  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[-0.01462554 -0.14453647 -0.03386655  0.10754518]\n",
      "[CartPole-v0 3:4  :20 ] train iteration=4  step=66  play  episode=1  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[-0.01751627  0.05105402 -0.03171564 -0.19562718]\n",
      "[CartPole-v0 3:4  :21 ] train iteration=4  step=66  play  episode=1  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[-0.01649519 -0.14360025 -0.03562819  0.08688455]\n",
      "[CartPole-v0 3:4  :22 ] train iteration=4  step=66  play  episode=1  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[-0.01936719  0.05201381 -0.03389049 -0.21682279]\n",
      "[CartPole-v0 3:4  :23 ] train iteration=4  step=66  play  episode=1  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[-0.01832692 -0.14260768 -0.03822695  0.06497991]\n",
      "[CartPole-v0 3:4  :24 ] train iteration=4  step=66  play  episode=1  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[-0.02117907  0.0530409  -0.03692735 -0.23951455]\n",
      "[CartPole-v0 3:4  :25 ] train iteration=4  step=66  play  episode=1  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[-0.02011825 -0.1415346  -0.04171764  0.04129555]\n",
      "[CartPole-v0 3:4  :26 ] train iteration=4  step=66  play  episode=1  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=1 observation=[-0.02294894  0.05415997 -0.04089173 -0.26425234]\n",
      "[CartPole-v0 3:4  :27 ] train iteration=4  step=66  play  episode=1  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[-0.02186574 -0.14035518 -0.04617678  0.01525767]\n",
      "[CartPole-v0 3:4  :28 ] train iteration=4  step=66  play  episode=1  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[-0.02467285  0.05539754 -0.04587163 -0.29162957]\n",
      "[CartPole-v0 3:4  :29 ] train iteration=4  step=66  play  episode=1  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[-0.0235649  -0.13904136 -0.05170422 -0.01375956]\n",
      "[CartPole-v0 3:4  :30 ] train iteration=4  step=66  play  episode=1  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[-0.02634572  0.05678251 -0.05197941 -0.32229708]\n",
      "[CartPole-v0 3:4  :31 ] train iteration=4  step=66  play  episode=1  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=0 observation=[-0.02521007 -0.1375622  -0.05842535 -0.04644881]\n",
      "[CartPole-v0 3:4  :32 ] train iteration=4  step=66  play  episode=1  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=1 observation=[-0.02796132  0.05834675 -0.05935433 -0.35697811]\n",
      "[CartPole-v0 3:4  :33 ] train iteration=4  step=66  play  episode=1  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[-0.02679438 -0.13588334 -0.06649389 -0.08358595]\n",
      "[CartPole-v0 3:4  :34 ] train iteration=4  step=66  play  episode=1  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[-0.02951205  0.06012565 -0.06816561 -0.39648449]\n",
      "[CartPole-v0 3:4  :35 ] train iteration=4  step=66  play  episode=1  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[-0.02830954 -0.13396629 -0.0760953  -0.12604789]\n",
      "[CartPole-v0 3:4  :36 ] train iteration=4  step=66  play  episode=1  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=0 observation=[-0.03098886 -0.32792029 -0.07861626  0.14169077]\n",
      "[CartPole-v0 3:4  :37 ] train iteration=4  step=66  play  episode=1  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.03754727 -0.13176557 -0.07578244 -0.1747219 ]\n",
      "[CartPole-v0 3:4  :38 ] train iteration=4  step=66  play  episode=1  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.04018258 -0.32572575 -0.07927688  0.09312462]\n",
      "[CartPole-v0 3:4  :39 ] train iteration=4  step=66  play  episode=1  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=1 observation=[-0.0466971  -0.1295623  -0.07741439 -0.2234794 ]\n",
      "[CartPole-v0 3:4  :40 ] train iteration=4  step=66  play  episode=1  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[-0.04928834 -0.32349734 -0.08188397  0.04381481]\n",
      "[CartPole-v0 3:4  :41 ] train iteration=4  step=66  play  episode=1  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=1 observation=[-0.05575829 -0.12730249 -0.08100768 -0.2735384 ]\n",
      "[CartPole-v0 3:4  :42 ] train iteration=4  step=66  play  episode=1  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=0 observation=[-0.05830434 -0.32118077 -0.08647845 -0.00746489]\n",
      "[CartPole-v0 3:4  :43 ] train iteration=4  step=66  play  episode=1  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=1 observation=[-0.06472795 -0.12493189 -0.08662774 -0.32613114]\n",
      "[CartPole-v0 3:4  :44 ] train iteration=4  step=66  play  episode=1  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=0 observation=[-0.06722659 -0.31872051 -0.09315037 -0.06197493]\n",
      "[CartPole-v0 3:4  :45 ] train iteration=4  step=66  play  episode=1  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[-0.073601   -0.122395   -0.09438986 -0.38253311]\n",
      "[CartPole-v0 3:4  :46 ] train iteration=4  step=66  play  episode=1  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[-0.0760489  -0.31605887 -0.10204053 -0.12103986]\n",
      "[CartPole-v0 3:4  :47 ] train iteration=4  step=66  play  episode=1  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=1 observation=[-0.08237008 -0.11963423 -0.10446132 -0.44409211]\n",
      "[CartPole-v0 3:4  :48 ] train iteration=4  step=66  play  episode=1  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=0 observation=[-0.08476276 -0.31313505 -0.11334317 -0.18607887]\n",
      "[CartPole-v0 3:4  :49 ] train iteration=4  step=66  play  episode=1  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=1 observation=[-0.09102546 -0.11658926 -0.11706474 -0.51225745]\n",
      "[CartPole-v0 3:5  :50 ] train iteration=4  step=66  play  episode=1  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=0 observation=[-0.09335725 -0.30988459 -0.12730989 -0.25863738]\n",
      "[CartPole-v0 3:5  :1  ] train iteration=4  step=66  play  episode=2  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[ 0.02719217  0.14678731 -0.00691121 -0.27544406]\n",
      "[CartPole-v0 3:5  :2  ] train iteration=4  step=66  play  episode=2  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[ 0.03012792 -0.04823536 -0.0124201   0.01505108]\n",
      "[CartPole-v0 3:5  :3  ] train iteration=4  step=66  play  episode=2  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 0.02916321  0.14706249 -0.01211907 -0.28152452]\n",
      "[CartPole-v0 3:5  :4  ] train iteration=4  step=66  play  episode=2  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[ 0.03210446 -0.04788451 -0.01774956  0.0073116 ]\n",
      "[CartPole-v0 3:5  :5  ] train iteration=4  step=66  play  episode=2  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[ 0.03114677  0.14748743 -0.01760333 -0.29091826]\n",
      "[CartPole-v0 3:5  :6  ] train iteration=4  step=66  play  episode=2  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[ 0.03409652 -0.04737915 -0.0234217  -0.00383879]\n",
      "[CartPole-v0 3:5  :7  ] train iteration=4  step=66  play  episode=2  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=1 observation=[ 0.03314893  0.14807074 -0.02349847 -0.30381856]\n",
      "[CartPole-v0 3:5  :8  ] train iteration=4  step=66  play  episode=2  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=0 observation=[ 0.03611035 -0.04670858 -0.02957484 -0.01863815]\n",
      "[CartPole-v0 3:5  :9  ] train iteration=4  step=66  play  episode=2  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[ 0.03517618  0.14882475 -0.02994761 -0.32050362]\n",
      "[CartPole-v0 3:5  :10 ] train iteration=4  step=66  play  episode=2  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[ 0.03815267 -0.0458582  -0.03635768 -0.03741343]\n",
      "[CartPole-v0 3:5  :11 ] train iteration=4  step=66  play  episode=2  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=1 observation=[ 0.03723551  0.14976576 -0.03710595 -0.34134224]\n",
      "[CartPole-v0 3:5  :12 ] train iteration=4  step=66  play  episode=2  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=0 observation=[ 0.04023082 -0.04480915 -0.04393279 -0.06058742]\n",
      "[CartPole-v0 3:5  :13 ] train iteration=4  step=66  play  episode=2  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=1 observation=[ 0.03933464  0.15091427 -0.04514454 -0.36680136]\n",
      "[CartPole-v0 3:5  :14 ] train iteration=4  step=66  play  episode=2  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=0 observation=[ 0.04235292 -0.04353807 -0.05248057 -0.08868802]\n",
      "[CartPole-v0 3:5  :15 ] train iteration=4  step=66  play  episode=2  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[ 0.04148216  0.15229531 -0.05425433 -0.39745587]\n",
      "[CartPole-v0 3:5  :16 ] train iteration=4  step=66  play  episode=2  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[ 0.04452807 -0.04201662 -0.06220345 -0.12235978]\n",
      "[CartPole-v0 3:5  :17 ] train iteration=4  step=66  play  episode=2  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[ 0.04368774 -0.23619479 -0.06465064  0.15006813]\n",
      "[CartPole-v0 3:5  :18 ] train iteration=4  step=66  play  episode=2  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[ 0.03896384 -0.04020951 -0.06164928 -0.16228968]\n",
      "[CartPole-v0 3:5  :19 ] train iteration=4  step=66  play  episode=2  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[ 0.03815965 -0.23439721 -0.06489507  0.1103251 ]\n",
      "[CartPole-v0 3:5  :20 ] train iteration=4  step=66  play  episode=2  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[ 0.03347171 -0.03840826 -0.06268857 -0.20210527]\n",
      "[CartPole-v0 3:5  :21 ] train iteration=4  step=66  play  episode=2  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[ 0.03270354 -0.23258025 -0.06673068  0.07016224]\n",
      "[CartPole-v0 3:5  :22 ] train iteration=4  step=66  play  episode=2  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[ 0.02805194 -0.03656821 -0.06532743 -0.24280569]\n",
      "[CartPole-v0 3:5  :23 ] train iteration=4  step=66  play  episode=2  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[ 0.02732057 -0.23069916 -0.07018355  0.02857697]\n",
      "[CartPole-v0 3:5  :24 ] train iteration=4  step=66  play  episode=2  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[ 0.02270659 -0.03464457 -0.06961201 -0.28539794]\n",
      "[CartPole-v0 3:5  :25 ] train iteration=4  step=66  play  episode=2  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[ 0.0220137  -0.22870824 -0.07531997 -0.01545687]\n",
      "[CartPole-v0 3:5  :26 ] train iteration=4  step=66  play  episode=2  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=0 observation=[ 0.01743953 -0.42267373 -0.0756291   0.25254333]\n",
      "[CartPole-v0 3:5  :27 ] train iteration=4  step=66  play  episode=2  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=1 observation=[ 0.00898606 -0.2265579  -0.07057824 -0.06300328]\n",
      "[CartPole-v0 3:5  :28 ] train iteration=4  step=66  play  episode=2  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=0 observation=[ 0.0044549  -0.42060068 -0.0718383   0.20660347]\n",
      "[CartPole-v0 3:5  :29 ] train iteration=4  step=66  play  episode=2  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=1 observation=[-0.00395711 -0.2245289  -0.06770623 -0.10784791]\n",
      "[CartPole-v0 3:5  :30 ] train iteration=4  step=66  play  episode=2  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[-0.00844769 -0.02850533 -0.06986319 -0.42110001]\n",
      "[CartPole-v0 3:5  :31 ] train iteration=4  step=66  play  episode=2  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=0 observation=[-0.0090178  -0.22257147 -0.07828519 -0.15123398]\n",
      "[CartPole-v0 3:5  :32 ] train iteration=4  step=66  play  episode=2  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=0 observation=[-0.01346923 -0.41649025 -0.08130987  0.11576096]\n",
      "[CartPole-v0 3:5  :33 ] train iteration=4  step=66  play  episode=2  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=1 observation=[-0.02179903 -0.22030308 -0.07899465 -0.2014263 ]\n",
      "[CartPole-v0 3:5  :34 ] train iteration=4  step=66  play  episode=2  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=0 observation=[-0.02620509 -0.41421161 -0.08302318  0.06532916]\n",
      "[CartPole-v0 3:5  :35 ] train iteration=4  step=66  play  episode=2  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=1 observation=[-0.03448933 -0.21800353 -0.08171659 -0.25235   ]\n",
      "[CartPole-v0 3:5  :36 ] train iteration=4  step=66  play  episode=2  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=0 observation=[-0.0388494  -0.41186931 -0.08676359  0.01348034]\n",
      "[CartPole-v0 3:5  :37 ] train iteration=4  step=66  play  episode=2  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.04708678 -0.21561712 -0.08649399 -0.30526711]\n",
      "[CartPole-v0 3:5  :38 ] train iteration=4  step=66  play  episode=2  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.05139912 -0.40940684 -0.09259933 -0.04106673]\n",
      "[CartPole-v0 3:5  :39 ] train iteration=4  step=66  play  episode=2  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=1 observation=[-0.05958726 -0.21308743 -0.09342066 -0.36146954]\n",
      "[CartPole-v0 3:5  :40 ] train iteration=4  step=66  play  episode=2  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[-0.06384901 -0.40676594 -0.10065006 -0.09964432]\n",
      "[CartPole-v0 3:5  :41 ] train iteration=4  step=66  play  episode=2  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=1 observation=[-0.07198433 -0.21035632 -0.10264294 -0.42230891]\n",
      "[CartPole-v0 3:5  :42 ] train iteration=4  step=66  play  episode=2  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=0 observation=[-0.07619146 -0.4038857  -0.11108912 -0.16366677]\n",
      "[CartPole-v0 3:5  :43 ] train iteration=4  step=66  play  episode=2  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=1 observation=[-0.08426917 -0.20736327 -0.11436246 -0.48922642]\n",
      "[CartPole-v0 3:5  :44 ] train iteration=4  step=66  play  episode=2  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=0 observation=[-0.08841643 -0.40070179 -0.12414698 -0.23466237]\n",
      "[CartPole-v0 3:5  :45 ] train iteration=4  step=66  play  episode=2  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[-0.09643047 -0.20404492 -0.12884023 -0.56378289]\n",
      "[CartPole-v0 3:5  :46 ] train iteration=4  step=66  play  episode=2  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[-0.10051137 -0.39714609 -0.14011589 -0.31430621]\n",
      "[CartPole-v0 3:5  :47 ] train iteration=4  step=66  play  episode=2  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=1 observation=[-0.10845429 -0.20033521 -0.14640201 -0.64768878]\n",
      "[CartPole-v0 3:5  :48 ] train iteration=4  step=66  play  episode=2  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=0 observation=[-0.11246099 -0.39314688 -0.15935579 -0.40445381]\n",
      "[CartPole-v0 3:5  :49 ] train iteration=4  step=66  play  episode=2  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=1 observation=[-0.12032393 -0.19616628 -0.16744486 -0.74283358]\n",
      "[CartPole-v0 3:6  :50 ] train iteration=4  step=66  play  episode=2  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=0 observation=[-0.12424726 -0.38863001 -0.18230154 -0.50717479]\n",
      "[CartPole-v0 2:12 :1  ] train iteration=4  step=1    reward=1.0   done=False action=0 observation=[ 0.00648396 -0.23746151  0.02922442  0.28708252]\n",
      "[CartPole-v0 2:12 :2  ] train iteration=4  step=2    reward=1.0   done=False action=0 observation=[ 0.00173473 -0.43298778  0.03496607  0.58883745]\n",
      "[CartPole-v0 2:12 :3  ] train iteration=4  step=3    reward=1.0   done=False action=0 observation=[-0.00692502 -0.62858147  0.04674282  0.89232658]\n",
      "[CartPole-v0 2:12 :4  ] train iteration=4  step=4    reward=1.0   done=False action=0 observation=[-0.01949665 -0.82430524  0.06458935  1.19932895]\n",
      "[CartPole-v0 2:12 :5  ] train iteration=4  step=5    reward=1.0   done=False action=0 observation=[-0.03598276 -1.02020063  0.08857593  1.5115354 ]\n",
      "[CartPole-v0 2:12 :6  ] train iteration=4  step=6    reward=1.0   done=False action=0 observation=[-0.05638677 -1.21627681  0.11880664  1.83050394]\n",
      "[CartPole-v0 2:12 :7  ] train iteration=4  step=7    reward=1.0   done=False action=0 observation=[-0.0807123  -1.41249746  0.15541672  2.15760715]\n",
      "[CartPole-v0 2:12 :8  ] train iteration=4  step=8    reward=1.0   done=False action=0 observation=[-0.10896225 -1.60876547  0.19856886  2.49396957]\n",
      "[CartPole-v0 2:13 :9  ] train iteration=4  step=9    reward=1.0   done=True  action=0 observation=[-0.14113756 -1.80490539  0.24844825  2.84039455]\n",
      "[CartPole-v0 2:13 :1  ] train iteration=4  step=10   reward=1.0   done=False action=0 observation=[ 0.04257711 -0.16977579 -0.04044967  0.30465062]\n",
      "[CartPole-v0 2:13 :2  ] train iteration=4  step=11   reward=1.0   done=False action=1 observation=[ 0.03918159  0.02589856 -0.03435666 -0.00050978]\n",
      "[CartPole-v0 2:13 :3  ] train iteration=4  step=12   reward=1.0   done=False action=0 observation=[ 0.03969956 -0.16871425 -0.03436685  0.28113829]\n",
      "[CartPole-v0 2:13 :4  ] train iteration=4  step=13   reward=1.0   done=False action=1 observation=[ 0.03632528  0.02688064 -0.02874409 -0.02218266]\n",
      "[CartPole-v0 2:13 :5  ] train iteration=4  step=14   reward=1.0   done=False action=0 observation=[ 0.03686289 -0.16781756 -0.02918774  0.26129439]\n",
      "[CartPole-v0 2:13 :6  ] train iteration=4  step=15   reward=1.0   done=False action=1 observation=[ 0.03350654  0.02770862 -0.02396185 -0.04044993]\n",
      "[CartPole-v0 2:13 :7  ] train iteration=4  step=16   reward=1.0   done=False action=1 observation=[ 0.03406071  0.22316584 -0.02477085 -0.34059571]\n",
      "[CartPole-v0 2:13 :8  ] train iteration=4  step=17   reward=1.0   done=False action=1 observation=[ 0.03852403  0.41863132 -0.03158277 -0.64098587]\n",
      "[CartPole-v0 2:13 :9  ] train iteration=4  step=18   reward=1.0   done=False action=1 observation=[ 0.04689665  0.61417899 -0.04440248 -0.94344488]\n",
      "[CartPole-v0 2:13 :10 ] train iteration=4  step=19   reward=1.0   done=False action=1 observation=[ 0.05918023  0.80987014 -0.06327138 -1.24974233]\n",
      "[CartPole-v0 2:13 :11 ] train iteration=4  step=20   reward=1.0   done=False action=0 observation=[ 0.07537764  0.61561366 -0.08826623 -0.97753003]\n",
      "[CartPole-v0 2:13 :12 ] train iteration=4  step=21   reward=1.0   done=False action=0 observation=[ 0.08768991  0.42177904 -0.10781683 -0.71382657]\n",
      "[CartPole-v0 2:13 :13 ] train iteration=4  step=22   reward=1.0   done=False action=0 observation=[ 0.09612549  0.22830182 -0.12209336 -0.45693268]\n",
      "[CartPole-v0 2:13 :14 ] train iteration=4  step=23   reward=1.0   done=False action=0 observation=[ 0.10069153  0.0350984  -0.13123201 -0.20509123]\n",
      "[CartPole-v0 2:13 :15 ] train iteration=4  step=24   reward=1.0   done=False action=1 observation=[ 0.1013935   0.23182902 -0.13533384 -0.53612132]\n",
      "[CartPole-v0 2:13 :16 ] train iteration=4  step=25   reward=1.0   done=False action=1 observation=[ 0.10603008  0.42856835 -0.14605626 -0.86819876]\n",
      "[CartPole-v0 2:13 :17 ] train iteration=4  step=26   reward=1.0   done=False action=0 observation=[ 0.11460144  0.23570329 -0.16342024 -0.62476942]\n",
      "[CartPole-v0 2:13 :18 ] train iteration=4  step=27   reward=1.0   done=False action=0 observation=[ 0.11931551  0.0431944  -0.17591563 -0.38768539]\n",
      "[CartPole-v0 2:13 :19 ] train iteration=4  step=28   reward=1.0   done=False action=1 observation=[ 0.1201794   0.24032007 -0.18366934 -0.7302633 ]\n",
      "[CartPole-v0 2:13 :20 ] train iteration=4  step=29   reward=1.0   done=False action=0 observation=[ 0.1249858   0.04814739 -0.1982746  -0.50054844]\n",
      "[CartPole-v0 2:13 :21 ] train iteration=4  step=30   reward=1.0   done=False action=0 observation=[ 0.12594875 -0.14370842 -0.20828557 -0.27631456]\n",
      "[CartPole-v0 2:14 :22 ] train iteration=4  step=31   reward=1.0   done=True  action=1 observation=[ 0.12307458  0.05368203 -0.21381186 -0.62679504]\n",
      "[CartPole-v0 2:14 :1  ] train iteration=4  step=32   reward=1.0   done=False action=1 observation=[-0.047718    0.1816533  -0.00634079 -0.29623005]\n",
      "[CartPole-v0 2:14 :2  ] train iteration=4  step=33   reward=1.0   done=False action=0 observation=[-0.04408493 -0.01337768 -0.01226539 -0.00555363]\n",
      "[CartPole-v0 2:14 :3  ] train iteration=4  step=34   reward=1.0   done=False action=0 observation=[-0.04435249 -0.2083216  -0.01237646  0.28323432]\n",
      "[CartPole-v0 2:14 :4  ] train iteration=4  step=35   reward=1.0   done=False action=1 observation=[-0.04851892 -0.01302533 -0.00671177 -0.01332624]\n",
      "[CartPole-v0 2:14 :5  ] train iteration=4  step=36   reward=1.0   done=False action=1 observation=[-0.04877942  0.18219223 -0.0069783  -0.30811923]\n",
      "[CartPole-v0 2:14 :6  ] train iteration=4  step=37   reward=1.0   done=False action=1 observation=[-0.04513558  0.37741292 -0.01314068 -0.60299473]\n",
      "[CartPole-v0 2:14 :7  ] train iteration=4  step=38   reward=1.0   done=False action=1 observation=[-0.03758732  0.57271617 -0.02520058 -0.89978757]\n",
      "[CartPole-v0 2:14 :8  ] train iteration=4  step=39   reward=1.0   done=False action=1 observation=[-0.026133    0.7681704  -0.04319633 -1.20028401]\n",
      "[CartPole-v0 2:14 :9  ] train iteration=4  step=40   reward=1.0   done=False action=1 observation=[-0.01076959  0.96382369 -0.06720201 -1.50618595]\n",
      "[CartPole-v0 2:14 :10 ] train iteration=4  step=41   reward=1.0   done=False action=1 observation=[ 0.00850688  1.15969327 -0.09732573 -1.81906966]\n",
      "[CartPole-v0 2:14 :11 ] train iteration=4  step=42   reward=1.0   done=False action=1 observation=[ 0.03170075  1.35575305 -0.13370712 -2.1403362 ]\n",
      "[CartPole-v0 2:14 :12 ] train iteration=4  step=43   reward=1.0   done=False action=0 observation=[ 0.05881581  1.16218179 -0.17651385 -1.89176376]\n",
      "[CartPole-v0 2:15 :13 ] train iteration=4  step=44   reward=1.0   done=True  action=1 observation=[ 0.08205945  1.35872641 -0.21434912 -2.23362578]\n",
      "[CartPole-v0 2:15 :1  ] train iteration=5  step=1    reward=1.0   done=False action=1 observation=[-0.04450532  0.22301279 -0.04892444 -0.31919023]\n",
      "[CartPole-v0 2:15 :2  ] train iteration=5  step=2    reward=1.0   done=False action=1 observation=[-0.04004506  0.41879615 -0.05530825 -0.62689192]\n",
      "[CartPole-v0 2:15 :3  ] train iteration=5  step=3    reward=1.0   done=False action=0 observation=[-0.03166914  0.22448803 -0.06784609 -0.35212776]\n",
      "[CartPole-v0 2:15 :4  ] train iteration=5  step=4    reward=1.0   done=False action=0 observation=[-0.02717938  0.03039318 -0.07488864 -0.08158675]\n",
      "[CartPole-v0 2:15 :5  ] train iteration=5  step=5    reward=1.0   done=False action=0 observation=[-0.02657151 -0.1635798  -0.07652038  0.18656052]\n",
      "[CartPole-v0 2:15 :6  ] train iteration=5  step=6    reward=1.0   done=False action=0 observation=[-0.02984311 -0.35752828 -0.07278917  0.45415688]\n",
      "[CartPole-v0 2:15 :7  ] train iteration=5  step=7    reward=1.0   done=False action=1 observation=[-0.03699367 -0.16145662 -0.06370603  0.13944706]\n",
      "[CartPole-v0 2:15 :8  ] train iteration=5  step=8    reward=1.0   done=False action=1 observation=[-0.04022281  0.03451717 -0.06091709 -0.17263423]\n",
      "[CartPole-v0 2:15 :9  ] train iteration=5  step=9    reward=1.0   done=False action=0 observation=[-0.03953246 -0.1596824  -0.06436977  0.10022627]\n",
      "[CartPole-v0 2:15 :10 ] train iteration=5  step=10   reward=1.0   done=False action=0 observation=[-0.04272611 -0.3538256  -0.06236525  0.3719263 ]\n",
      "[CartPole-v0 2:15 :11 ] train iteration=5  step=11   reward=1.0   done=False action=0 observation=[-0.04980262 -0.54800868 -0.05492672  0.64431116]\n",
      "[CartPole-v0 2:15 :12 ] train iteration=5  step=12   reward=1.0   done=False action=1 observation=[-0.0607628  -0.352166   -0.0420405   0.33484983]\n",
      "[CartPole-v0 2:15 :13 ] train iteration=5  step=13   reward=1.0   done=False action=1 observation=[-0.06780612 -0.15647173 -0.0353435   0.02921152]\n",
      "[CartPole-v0 2:15 :14 ] train iteration=5  step=14   reward=1.0   done=False action=1 observation=[-0.07093555  0.03913878 -0.03475927 -0.27440982]\n",
      "[CartPole-v0 2:15 :15 ] train iteration=5  step=15   reward=1.0   done=False action=1 observation=[-0.07015278  0.23473899 -0.04024747 -0.57785008]\n",
      "[CartPole-v0 2:15 :16 ] train iteration=5  step=16   reward=1.0   done=False action=0 observation=[-0.065458    0.04020356 -0.05180447 -0.2981128 ]\n",
      "[CartPole-v0 2:15 :17 ] train iteration=5  step=17   reward=1.0   done=False action=0 observation=[-0.06465393 -0.15414313 -0.05776672 -0.02220756]\n",
      "[CartPole-v0 2:15 :18 ] train iteration=5  step=18   reward=1.0   done=False action=1 observation=[-0.06773679  0.04175763 -0.05821087 -0.33254252]\n",
      "[CartPole-v0 2:15 :19 ] train iteration=5  step=19   reward=1.0   done=False action=0 observation=[-0.06690164 -0.15248955 -0.06486173 -0.05876961]\n",
      "[CartPole-v0 2:15 :20 ] train iteration=5  step=20   reward=1.0   done=False action=0 observation=[-0.06995143 -0.34662443 -0.06603712  0.21276441]\n",
      "[CartPole-v0 2:15 :21 ] train iteration=5  step=21   reward=1.0   done=False action=1 observation=[-0.07688391 -0.15062353 -0.06178183 -0.09999693]\n",
      "[CartPole-v0 2:15 :22 ] train iteration=5  step=22   reward=1.0   done=False action=1 observation=[-0.07989639  0.04532695 -0.06378177 -0.41151417]\n",
      "[CartPole-v0 2:15 :23 ] train iteration=5  step=23   reward=1.0   done=False action=0 observation=[-0.07898985 -0.14883557 -0.07201205 -0.13960173]\n",
      "[CartPole-v0 2:15 :24 ] train iteration=5  step=24   reward=1.0   done=False action=1 observation=[-0.08196656  0.04723993 -0.07480409 -0.45410597]\n",
      "[CartPole-v0 2:15 :25 ] train iteration=5  step=25   reward=1.0   done=False action=0 observation=[-0.08102176 -0.14674897 -0.08388621 -0.18590825]\n",
      "[CartPole-v0 2:15 :26 ] train iteration=5  step=26   reward=1.0   done=False action=0 observation=[-0.08395674 -0.34057677 -0.08760437  0.07917746]\n",
      "[CartPole-v0 2:15 :27 ] train iteration=5  step=27   reward=1.0   done=False action=1 observation=[-0.09076827 -0.14431532 -0.08602082 -0.23980853]\n",
      "[CartPole-v0 2:15 :28 ] train iteration=5  step=28   reward=1.0   done=False action=1 observation=[-0.09365458  0.05192341 -0.09081699 -0.55833717]\n",
      "[CartPole-v0 2:15 :29 ] train iteration=5  step=29   reward=1.0   done=False action=0 observation=[-0.09261611 -0.14181423 -0.10198373 -0.29559182]\n",
      "[CartPole-v0 2:15 :30 ] train iteration=5  step=30   reward=1.0   done=False action=0 observation=[-0.0954524  -0.33534561 -0.10789557 -0.03673436]\n",
      "[CartPole-v0 2:15 :31 ] train iteration=5  step=31   reward=1.0   done=False action=1 observation=[-0.10215931 -0.13885513 -0.10863026 -0.36141596]\n",
      "[CartPole-v0 2:15 :32 ] train iteration=5  step=32   reward=1.0   done=False action=1 observation=[-0.10493641  0.05762971 -0.11585858 -0.68628047]\n",
      "[CartPole-v0 2:15 :33 ] train iteration=5  step=33   reward=1.0   done=False action=1 observation=[-0.10378382  0.25415313 -0.12958419 -1.01307561]\n",
      "[CartPole-v0 2:15 :34 ] train iteration=5  step=34   reward=1.0   done=False action=1 observation=[-0.09870075  0.45074319 -0.1498457  -1.34347951]\n",
      "[CartPole-v0 2:15 :35 ] train iteration=5  step=35   reward=1.0   done=False action=1 observation=[-0.08968589  0.64739856 -0.17671529 -1.67904697]\n",
      "[CartPole-v0 2:16 :36 ] train iteration=5  step=36   reward=1.0   done=True  action=0 observation=[-0.07673792  0.45471074 -0.21029623 -1.4462008 ]\n",
      "[CartPole-v0 2:16 :1  ] train iteration=5  step=37   reward=1.0   done=False action=0 observation=[ 0.01319962 -0.18486501 -0.00309821  0.31524012]\n",
      "[CartPole-v0 2:16 :2  ] train iteration=5  step=38   reward=1.0   done=False action=1 observation=[0.00950232 0.01030094 0.00320659 0.02158174]\n",
      "[CartPole-v0 2:16 :3  ] train iteration=5  step=39   reward=1.0   done=False action=1 observation=[ 0.00970834  0.20537676  0.00363822 -0.27008775]\n",
      "[CartPole-v0 2:16 :4  ] train iteration=5  step=40   reward=1.0   done=False action=0 observation=[ 0.01381588  0.01020308 -0.00176353  0.02374047]\n",
      "[CartPole-v0 2:16 :5  ] train iteration=5  step=41   reward=1.0   done=False action=1 observation=[ 0.01401994  0.20535028 -0.00128872 -0.26949835]\n",
      "[CartPole-v0 2:16 :6  ] train iteration=5  step=42   reward=1.0   done=False action=1 observation=[ 0.01812694  0.40049059 -0.00667869 -0.56258747]\n",
      "[CartPole-v0 2:16 :7  ] train iteration=5  step=43   reward=1.0   done=False action=1 observation=[ 0.02613676  0.59570562 -0.01793044 -0.85736701]\n",
      "[CartPole-v0 2:16 :8  ] train iteration=5  step=44   reward=1.0   done=False action=0 observation=[ 0.03805087  0.40083249 -0.03507778 -0.57037556]\n",
      "[CartPole-v0 2:16 :9  ] train iteration=5  step=45   reward=1.0   done=False action=0 observation=[ 0.04606752  0.20621958 -0.04648529 -0.28894652]\n",
      "[CartPole-v0 2:16 :10 ] train iteration=5  step=46   reward=1.0   done=False action=1 observation=[ 0.05019191  0.40197252 -0.05226422 -0.5959205 ]\n",
      "[CartPole-v0 2:16 :11 ] train iteration=5  step=47   reward=1.0   done=False action=0 observation=[ 0.05823136  0.20761946 -0.06418263 -0.32014767]\n",
      "[CartPole-v0 2:16 :12 ] train iteration=5  step=48   reward=1.0   done=False action=1 observation=[ 0.06238375  0.40359396 -0.07058558 -0.63236089]\n",
      "[CartPole-v0 2:16 :13 ] train iteration=5  step=49   reward=1.0   done=False action=1 observation=[ 0.07045563  0.59962599 -0.0832328  -0.94641165]\n",
      "[CartPole-v0 2:16 :14 ] train iteration=5  step=50   reward=1.0   done=False action=0 observation=[ 0.08244815  0.40571763 -0.10216103 -0.68099823]\n",
      "[CartPole-v0 2:16 :15 ] train iteration=5  step=51   reward=1.0   done=False action=1 observation=[ 0.0905625   0.60209896 -0.115781   -1.00401748]\n",
      "[CartPole-v0 2:16 :16 ] train iteration=5  step=52   reward=1.0   done=False action=0 observation=[ 0.10260448  0.40869792 -0.13586135 -0.7498218 ]\n",
      "[CartPole-v0 2:16 :17 ] train iteration=5  step=53   reward=1.0   done=False action=1 observation=[ 0.11077844  0.60540609 -0.15085778 -1.08198554]\n",
      "[CartPole-v0 2:16 :18 ] train iteration=5  step=54   reward=1.0   done=False action=0 observation=[ 0.12288656  0.41256204 -0.17249749 -0.84018894]\n",
      "[CartPole-v0 2:16 :19 ] train iteration=5  step=55   reward=1.0   done=False action=0 observation=[ 0.1311378   0.22016172 -0.18930127 -0.60633467]\n",
      "[CartPole-v0 2:16 :20 ] train iteration=5  step=56   reward=1.0   done=False action=0 observation=[ 0.13554104  0.0281203  -0.20142797 -0.37874127]\n",
      "[CartPole-v0 2:16 :21 ] train iteration=5  step=57   reward=1.0   done=False action=0 observation=[ 0.13610344 -0.1636567  -0.20900279 -0.155712  ]\n",
      "[CartPole-v0 2:17 :22 ] train iteration=5  step=58   reward=1.0   done=True  action=0 observation=[ 0.13283031 -0.35526911 -0.21211703  0.06445145]\n",
      "[CartPole-v0 2:17 :1  ] train iteration=5  step=59   reward=1.0   done=False action=0 observation=[-0.00901395 -0.19560802 -0.01849655  0.24772046]\n",
      "[CartPole-v0 2:17 :2  ] train iteration=5  step=60   reward=1.0   done=False action=1 observation=[-0.01292611 -0.00022686 -0.01354214 -0.05073882]\n",
      "[CartPole-v0 2:17 :3  ] train iteration=5  step=61   reward=1.0   done=False action=0 observation=[-0.01293065 -0.19515204 -0.01455692  0.23764087]\n",
      "[CartPole-v0 2:17 :4  ] train iteration=5  step=62   reward=1.0   done=False action=0 observation=[-0.01683369 -0.39006303 -0.0098041   0.5256968 ]\n",
      "[CartPole-v0 2:17 :5  ] train iteration=5  step=63   reward=1.0   done=False action=0 observation=[-2.46349521e-02 -5.85045661e-01  7.09838136e-04  8.15274327e-01]\n",
      "[CartPole-v0 2:17 :6  ] train iteration=5  step=64   reward=1.0   done=False action=0 observation=[-0.03633587 -0.78017732  0.01701532  1.10818044]\n",
      "[CartPole-v0 2:17 :7  ] train iteration=5  step=65   reward=1.0   done=False action=1 observation=[-0.05193941 -0.58528309  0.03917893  0.82088368]\n",
      "[CartPole-v0 2:17 :8  ] train iteration=5  step=66   reward=1.0   done=False action=0 observation=[-0.06364507 -0.78091864  0.05559661  1.12562746]\n",
      "[CartPole-v0 2:17 :9  ] train iteration=5  step=67   reward=1.0   done=False action=1 observation=[-0.07926345 -0.58656761  0.07810916  0.85088833]\n",
      "[CartPole-v0 2:17 :10 ] train iteration=5  step=68   reward=1.0   done=False action=0 observation=[-0.0909948  -0.78266273  0.09512692  1.16707493]\n",
      "[CartPole-v0 2:17 :11 ] train iteration=5  step=69   reward=1.0   done=False action=0 observation=[-0.10664805 -0.97888497  0.11846842  1.48800272]\n",
      "[CartPole-v0 2:17 :12 ] train iteration=5  step=70   reward=1.0   done=False action=1 observation=[-0.12622575 -0.78538865  0.14822848  1.23454091]\n",
      "[CartPole-v0 2:17 :13 ] train iteration=5  step=71   reward=1.0   done=False action=0 observation=[-0.14193353 -0.98207192  0.17291929  1.56975041]\n",
      "[CartPole-v0 2:17 :14 ] train iteration=5  step=72   reward=1.0   done=False action=0 observation=[-0.16157496 -1.1787849   0.2043143   1.91100472]\n",
      "[CartPole-v0 2:18 :15 ] train iteration=5  step=73   reward=1.0   done=True  action=0 observation=[-0.18515066 -1.37544089  0.2425344   2.2595045 ]\n",
      "[CartPole-v0 2:18 :1  ] train iteration=6  step=1    reward=1.0   done=False action=1 observation=[-0.00649145  0.22647799 -0.0027861  -0.31866249]\n",
      "[CartPole-v0 2:18 :2  ] train iteration=6  step=2    reward=1.0   done=False action=0 observation=[-0.00196189  0.03139583 -0.00915935 -0.0268595 ]\n",
      "[CartPole-v0 2:18 :3  ] train iteration=6  step=3    reward=1.0   done=False action=1 observation=[-0.00133398  0.22664792 -0.00969654 -0.32241817]\n",
      "[CartPole-v0 2:18 :4  ] train iteration=6  step=4    reward=1.0   done=False action=0 observation=[ 0.00319898  0.03166539 -0.0161449  -0.03280884]\n",
      "[CartPole-v0 2:18 :5  ] train iteration=6  step=5    reward=1.0   done=False action=0 observation=[ 0.00383229 -0.16322137 -0.01680108  0.25473679]\n",
      "[CartPole-v0 2:18 :6  ] train iteration=6  step=6    reward=1.0   done=False action=1 observation=[ 0.00056786  0.03213639 -0.01170634 -0.04319778]\n",
      "[CartPole-v0 2:18 :7  ] train iteration=6  step=7    reward=1.0   done=False action=1 observation=[ 0.00121059  0.22742424 -0.0125703  -0.33955105]\n",
      "[CartPole-v0 2:18 :8  ] train iteration=6  step=8    reward=1.0   done=False action=0 observation=[ 0.00575907  0.03248338 -0.01936132 -0.05085845]\n",
      "[CartPole-v0 2:18 :9  ] train iteration=6  step=9    reward=1.0   done=False action=1 observation=[ 0.00640874  0.22787753 -0.02037849 -0.3495866 ]\n",
      "[CartPole-v0 2:18 :10 ] train iteration=6  step=10   reward=1.0   done=False action=1 observation=[ 0.01096629  0.42328329 -0.02737022 -0.64862524]\n",
      "[CartPole-v0 2:18 :11 ] train iteration=6  step=11   reward=1.0   done=False action=1 observation=[ 0.01943196  0.61877563 -0.04034272 -0.94979976]\n",
      "[CartPole-v0 2:18 :12 ] train iteration=6  step=12   reward=1.0   done=False action=1 observation=[ 0.03180747  0.81441674 -0.05933872 -1.2548802 ]\n",
      "[CartPole-v0 2:18 :13 ] train iteration=6  step=13   reward=1.0   done=False action=0 observation=[ 0.0480958   0.62010269 -0.08443632 -0.98135747]\n",
      "[CartPole-v0 2:18 :14 ] train iteration=6  step=14   reward=1.0   done=False action=0 observation=[ 0.06049786  0.4262076  -0.10406347 -0.71634579]\n",
      "[CartPole-v0 2:18 :15 ] train iteration=6  step=15   reward=1.0   done=False action=0 observation=[ 0.06902201  0.23266812 -0.11839039 -0.45814653]\n",
      "[CartPole-v0 2:18 :16 ] train iteration=6  step=16   reward=1.0   done=False action=0 observation=[ 0.07367537  0.03940134 -0.12755332 -0.20500117]\n",
      "[CartPole-v0 2:18 :17 ] train iteration=6  step=17   reward=1.0   done=False action=0 observation=[ 0.0744634  -0.15368768 -0.13165334  0.04488033]\n",
      "[CartPole-v0 2:18 :18 ] train iteration=6  step=18   reward=1.0   done=False action=0 observation=[ 0.07138965 -0.34670015 -0.13075573  0.29329925]\n",
      "[CartPole-v0 2:18 :19 ] train iteration=6  step=19   reward=1.0   done=False action=0 observation=[ 0.06445564 -0.539739   -0.12488975  0.542053  ]\n",
      "[CartPole-v0 2:18 :20 ] train iteration=6  step=20   reward=1.0   done=False action=0 observation=[ 0.05366086 -0.73290481 -0.11404869  0.79292278]\n",
      "[CartPole-v0 2:18 :21 ] train iteration=6  step=21   reward=1.0   done=False action=0 observation=[ 0.03900277 -0.92629183 -0.09819023  1.04766112]\n",
      "[CartPole-v0 2:18 :22 ] train iteration=6  step=22   reward=1.0   done=False action=0 observation=[ 0.02047693 -1.11998339 -0.07723701  1.30797745]\n",
      "[CartPole-v0 2:18 :23 ] train iteration=6  step=23   reward=1.0   done=False action=0 observation=[-0.00192274 -1.3140463  -0.05107746  1.57551886]\n",
      "[CartPole-v0 2:18 :24 ] train iteration=6  step=24   reward=1.0   done=False action=1 observation=[-0.02820366 -1.11835406 -0.01956708  1.26735308]\n",
      "[CartPole-v0 2:18 :25 ] train iteration=6  step=25   reward=1.0   done=False action=0 observation=[-0.05057074 -1.31322066  0.00577998  1.55384468]\n",
      "[CartPole-v0 2:18 :26 ] train iteration=6  step=26   reward=1.0   done=False action=1 observation=[-0.07683516 -1.11816847  0.03685687  1.26297057]\n",
      "[CartPole-v0 2:18 :27 ] train iteration=6  step=27   reward=1.0   done=False action=1 observation=[-0.09919853 -0.92353661  0.06211628  0.98205453]\n",
      "[CartPole-v0 2:18 :28 ] train iteration=6  step=28   reward=1.0   done=False action=1 observation=[-0.11766926 -0.72929957  0.08175737  0.70951132]\n",
      "[CartPole-v0 2:18 :29 ] train iteration=6  step=29   reward=1.0   done=False action=1 observation=[-0.13225525 -0.53539944  0.0959476   0.44364253]\n",
      "[CartPole-v0 2:18 :30 ] train iteration=6  step=30   reward=1.0   done=False action=1 observation=[-0.14296324 -0.34175673  0.10482045  0.18267978]\n",
      "[CartPole-v0 2:18 :31 ] train iteration=6  step=31   reward=1.0   done=False action=1 observation=[-0.14979837 -0.14827864  0.10847405 -0.07518365]\n",
      "[CartPole-v0 2:18 :32 ] train iteration=6  step=32   reward=1.0   done=False action=0 observation=[-0.15276395 -0.34477498  0.10697037  0.24965735]\n",
      "[CartPole-v0 2:18 :33 ] train iteration=6  step=33   reward=1.0   done=False action=1 observation=[-0.15965945 -0.15133032  0.11196352 -0.00746173]\n",
      "[CartPole-v0 2:18 :34 ] train iteration=6  step=34   reward=1.0   done=False action=1 observation=[-0.16268605  0.04202269  0.11181428 -0.26282672]\n",
      "[CartPole-v0 2:18 :35 ] train iteration=6  step=35   reward=1.0   done=False action=1 observation=[-0.1618456   0.23538576  0.10655775 -0.51825513]\n",
      "[CartPole-v0 2:18 :36 ] train iteration=6  step=36   reward=1.0   done=False action=0 observation=[-0.15713788  0.03893762  0.09619265 -0.19398556]\n",
      "[CartPole-v0 2:18 :37 ] train iteration=6  step=37   reward=1.0   done=False action=1 observation=[-0.15635913  0.23256136  0.09231294 -0.45484145]\n",
      "[CartPole-v0 2:18 :38 ] train iteration=6  step=38   reward=1.0   done=False action=1 observation=[-0.1517079   0.42626508  0.08321611 -0.71705843]\n",
      "[CartPole-v0 2:18 :39 ] train iteration=6  step=39   reward=1.0   done=False action=0 observation=[-0.1431826   0.23009606  0.06887494 -0.39938584]\n",
      "[CartPole-v0 2:18 :40 ] train iteration=6  step=40   reward=1.0   done=False action=0 observation=[-0.13858068  0.0340681   0.06088722 -0.08580784]\n",
      "[CartPole-v0 2:18 :41 ] train iteration=6  step=41   reward=1.0   done=False action=0 observation=[-0.13789932 -0.16187138  0.05917107  0.22544654]\n",
      "[CartPole-v0 2:18 :42 ] train iteration=6  step=42   reward=1.0   done=False action=1 observation=[-0.14113675  0.03235718  0.06368    -0.04800028]\n",
      "[CartPole-v0 2:18 :43 ] train iteration=6  step=43   reward=1.0   done=False action=1 observation=[-0.1404896   0.22651095  0.06271999 -0.31993137]\n",
      "[CartPole-v0 2:18 :44 ] train iteration=6  step=44   reward=1.0   done=False action=1 observation=[-0.13595938  0.4206862   0.05632136 -0.59219396]\n",
      "[CartPole-v0 2:18 :45 ] train iteration=6  step=45   reward=1.0   done=False action=0 observation=[-0.12754566  0.2248229   0.04447748 -0.28231513]\n",
      "[CartPole-v0 2:18 :46 ] train iteration=6  step=46   reward=1.0   done=False action=1 observation=[-0.1230492   0.41928315  0.03883118 -0.56064496]\n",
      "[CartPole-v0 2:18 :47 ] train iteration=6  step=47   reward=1.0   done=False action=1 observation=[-0.11466354  0.61383921  0.02761828 -0.84084557]\n",
      "[CartPole-v0 2:18 :48 ] train iteration=6  step=48   reward=1.0   done=False action=1 observation=[-0.10238676  0.80857346  0.01080137 -1.1247168 ]\n",
      "[CartPole-v0 2:18 :49 ] train iteration=6  step=49   reward=1.0   done=False action=0 observation=[-0.08621529  0.61331161 -0.01169297 -0.82866557]\n",
      "[CartPole-v0 2:19 :50 ] train iteration=6  step=50   reward=1.0   done=True  action=0 observation=[-0.07394905  0.41835145 -0.02826628 -0.53968298]\n",
      "[CartPole-v0 2:19 :1  ] train iteration=6  step=51   reward=1.0   done=False action=1 observation=[-0.04589619  0.17428554  0.01451498 -0.25352143]\n",
      "[CartPole-v0 2:19 :2  ] train iteration=6  step=52   reward=1.0   done=False action=0 observation=[-0.04241048 -0.02104063  0.00944455  0.04370421]\n",
      "[CartPole-v0 2:19 :3  ] train iteration=6  step=53   reward=1.0   done=False action=0 observation=[-0.04283129 -0.21629673  0.01031864  0.33935195]\n",
      "[CartPole-v0 2:19 :4  ] train iteration=6  step=54   reward=1.0   done=False action=1 observation=[-0.04715723 -0.02132311  0.01710568  0.04994072]\n",
      "[CartPole-v0 2:19 :5  ] train iteration=6  step=55   reward=1.0   done=False action=1 observation=[-0.04758369  0.17354944  0.01810449 -0.23729652]\n",
      "[CartPole-v0 2:19 :6  ] train iteration=6  step=56   reward=1.0   done=False action=0 observation=[-0.0441127  -0.02182642  0.01335856  0.06104167]\n",
      "[CartPole-v0 2:19 :7  ] train iteration=6  step=57   reward=1.0   done=False action=1 observation=[-0.04454923  0.17310148  0.01457939 -0.22739678]\n",
      "[CartPole-v0 2:19 :8  ] train iteration=6  step=58   reward=1.0   done=False action=1 observation=[-0.0410872   0.36801207  0.01003146 -0.51544541]\n",
      "[CartPole-v0 2:19 :9  ] train iteration=6  step=59   reward=1.0   done=False action=1 observation=[-3.37269591e-02  5.62991331e-01 -2.77451236e-04 -8.04950388e-01]\n",
      "[CartPole-v0 2:19 :10 ] train iteration=6  step=60   reward=1.0   done=False action=0 observation=[-0.02246713  0.36787318 -0.01637646 -0.51235475]\n",
      "[CartPole-v0 2:19 :11 ] train iteration=6  step=61   reward=1.0   done=False action=1 observation=[-0.01510967  0.56322193 -0.02662355 -0.81015304]\n",
      "[CartPole-v0 2:19 :12 ] train iteration=6  step=62   reward=1.0   done=False action=0 observation=[-0.00384523  0.36847467 -0.04282661 -0.52596207]\n",
      "[CartPole-v0 2:19 :13 ] train iteration=6  step=63   reward=1.0   done=False action=0 observation=[ 0.00352426  0.1739807  -0.05334586 -0.24707579]\n",
      "[CartPole-v0 2:19 :14 ] train iteration=6  step=64   reward=1.0   done=False action=0 observation=[ 0.00700388 -0.0203404  -0.05828737  0.02831496]\n",
      "[CartPole-v0 2:19 :15 ] train iteration=6  step=65   reward=1.0   done=False action=1 observation=[ 0.00659707  0.17556689 -0.05772107 -0.28217372]\n",
      "[CartPole-v0 2:19 :16 ] train iteration=6  step=66   reward=1.0   done=False action=1 observation=[ 0.01010841  0.37146263 -0.06336455 -0.59248853]\n",
      "[CartPole-v0 2:19 :17 ] train iteration=6  step=67   reward=1.0   done=False action=1 observation=[ 0.01753766  0.56741171 -0.07521432 -0.90443901]\n",
      "[CartPole-v0 2:19 :18 ] train iteration=6  step=68   reward=1.0   done=False action=0 observation=[ 0.02888589  0.37338458 -0.0933031  -0.63631332]\n",
      "[CartPole-v0 2:19 :19 ] train iteration=6  step=69   reward=1.0   done=False action=0 observation=[ 0.03635359  0.1796792  -0.10602936 -0.37441039]\n",
      "[CartPole-v0 2:19 :20 ] train iteration=6  step=70   reward=1.0   done=False action=0 observation=[ 0.03994717 -0.01378942 -0.11351757 -0.11695144]\n",
      "[CartPole-v0 2:19 :21 ] train iteration=6  step=71   reward=1.0   done=False action=0 observation=[ 0.03967138 -0.20711732 -0.1158566   0.13787142]\n",
      "[CartPole-v0 2:19 :22 ] train iteration=6  step=72   reward=1.0   done=False action=1 observation=[ 0.03552903 -0.01054299 -0.11309917 -0.18899905]\n",
      "[CartPole-v0 2:19 :23 ] train iteration=6  step=73   reward=1.0   done=False action=0 observation=[ 0.03531817 -0.20388048 -0.11687915  0.06597405]\n",
      "[CartPole-v0 2:19 :24 ] train iteration=6  step=74   reward=1.0   done=False action=1 observation=[ 0.03124056 -0.00729364 -0.11555967 -0.26117865]\n",
      "[CartPole-v0 2:19 :25 ] train iteration=6  step=75   reward=1.0   done=False action=0 observation=[ 0.03109469 -0.20059265 -0.12078325 -0.00706296]\n",
      "[CartPole-v0 2:19 :26 ] train iteration=6  step=76   reward=1.0   done=False action=0 observation=[ 0.02708284 -0.39379396 -0.12092451  0.24520368]\n",
      "[CartPole-v0 2:19 :27 ] train iteration=6  step=77   reward=1.0   done=False action=1 observation=[ 0.01920696 -0.19717106 -0.11602043 -0.08304214]\n",
      "[CartPole-v0 2:19 :28 ] train iteration=6  step=78   reward=1.0   done=False action=1 observation=[ 0.01526354 -0.00059363 -0.11768127 -0.4099595 ]\n",
      "[CartPole-v0 2:19 :29 ] train iteration=6  step=79   reward=1.0   done=False action=0 observation=[ 0.01525167 -0.1938677  -0.12588046 -0.15657204]\n",
      "[CartPole-v0 2:19 :30 ] train iteration=6  step=80   reward=1.0   done=False action=0 observation=[ 0.01137431 -0.38698362 -0.1290119   0.09389862]\n",
      "[CartPole-v0 2:19 :31 ] train iteration=6  step=81   reward=1.0   done=False action=1 observation=[ 0.00363464 -0.19027126 -0.12713393 -0.23654213]\n",
      "[CartPole-v0 2:19 :32 ] train iteration=6  step=82   reward=1.0   done=False action=0 observation=[-1.70785535e-04 -3.83369290e-01 -1.31864775e-01  1.34905062e-02]\n",
      "[CartPole-v0 2:19 :33 ] train iteration=6  step=83   reward=1.0   done=False action=0 observation=[-0.00783817 -0.57637783 -0.13159497  0.2618339 ]\n",
      "[CartPole-v0 2:19 :34 ] train iteration=6  step=84   reward=1.0   done=False action=0 observation=[-0.01936573 -0.76939983 -0.12635829  0.51028621]\n",
      "[CartPole-v0 2:19 :35 ] train iteration=6  step=85   reward=1.0   done=False action=1 observation=[-0.03475372 -0.57274549 -0.11615256  0.1806059 ]\n",
      "[CartPole-v0 2:19 :36 ] train iteration=6  step=86   reward=1.0   done=False action=0 observation=[-0.04620863 -0.76603032 -0.11254044  0.43450747]\n",
      "[CartPole-v0 2:19 :37 ] train iteration=6  step=87   reward=1.0   done=False action=0 observation=[-0.06152924 -0.95939412 -0.1038503   0.68970124]\n",
      "[CartPole-v0 2:19 :38 ] train iteration=6  step=88   reward=1.0   done=False action=0 observation=[-0.08071712 -1.15293331 -0.09005627  0.94796884]\n",
      "[CartPole-v0 2:19 :39 ] train iteration=6  step=89   reward=1.0   done=False action=1 observation=[-0.10377579 -0.95672177 -0.07109689  0.62840342]\n",
      "[CartPole-v0 2:19 :40 ] train iteration=6  step=90   reward=1.0   done=False action=1 observation=[-0.12291022 -0.76068337 -0.05852883  0.31420382]\n",
      "[CartPole-v0 2:19 :41 ] train iteration=6  step=91   reward=1.0   done=False action=1 observation=[-0.13812389 -0.56477863 -0.05224475  0.00365223]\n",
      "[CartPole-v0 2:19 :42 ] train iteration=6  step=92   reward=1.0   done=False action=1 observation=[-0.14941946 -0.36894785 -0.0521717  -0.3050461 ]\n",
      "[CartPole-v0 2:19 :43 ] train iteration=6  step=93   reward=1.0   done=False action=0 observation=[-0.15679842 -0.563289   -0.05827263 -0.02926254]\n",
      "[CartPole-v0 2:19 :44 ] train iteration=6  step=94   reward=1.0   done=False action=0 observation=[-0.1680642  -0.75752897 -0.05885788  0.24448041]\n",
      "[CartPole-v0 2:19 :45 ] train iteration=6  step=95   reward=1.0   done=False action=1 observation=[-0.18321478 -0.56161789 -0.05396827 -0.06617157]\n",
      "[CartPole-v0 2:19 :46 ] train iteration=6  step=96   reward=1.0   done=False action=1 observation=[-0.19444714 -0.36576539 -0.0552917  -0.37538157]\n",
      "[CartPole-v0 2:19 :47 ] train iteration=6  step=97   reward=1.0   done=False action=0 observation=[-0.20176245 -0.56006017 -0.06279933 -0.10063226]\n",
      "[CartPole-v0 2:19 :48 ] train iteration=6  step=98   reward=1.0   done=False action=1 observation=[-0.21296365 -0.36409704 -0.06481198 -0.41244838]\n",
      "[CartPole-v0 2:19 :49 ] train iteration=6  step=99   reward=1.0   done=False action=1 observation=[-0.22024559 -0.16811909 -0.07306094 -0.72483949]\n",
      "[CartPole-v0 2:20 :50 ] train iteration=6  step=100  reward=1.0   done=True  action=1 observation=[-0.22360797  0.02793308 -0.08755773 -1.03959403]\n",
      "[CartPole-v0 2:20 :1  ] train iteration=6  step=101  reward=1.0   done=False action=1 observation=[-0.02938871  0.18113548  0.02413068 -0.31075176]\n",
      "[CartPole-v0 2:20 :2  ] train iteration=6  step=102  reward=1.0   done=False action=0 observation=[-0.025766   -0.01432181  0.01791565 -0.01055745]\n",
      "[CartPole-v0 2:20 :3  ] train iteration=6  step=103  reward=1.0   done=False action=1 observation=[-0.02605244  0.18053868  0.0177045  -0.29753437]\n",
      "[CartPole-v0 2:20 :4  ] train iteration=6  step=104  reward=1.0   done=False action=1 observation=[-0.02244167  0.37540384  0.01175381 -0.58458144]\n",
      "[CartPole-v0 2:20 :5  ] train iteration=6  step=105  reward=1.0   done=False action=0 observation=[-1.49335898e-02  1.80119231e-01  6.21803334e-05 -2.88219221e-01]\n",
      "[CartPole-v0 2:20 :6  ] train iteration=6  step=106  reward=1.0   done=False action=1 observation=[-0.01133121  0.3752403  -0.0057022  -0.58088254]\n",
      "[CartPole-v0 2:20 :7  ] train iteration=6  step=107  reward=1.0   done=False action=1 observation=[-0.0038264   0.57044168 -0.01731985 -0.87535629]\n",
      "[CartPole-v0 2:20 :8  ] train iteration=6  step=108  reward=1.0   done=False action=1 observation=[ 0.00758243  0.76579474 -0.03482698 -1.17343371]\n",
      "[CartPole-v0 2:20 :9  ] train iteration=6  step=109  reward=1.0   done=False action=0 observation=[ 0.02289833  0.57114235 -0.05829565 -0.89186924]\n",
      "[CartPole-v0 2:20 :10 ] train iteration=6  step=110  reward=1.0   done=False action=1 observation=[ 0.03432118  0.76700459 -0.07613304 -1.20229275]\n",
      "[CartPole-v0 2:20 :11 ] train iteration=6  step=111  reward=1.0   done=False action=1 observation=[ 0.04966127  0.96302395 -0.10017889 -1.51783157]\n",
      "[CartPole-v0 2:20 :12 ] train iteration=6  step=112  reward=1.0   done=False action=1 observation=[ 0.06892175  1.15920465 -0.13053553 -1.84003059]\n",
      "[CartPole-v0 2:20 :13 ] train iteration=6  step=113  reward=1.0   done=False action=0 observation=[ 0.09210584  0.96574346 -0.16733614 -1.59057621]\n",
      "[CartPole-v0 2:20 :14 ] train iteration=6  step=114  reward=1.0   done=False action=1 observation=[ 0.11142071  1.16241041 -0.19914766 -1.9304236 ]\n",
      "[CartPole-v0 2:21 :15 ] train iteration=6  step=115  reward=1.0   done=True  action=1 observation=[ 0.13466892  1.35903118 -0.23775613 -2.27768878]\n",
      "[CartPole-v0 2:21 :1  ] train iteration=7  step=1    reward=1.0   done=False action=0 observation=[ 0.00722404 -0.17550065 -0.03192268  0.32143564]\n",
      "[CartPole-v0 2:21 :2  ] train iteration=7  step=2    reward=1.0   done=False action=1 observation=[ 0.00371403  0.02006101 -0.02549397  0.01885892]\n",
      "[CartPole-v0 2:21 :3  ] train iteration=7  step=3    reward=1.0   done=False action=0 observation=[ 0.00411525 -0.17468622 -0.02511679  0.30339044]\n",
      "[CartPole-v0 2:21 :4  ] train iteration=7  step=4    reward=1.0   done=False action=0 observation=[ 0.00062153 -0.36944138 -0.01904898  0.58804747]\n",
      "[CartPole-v0 2:21 :5  ] train iteration=7  step=5    reward=1.0   done=False action=0 observation=[-0.0067673  -0.56429146 -0.00728803  0.87466951]\n",
      "[CartPole-v0 2:21 :6  ] train iteration=7  step=6    reward=1.0   done=False action=1 observation=[-0.01805313 -0.36907119  0.01020536  0.57970421]\n",
      "[CartPole-v0 2:21 :7  ] train iteration=7  step=7    reward=1.0   done=False action=1 observation=[-0.02543455 -0.17409373  0.02179944  0.29025358]\n",
      "[CartPole-v0 2:21 :8  ] train iteration=7  step=8    reward=1.0   done=False action=0 observation=[-0.02891643 -0.36951963  0.02760451  0.58973131]\n",
      "[CartPole-v0 2:21 :9  ] train iteration=7  step=9    reward=1.0   done=False action=1 observation=[-0.03630682 -0.17479486  0.03939914  0.30587012]\n",
      "[CartPole-v0 2:21 :10 ] train iteration=7  step=10   reward=1.0   done=False action=1 observation=[-0.03980272  0.01974415  0.04551654  0.02586842]\n",
      "[CartPole-v0 2:21 :11 ] train iteration=7  step=11   reward=1.0   done=False action=0 observation=[-0.03940784 -0.176       0.04603391  0.33255778]\n",
      "[CartPole-v0 2:21 :12 ] train iteration=7  step=12   reward=1.0   done=False action=1 observation=[-0.04292784  0.01843753  0.05268507  0.05473965]\n",
      "[CartPole-v0 2:21 :13 ] train iteration=7  step=13   reward=1.0   done=False action=0 observation=[-0.04255909 -0.17739871  0.05377986  0.36356867]\n",
      "[CartPole-v0 2:21 :14 ] train iteration=7  step=14   reward=1.0   done=False action=0 observation=[-0.04610706 -0.37324212  0.06105123  0.67271272]\n",
      "[CartPole-v0 2:21 :15 ] train iteration=7  step=15   reward=1.0   done=False action=1 observation=[-0.0535719  -0.17901952  0.07450549  0.39985951]\n",
      "[CartPole-v0 2:21 :16 ] train iteration=7  step=16   reward=1.0   done=False action=1 observation=[-0.05715229  0.01497082  0.08250268  0.13156561]\n",
      "[CartPole-v0 2:21 :17 ] train iteration=7  step=17   reward=1.0   done=False action=0 observation=[-0.05685288 -0.18123009  0.08513399  0.44909421]\n",
      "[CartPole-v0 2:21 :18 ] train iteration=7  step=18   reward=1.0   done=False action=0 observation=[-0.06047748 -0.37744656  0.09411587  0.76735212]\n",
      "[CartPole-v0 2:21 :19 ] train iteration=7  step=19   reward=1.0   done=False action=0 observation=[-0.06802641 -0.57372948  0.10946292  1.08810273]\n",
      "[CartPole-v0 2:21 :20 ] train iteration=7  step=20   reward=1.0   done=False action=0 observation=[-0.079501   -0.7701111   0.13122497  1.41302999]\n",
      "[CartPole-v0 2:21 :21 ] train iteration=7  step=21   reward=1.0   done=False action=1 observation=[-0.09490322 -0.57683682  0.15948557  1.16408064]\n",
      "[CartPole-v0 2:21 :22 ] train iteration=7  step=22   reward=1.0   done=False action=0 observation=[-0.10643996 -0.77363432  0.18276718  1.50222081]\n",
      "[CartPole-v0 2:22 :23 ] train iteration=7  step=23   reward=1.0   done=True  action=1 observation=[-0.12191264 -0.58114066  0.2128116   1.27172434]\n",
      "[CartPole-v0 2:22 :1  ] train iteration=7  step=24   reward=1.0   done=False action=1 observation=[-0.02317509  0.19447801  0.02944519 -0.25700798]\n",
      "[CartPole-v0 2:22 :2  ] train iteration=7  step=25   reward=1.0   done=False action=1 observation=[-0.01928553  0.38916747  0.02430503 -0.54025994]\n",
      "[CartPole-v0 2:22 :3  ] train iteration=7  step=26   reward=1.0   done=False action=1 observation=[-0.01150218  0.58393949  0.01349983 -0.82518671]\n",
      "[CartPole-v0 2:22 :4  ] train iteration=7  step=27   reward=1.0   done=False action=1 observation=[ 1.76611922e-04  7.78874228e-01 -3.00390397e-03 -1.11359334e+00]\n",
      "[CartPole-v0 2:22 :5  ] train iteration=7  step=28   reward=1.0   done=False action=0 observation=[ 0.0157541   0.58379185 -0.02527577 -0.82185424]\n",
      "[CartPole-v0 2:22 :6  ] train iteration=7  step=29   reward=1.0   done=False action=1 observation=[ 0.02742993  0.77925035 -0.04171286 -1.12237863]\n",
      "[CartPole-v0 2:22 :7  ] train iteration=7  step=30   reward=1.0   done=False action=1 observation=[ 0.04301494  0.97489369 -0.06416043 -1.42784839]\n",
      "[CartPole-v0 2:22 :8  ] train iteration=7  step=31   reward=1.0   done=False action=0 observation=[ 0.06251281  0.78062028 -0.0927174  -1.15588809]\n",
      "[CartPole-v0 2:22 :9  ] train iteration=7  step=32   reward=1.0   done=False action=0 observation=[ 0.07812522  0.58682129 -0.11583516 -0.89365809]\n",
      "[CartPole-v0 2:22 :10 ] train iteration=7  step=33   reward=1.0   done=False action=0 observation=[ 0.08986165  0.39344472 -0.13370832 -0.63951651]\n",
      "[CartPole-v0 2:22 :11 ] train iteration=7  step=34   reward=1.0   done=False action=0 observation=[ 0.09773054  0.20041539 -0.14649865 -0.39175009]\n",
      "[CartPole-v0 2:22 :12 ] train iteration=7  step=35   reward=1.0   done=False action=1 observation=[ 0.10173885  0.39727961 -0.15433365 -0.72679999]\n",
      "[CartPole-v0 2:22 :13 ] train iteration=7  step=36   reward=1.0   done=False action=1 observation=[ 0.10968444  0.59416031 -0.16886965 -1.0638051 ]\n",
      "[CartPole-v0 2:22 :14 ] train iteration=7  step=37   reward=1.0   done=False action=1 observation=[ 0.12156765  0.79106579 -0.19014575 -1.40437399]\n",
      "[CartPole-v0 2:23 :15 ] train iteration=7  step=38   reward=1.0   done=True  action=1 observation=[ 0.13738896  0.98797111 -0.21823323 -1.74997525]\n",
      "[CartPole-v0 2:23 :1  ] train iteration=7  step=39   reward=1.0   done=False action=0 observation=[-0.00983232 -0.20795695  0.02817655  0.26935678]\n",
      "[CartPole-v0 2:23 :2  ] train iteration=7  step=40   reward=1.0   done=False action=0 observation=[-0.01399146 -0.40346943  0.03356369  0.57079191]\n",
      "[CartPole-v0 2:23 :3  ] train iteration=7  step=41   reward=1.0   done=False action=0 observation=[-0.02206085 -0.59904559  0.04497953  0.87385679]\n",
      "[CartPole-v0 2:23 :4  ] train iteration=7  step=42   reward=1.0   done=False action=1 observation=[-0.03404176 -0.40456312  0.06245666  0.59564765]\n",
      "[CartPole-v0 2:23 :5  ] train iteration=7  step=43   reward=1.0   done=False action=0 observation=[-0.04213302 -0.600501    0.07436961  0.90733175]\n",
      "[CartPole-v0 2:23 :6  ] train iteration=7  step=44   reward=1.0   done=False action=0 observation=[-0.05414304 -0.79654673  0.09251625  1.222432  ]\n",
      "[CartPole-v0 2:23 :7  ] train iteration=7  step=45   reward=1.0   done=False action=1 observation=[-0.07007397 -0.60273039  0.11696489  0.96011179]\n",
      "[CartPole-v0 2:23 :8  ] train iteration=7  step=46   reward=1.0   done=False action=1 observation=[-0.08212858 -0.40935837  0.13616713  0.70634494]\n",
      "[CartPole-v0 2:23 :9  ] train iteration=7  step=47   reward=1.0   done=False action=0 observation=[-0.09031575 -0.60607779  0.15029402  1.03860222]\n",
      "[CartPole-v0 2:23 :10 ] train iteration=7  step=48   reward=1.0   done=False action=0 observation=[-0.10243731 -0.80284252  0.17106607  1.37444244]\n",
      "[CartPole-v0 2:23 :11 ] train iteration=7  step=49   reward=1.0   done=False action=1 observation=[-0.11849416 -0.61022102  0.19855492  1.13977598]\n",
      "[CartPole-v0 2:24 :12 ] train iteration=7  step=50   reward=1.0   done=True  action=1 observation=[-0.13069858 -0.41816915  0.22135044  0.91535048]\n",
      "[CartPole-v0 3:6  :1  ] train iteration=8  step=50  play  episode=0  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[ 0.03702274  0.22412742  0.02434186 -0.32344455]\n",
      "[CartPole-v0 3:6  :2  ] train iteration=8  step=50  play  episode=0  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[ 0.04150529  0.02866746  0.01787297 -0.02318568]\n",
      "[CartPole-v0 3:6  :3  ] train iteration=8  step=50  play  episode=0  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 0.04207864  0.2235286   0.01740926 -0.31017632]\n",
      "[CartPole-v0 3:6  :4  ] train iteration=8  step=50  play  episode=0  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[ 0.04654921  0.02816299  0.01120573 -0.01205425]\n",
      "[CartPole-v0 3:6  :5  ] train iteration=8  step=50  play  episode=0  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[ 0.04711247  0.22312246  0.01096465 -0.30118068]\n",
      "[CartPole-v0 3:6  :6  ] train iteration=8  step=50  play  episode=0  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[ 0.05157492  0.02784596  0.00494103 -0.00506   ]\n",
      "[CartPole-v0 3:6  :7  ] train iteration=8  step=50  play  episode=0  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=1 observation=[ 0.05213184  0.2228967   0.00483983 -0.29617988]\n",
      "[CartPole-v0 3:6  :8  ] train iteration=8  step=50  play  episode=0  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=0 observation=[ 0.05658977  0.02770609 -0.00108376 -0.00197449]\n",
      "[CartPole-v0 3:6  :9  ] train iteration=8  step=50  play  episode=0  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[ 0.05714389  0.22284357 -0.00112325 -0.29499916]\n",
      "[CartPole-v0 3:6  :10 ] train iteration=8  step=50  play  episode=0  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[ 0.06160077  0.02773765 -0.00702324 -0.0026707 ]\n",
      "[CartPole-v0 3:6  :11 ] train iteration=8  step=50  play  episode=0  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=1 observation=[ 0.06215552  0.22295961 -0.00707665 -0.29756124]\n",
      "[CartPole-v0 3:6  :12 ] train iteration=8  step=50  play  episode=0  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=0 observation=[ 0.06661471  0.02793925 -0.01302788 -0.00711854]\n",
      "[CartPole-v0 3:6  :13 ] train iteration=8  step=50  play  episode=0  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=1 observation=[ 0.0671735   0.22324559 -0.01317025 -0.30388328]\n",
      "[CartPole-v0 3:6  :14 ] train iteration=8  step=50  play  episode=0  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=0 observation=[ 0.07163841  0.02831379 -0.01924791 -0.01538288]\n",
      "[CartPole-v0 3:6  :15 ] train iteration=8  step=50  play  episode=0  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[ 0.07220468  0.22370642 -0.01955557 -0.31407606]\n",
      "[CartPole-v0 3:6  :16 ] train iteration=8  step=50  play  episode=0  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[ 0.07667881  0.02886842 -0.02583709 -0.02762392]\n",
      "[CartPole-v0 3:6  :17 ] train iteration=8  step=50  play  episode=0  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=1 observation=[ 0.07725618  0.22435118 -0.02638957 -0.32834545]\n",
      "[CartPole-v0 3:6  :18 ] train iteration=8  step=50  play  episode=0  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=0 observation=[ 0.0817432   0.02961466 -0.03295648 -0.04410002]\n",
      "[CartPole-v0 3:6  :19 ] train iteration=8  step=50  play  episode=0  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=1 observation=[ 0.0823355   0.22519332 -0.03383848 -0.34699615]\n",
      "[CartPole-v0 3:6  :20 ] train iteration=8  step=50  play  episode=0  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=0 observation=[ 0.08683936  0.03056861 -0.0407784  -0.06517283]\n",
      "[CartPole-v0 3:6  :21 ] train iteration=8  step=50  play  episode=0  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=1 observation=[ 0.08745074  0.22625077 -0.04208186 -0.37043759]\n",
      "[CartPole-v0 3:6  :22 ] train iteration=8  step=50  play  episode=0  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=0 observation=[ 0.09197575  0.03175118 -0.04949061 -0.0913149 ]\n",
      "[CartPole-v0 3:6  :23 ] train iteration=8  step=50  play  episode=0  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=1 observation=[ 0.09261077  0.22754628 -0.05131691 -0.39919225]\n",
      "[CartPole-v0 3:6  :24 ] train iteration=8  step=50  play  episode=0  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=0 observation=[ 0.0971617   0.03318844 -0.05930075 -0.12311982]\n",
      "[CartPole-v0 3:6  :25 ] train iteration=8  step=50  play  episode=0  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[ 0.09782547 -0.161036   -0.06176315  0.15028053]\n",
      "[CartPole-v0 3:6  :26 ] train iteration=8  step=50  play  episode=0  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=1 observation=[ 0.09460475  0.03491349 -0.05875754 -0.16123009]\n",
      "[CartPole-v0 3:6  :27 ] train iteration=8  step=50  play  episode=0  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[ 0.09530302 -0.15932021 -0.06198214  0.11235289]\n",
      "[CartPole-v0 3:6  :28 ] train iteration=8  step=50  play  episode=0  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[ 0.09211661  0.0366326  -0.05973508 -0.19922299]\n",
      "[CartPole-v0 3:6  :29 ] train iteration=8  step=50  play  episode=0  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[ 0.09284927 -0.15758636 -0.06371954  0.07403416]\n",
      "[CartPole-v0 3:6  :30 ] train iteration=8  step=50  play  episode=0  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[ 0.08969754  0.03838847 -0.06223886 -0.23805238]\n",
      "[CartPole-v0 3:6  :31 ] train iteration=8  step=50  play  episode=0  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=0 observation=[ 0.09046531 -0.15579166 -0.06699991  0.03436744]\n",
      "[CartPole-v0 3:6  :32 ] train iteration=8  step=50  play  episode=0  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=1 observation=[ 0.08734948  0.04022393 -0.06631256 -0.2786795 ]\n",
      "[CartPole-v0 3:6  :33 ] train iteration=8  step=50  play  episode=0  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[ 0.08815395 -0.15389244 -0.07188615 -0.00762651]\n",
      "[CartPole-v0 3:6  :34 ] train iteration=8  step=50  play  episode=0  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[ 0.0850761   0.0421829  -0.07203868 -0.32209625]\n",
      "[CartPole-v0 3:6  :35 ] train iteration=8  step=50  play  episode=0  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[ 0.08591976 -0.15184322 -0.0784806  -0.05297299]\n",
      "[CartPole-v0 3:6  :36 ] train iteration=8  step=50  play  episode=0  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=1 observation=[ 0.0828829   0.04431121 -0.07954006 -0.3693486 ]\n",
      "[CartPole-v0 3:6  :37 ] train iteration=8  step=50  play  episode=0  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=0 observation=[ 0.08376912 -0.14959583 -0.08692704 -0.10276777]\n",
      "[CartPole-v0 3:6  :38 ] train iteration=8  step=50  play  episode=0  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=1 observation=[ 0.08077721  0.04665738 -0.08898239 -0.42156045]\n",
      "[CartPole-v0 3:6  :39 ] train iteration=8  step=50  play  episode=0  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=0 observation=[ 0.08171035 -0.14709861 -0.0974136  -0.15820262]\n",
      "[CartPole-v0 3:6  :40 ] train iteration=8  step=50  play  episode=0  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[ 0.07876838 -0.3407007  -0.10057765  0.1022294 ]\n",
      "[CartPole-v0 3:6  :41 ] train iteration=8  step=50  play  episode=0  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=1 observation=[ 0.07195437 -0.14429194 -0.09853306 -0.22041486]\n",
      "[CartPole-v0 3:6  :42 ] train iteration=8  step=50  play  episode=0  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=0 observation=[ 0.06906853 -0.33787749 -0.10294136  0.03963314]\n",
      "[CartPole-v0 3:6  :43 ] train iteration=8  step=50  play  episode=0  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=1 observation=[ 0.06231098 -0.14144155 -0.1021487  -0.28367227]\n",
      "[CartPole-v0 3:6  :44 ] train iteration=8  step=50  play  episode=0  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=0 observation=[ 0.05948215 -0.33496947 -0.10782214 -0.0248731 ]\n",
      "[CartPole-v0 3:6  :45 ] train iteration=8  step=50  play  episode=0  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[ 0.05278276 -0.13847972 -0.10831961 -0.34953448]\n",
      "[CartPole-v0 3:6  :46 ] train iteration=8  step=50  play  episode=0  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[ 0.05001316 -0.3319078  -0.1153103  -0.09287656]\n",
      "[CartPole-v0 3:6  :47 ] train iteration=8  step=50  play  episode=0  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=0 observation=[ 0.04337501 -0.52520439 -0.11716783  0.1613167 ]\n",
      "[CartPole-v0 3:6  :48 ] train iteration=8  step=50  play  episode=0  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=1 observation=[ 0.03287092 -0.32861696 -0.11394149 -0.16591124]\n",
      "[CartPole-v0 3:6  :49 ] train iteration=8  step=50  play  episode=0  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[ 0.02629858 -0.52193913 -0.11725972  0.08876531]\n",
      "[CartPole-v0 3:7  :50 ] train iteration=8  step=50  play  episode=0  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[ 0.0158598  -0.32534866 -0.11548441 -0.23849081]\n",
      "[CartPole-v0 3:7  :1  ] train iteration=8  step=50  play  episode=1  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[ 2.61865283e-04  1.71471112e-01 -1.88614158e-02 -3.15043135e-01]\n",
      "[CartPole-v0 3:7  :2  ] train iteration=8  step=50  play  episode=1  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[ 0.00369129 -0.02337716 -0.02516228 -0.02836764]\n",
      "[CartPole-v0 3:7  :3  ] train iteration=8  step=50  play  episode=1  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 0.00322374  0.17209643 -0.02572963 -0.32888214]\n",
      "[CartPole-v0 3:7  :4  ] train iteration=8  step=50  play  episode=1  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[ 0.00666567 -0.02264997 -0.03230727 -0.04442291]\n",
      "[CartPole-v0 3:7  :5  ] train iteration=8  step=50  play  episode=1  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=0 observation=[ 0.00621267 -0.21729411 -0.03319573  0.23789426]\n",
      "[CartPole-v0 3:7  :6  ] train iteration=8  step=50  play  episode=1  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=1 observation=[ 0.00186679 -0.02171403 -0.02843785 -0.06507199]\n",
      "[CartPole-v0 3:7  :7  ] train iteration=8  step=50  play  episode=1  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[ 0.00143251 -0.21641696 -0.02973929  0.21850472]\n",
      "[CartPole-v0 3:7  :8  ] train iteration=8  step=50  play  episode=1  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[-0.00289583 -0.02088279 -0.02536919 -0.08340891]\n",
      "[CartPole-v0 3:7  :9  ] train iteration=8  step=50  play  episode=1  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=0 observation=[-0.00331348 -0.21563207 -0.02703737  0.20116327]\n",
      "[CartPole-v0 3:7  :10 ] train iteration=8  step=50  play  episode=1  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=1 observation=[-0.00762613 -0.02013407 -0.02301411 -0.09992456]\n",
      "[CartPole-v0 3:7  :11 ] train iteration=8  step=50  play  episode=1  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[-0.00802881 -0.21491876 -0.0250126   0.18540955]\n",
      "[CartPole-v0 3:7  :12 ] train iteration=8  step=50  play  episode=1  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[-0.01232718 -0.01944802 -0.02130441 -0.11505778]\n",
      "[CartPole-v0 3:7  :13 ] train iteration=8  step=50  play  episode=1  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[-0.01271614 -0.21425834 -0.02360556  0.17082836]\n",
      "[CartPole-v0 3:7  :14 ] train iteration=8  step=50  play  episode=1  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[-0.01700131 -0.01880661 -0.02018899 -0.12920694]\n",
      "[CartPole-v0 3:7  :15 ] train iteration=8  step=50  play  episode=1  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=0 observation=[-0.01737744 -0.21363362 -0.02277313  0.15703886]\n",
      "[CartPole-v0 3:7  :16 ] train iteration=8  step=50  play  episode=1  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=1 observation=[-0.02165011 -0.01819315 -0.01963236 -0.14274056]\n",
      "[CartPole-v0 3:7  :17 ] train iteration=8  step=50  play  episode=1  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[-0.02201398 -0.21302851 -0.02248717  0.14368462]\n",
      "[CartPole-v0 3:7  :18 ] train iteration=8  step=50  play  episode=1  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[-0.02627455 -0.01759185 -0.01961347 -0.15600692]\n",
      "[CartPole-v0 3:7  :19 ] train iteration=8  step=50  play  episode=1  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[-0.02662638 -0.21242757 -0.02273361  0.13042446]\n",
      "[CartPole-v0 3:7  :20 ] train iteration=8  step=50  play  episode=1  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[-0.03087494 -0.01698747 -0.02012512 -0.16934305]\n",
      "[CartPole-v0 3:7  :21 ] train iteration=8  step=50  play  episode=1  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[-0.03121468 -0.21181566 -0.02351198  0.11692367]\n",
      "[CartPole-v0 3:7  :22 ] train iteration=8  step=50  play  episode=1  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[-0.035451   -0.01636486 -0.02117351 -0.18308339]\n",
      "[CartPole-v0 3:7  :23 ] train iteration=8  step=50  play  episode=1  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[-0.0357783  -0.21117754 -0.02483518  0.10284559]\n",
      "[CartPole-v0 3:7  :24 ] train iteration=8  step=50  play  episode=1  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[-0.04000185 -0.01570864 -0.02277827 -0.19756814]\n",
      "[CartPole-v0 3:7  :25 ] train iteration=8  step=50  play  episode=1  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[-0.04031602 -0.2104975  -0.02672963  0.08784313]\n",
      "[CartPole-v0 3:7  :26 ] train iteration=8  step=50  play  episode=1  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=1 observation=[-0.04452597 -0.01500281 -0.02497277 -0.21315173]\n",
      "[CartPole-v0 3:7  :27 ] train iteration=8  step=50  play  episode=1  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[-0.04482603 -0.20975899 -0.0292358   0.07155021]\n",
      "[CartPole-v0 3:7  :28 ] train iteration=8  step=50  play  episode=1  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[-0.0490212  -0.01423036 -0.0278048  -0.23021149]\n",
      "[CartPole-v0 3:7  :29 ] train iteration=8  step=50  play  episode=1  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[-0.04930581 -0.20894418 -0.03240903  0.05357279]\n",
      "[CartPole-v0 3:7  :30 ] train iteration=8  step=50  play  episode=1  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[-0.0534847  -0.01337288 -0.03133757 -0.2491567 ]\n",
      "[CartPole-v0 3:7  :31 ] train iteration=8  step=50  play  episode=1  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=0 observation=[-0.05375215 -0.20803361 -0.03632071  0.0334793 ]\n",
      "[CartPole-v0 3:7  :32 ] train iteration=8  step=50  play  episode=1  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=1 observation=[-0.05791283 -0.01241014 -0.03565112 -0.27043832]\n",
      "[CartPole-v0 3:7  :33 ] train iteration=8  step=50  play  episode=1  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[-0.05816103 -0.20700569 -0.04105989  0.01079031]\n",
      "[CartPole-v0 3:7  :34 ] train iteration=8  step=50  play  episode=1  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[-0.06230114 -0.01131967 -0.04084408 -0.29455953]\n",
      "[CartPole-v0 3:7  :35 ] train iteration=8  step=50  play  episode=1  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[-0.06252754 -0.20583624 -0.04673527 -0.01503285]\n",
      "[CartPole-v0 3:7  :36 ] train iteration=8  step=50  play  episode=1  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=1 observation=[-0.06664426 -0.01007628 -0.04703593 -0.32208732]\n",
      "[CartPole-v0 3:7  :37 ] train iteration=8  step=50  play  episode=1  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=0 observation=[-0.06684579 -0.20449798 -0.05347767 -0.04460079]\n",
      "[CartPole-v0 3:7  :38 ] train iteration=8  step=50  play  episode=1  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=1 observation=[-0.07093575 -0.00865158 -0.05436969 -0.35366535]\n",
      "[CartPole-v0 3:7  :39 ] train iteration=8  step=50  play  episode=1  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=0 observation=[-0.07110878 -0.20295997 -0.061443   -0.07861027]\n",
      "[CartPole-v0 3:7  :40 ] train iteration=8  step=50  play  episode=1  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=1 observation=[-0.07516798 -0.00701349 -0.0630152  -0.39002824]\n",
      "[CartPole-v0 3:7  :41 ] train iteration=8  step=50  play  episode=1  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[-0.07530825 -0.2011871  -0.07081577 -0.11786012]\n",
      "[CartPole-v0 3:7  :42 ] train iteration=8  step=50  play  episode=1  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[-0.07933199 -0.00512572 -0.07317297 -0.43201752]\n",
      "[CartPole-v0 3:7  :43 ] train iteration=8  step=50  play  episode=1  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=0 observation=[-0.0794345  -0.19913945 -0.08181332 -0.16326935]\n",
      "[CartPole-v0 3:7  :44 ] train iteration=8  step=50  play  episode=1  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=1 observation=[-0.08341729 -0.0029474  -0.08507871 -0.48059937]\n",
      "[CartPole-v0 3:7  :45 ] train iteration=8  step=50  play  episode=1  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=0 observation=[-0.08347624 -0.19677182 -0.09469069 -0.21589732]\n",
      "[CartPole-v0 3:7  :46 ] train iteration=8  step=50  play  episode=1  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[-0.08741168 -0.3904215  -0.09900864  0.04547845]\n",
      "[CartPole-v0 3:7  :47 ] train iteration=8  step=50  play  episode=1  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=1 observation=[-0.09522011 -0.19402948 -0.09809907 -0.27672787]\n",
      "[CartPole-v0 3:7  :48 ] train iteration=8  step=50  play  episode=1  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=0 observation=[-0.0991007  -0.38762499 -0.10363363 -0.01652567]\n",
      "[CartPole-v0 3:7  :49 ] train iteration=8  step=50  play  episode=1  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=1 observation=[-0.1068532  -0.19118125 -0.10396414 -0.34002413]\n",
      "[CartPole-v0 3:8  :50 ] train iteration=8  step=50  play  episode=1  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=0 observation=[-0.11067682 -0.38468215 -0.11076463 -0.08185039]\n",
      "[CartPole-v0 3:8  :1  ] train iteration=8  step=50  play  episode=2  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=0 observation=[ 0.00256538 -0.15460694 -0.00928383  0.27996784]\n",
      "[CartPole-v0 3:8  :2  ] train iteration=8  step=50  play  episode=2  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=1 observation=[-0.00052676  0.04064621 -0.00368447 -0.01562867]\n",
      "[CartPole-v0 3:8  :3  ] train iteration=8  step=50  play  episode=2  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 2.86162609e-04  2.35820807e-01 -3.99704546e-03 -3.09471807e-01]\n",
      "[CartPole-v0 3:8  :4  ] train iteration=8  step=50  play  episode=2  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[ 0.00500258  0.04075603 -0.01018648 -0.01805211]\n",
      "[CartPole-v0 3:8  :5  ] train iteration=8  step=50  play  episode=2  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=0 observation=[ 0.0058177  -0.15421836 -0.01054752  0.27139953]\n",
      "[CartPole-v0 3:8  :6  ] train iteration=8  step=50  play  episode=2  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=1 observation=[ 0.00273333  0.0410525  -0.00511953 -0.02459138]\n",
      "[CartPole-v0 3:8  :7  ] train iteration=8  step=50  play  episode=2  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[ 0.00355438 -0.15399566 -0.00561136  0.26647189]\n",
      "[CartPole-v0 3:8  :8  ] train iteration=8  step=50  play  episode=2  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[ 0.00047447  0.04120592 -0.00028192 -0.02797561]\n",
      "[CartPole-v0 3:8  :9  ] train iteration=8  step=50  play  episode=2  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[ 0.00129859  0.23633192 -0.00084144 -0.32074747]\n",
      "[CartPole-v0 3:8  :10 ] train iteration=8  step=50  play  episode=2  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[ 0.00602523  0.04122196 -0.00725638 -0.02833002]\n",
      "[CartPole-v0 3:8  :11 ] train iteration=8  step=50  play  episode=2  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[ 0.00684966 -0.15379518 -0.00782298  0.26205463]\n",
      "[CartPole-v0 3:8  :12 ] train iteration=8  step=50  play  episode=2  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[ 0.00377376  0.04143756 -0.00258189 -0.03308545]\n",
      "[CartPole-v0 3:8  :13 ] train iteration=8  step=50  play  episode=2  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[ 0.00460251 -0.15364727 -0.0032436   0.25878174]\n",
      "[CartPole-v0 3:8  :14 ] train iteration=8  step=50  play  episode=2  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[ 0.00152957  0.04152083  0.00193203 -0.03492249]\n",
      "[CartPole-v0 3:8  :15 ] train iteration=8  step=50  play  episode=2  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[ 0.00235998  0.23661503  0.00123358 -0.32699522]\n",
      "[CartPole-v0 3:8  :16 ] train iteration=8  step=50  play  episode=2  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[ 0.00709228  0.04147553 -0.00530632 -0.03392353]\n",
      "[CartPole-v0 3:8  :17 ] train iteration=8  step=50  play  episode=2  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[ 0.00792179 -0.15356992 -0.00598479  0.25708049]\n",
      "[CartPole-v0 3:8  :18 ] train iteration=8  step=50  play  episode=2  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[ 0.0048504   0.04163696 -0.00084318 -0.03748411]\n",
      "[CartPole-v0 3:8  :19 ] train iteration=8  step=50  play  episode=2  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[ 0.00568314 -0.15347289 -0.00159286  0.25493266]\n",
      "[CartPole-v0 3:8  :20 ] train iteration=8  step=50  play  episode=2  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[ 0.00261368  0.04167177  0.00350579 -0.03825225]\n",
      "[CartPole-v0 3:8  :21 ] train iteration=8  step=50  play  episode=2  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=1 observation=[ 0.00344711  0.23674327  0.00274074 -0.32982701]\n",
      "[CartPole-v0 3:8  :22 ] train iteration=8  step=50  play  episode=2  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=0 observation=[ 0.00818198  0.04158241 -0.0038558  -0.03628104]\n",
      "[CartPole-v0 3:8  :23 ] train iteration=8  step=50  play  episode=2  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[ 0.00901363 -0.15348404 -0.00458142  0.25518285]\n",
      "[CartPole-v0 3:8  :24 ] train iteration=8  step=50  play  episode=2  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[ 0.00594395  0.04170303  0.00052224 -0.0389416 ]\n",
      "[CartPole-v0 3:8  :25 ] train iteration=8  step=50  play  episode=2  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=1 observation=[ 6.77800653e-03  2.36817487e-01 -2.56591788e-04 -3.31459714e-01]\n",
      "[CartPole-v0 3:8  :26 ] train iteration=8  step=50  play  episode=2  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=0 observation=[ 0.01151436  0.04169919 -0.00688579 -0.03885771]\n",
      "[CartPole-v0 3:8  :27 ] train iteration=8  step=50  play  episode=2  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[ 0.01234834 -0.15332335 -0.00766294  0.25164475]\n",
      "[CartPole-v0 3:8  :28 ] train iteration=8  step=50  play  episode=2  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[ 0.00928187  0.04190719 -0.00263005 -0.04344533]\n",
      "[CartPole-v0 3:8  :29 ] train iteration=8  step=50  play  episode=2  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[ 0.01012002 -0.15317695 -0.00349895  0.24840663]\n",
      "[CartPole-v0 3:8  :30 ] train iteration=8  step=50  play  episode=2  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[ 0.00705648  0.04199479  0.00146918 -0.04537789]\n",
      "[CartPole-v0 3:8  :31 ] train iteration=8  step=50  play  episode=2  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=1 observation=[ 0.00789637  0.23709565  0.00056162 -0.33759691]\n",
      "[CartPole-v0 3:8  :32 ] train iteration=8  step=50  play  episode=2  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=0 observation=[ 0.01263829  0.04196571 -0.00619032 -0.04473693]\n",
      "[CartPole-v0 3:8  :33 ] train iteration=8  step=50  play  episode=2  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[ 0.0134776  -0.15306693 -0.00708505  0.24598648]\n",
      "[CartPole-v0 3:8  :34 ] train iteration=8  step=50  play  episode=2  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[ 0.01041626  0.04215549 -0.00216532 -0.04892279]\n",
      "[CartPole-v0 3:8  :35 ] train iteration=8  step=50  play  episode=2  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[ 0.01125937 -0.15293535 -0.00314378  0.24307617]\n",
      "[CartPole-v0 3:8  :36 ] train iteration=8  step=50  play  episode=2  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=1 observation=[ 0.00820066  0.04223137  0.00171774 -0.05059672]\n",
      "[CartPole-v0 3:8  :37 ] train iteration=8  step=50  play  episode=2  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[ 0.00904529  0.23732865  0.00070581 -0.34273719]\n",
      "[CartPole-v0 3:8  :38 ] train iteration=8  step=50  play  episode=2  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[ 0.01379187  0.04219666 -0.00614894 -0.04983178]\n",
      "[CartPole-v0 3:8  :39 ] train iteration=8  step=50  play  episode=2  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=0 observation=[ 0.0146358  -0.15283658 -0.00714557  0.24090478]\n",
      "[CartPole-v0 3:8  :40 ] train iteration=8  step=50  play  episode=2  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=1 observation=[ 0.01157907  0.04238671 -0.00232748 -0.05402346]\n",
      "[CartPole-v0 3:8  :41 ] train iteration=8  step=50  play  episode=2  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[ 0.0124268  -0.15270179 -0.00340794  0.23792422]\n",
      "[CartPole-v0 3:8  :42 ] train iteration=8  step=50  play  episode=2  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[ 0.00937277  0.04246868  0.00135054 -0.05583172]\n",
      "[CartPole-v0 3:8  :43 ] train iteration=8  step=50  play  episode=2  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=0 observation=[ 1.02221387e-02 -1.52672610e-01  2.33905625e-04  2.37277006e-01]\n",
      "[CartPole-v0 3:8  :44 ] train iteration=8  step=50  play  episode=2  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=1 observation=[ 0.00716869  0.042446    0.00497945 -0.05533213]\n",
      "[CartPole-v0 3:8  :45 ] train iteration=8  step=50  play  episode=2  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[ 0.00801761  0.2374962   0.0038728  -0.34643985]\n",
      "[CartPole-v0 3:8  :46 ] train iteration=8  step=50  play  episode=2  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[ 0.01276753  0.04231937 -0.00305599 -0.05253821]\n",
      "[CartPole-v0 3:8  :47 ] train iteration=8  step=50  play  episode=2  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=0 observation=[ 0.01361392 -0.15275862 -0.00410676  0.23917896]\n",
      "[CartPole-v0 3:8  :48 ] train iteration=8  step=50  play  episode=2  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=1 observation=[ 0.01055875  0.04242175  0.00067682 -0.05479652]\n",
      "[CartPole-v0 3:8  :49 ] train iteration=8  step=50  play  episode=2  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[ 0.01140718 -0.1527099  -0.00041911  0.23809987]\n",
      "[CartPole-v0 3:9  :50 ] train iteration=8  step=50  play  episode=2  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[ 0.00835298  0.04241804  0.00434289 -0.05471523]\n",
      "[CartPole-v0 2:24 :1  ] train iteration=8  step=1    reward=1.0   done=False action=0 observation=[-0.02713179 -0.24484472 -0.01489691  0.24024356]\n",
      "[CartPole-v0 2:24 :2  ] train iteration=8  step=2    reward=1.0   done=False action=1 observation=[-0.03202868 -0.04951316 -0.01009204 -0.05710078]\n",
      "[CartPole-v0 2:24 :3  ] train iteration=8  step=3    reward=1.0   done=False action=1 observation=[-0.03301895  0.14575203 -0.01123405 -0.35295066]\n",
      "[CartPole-v0 2:24 :4  ] train iteration=8  step=4    reward=1.0   done=False action=0 observation=[-0.03010391 -0.04920839 -0.01829306 -0.06383123]\n",
      "[CartPole-v0 2:24 :5  ] train iteration=8  step=5    reward=1.0   done=False action=0 observation=[-0.03108807 -0.24406335 -0.01956969  0.22302445]\n",
      "[CartPole-v0 2:24 :6  ] train iteration=8  step=6    reward=1.0   done=False action=0 observation=[-0.03596934 -0.43890021 -0.0151092   0.50947065]\n",
      "[CartPole-v0 2:24 :7  ] train iteration=8  step=7    reward=1.0   done=False action=0 observation=[-0.04474734 -0.63380608 -0.00491979  0.79735414]\n",
      "[CartPole-v0 2:24 :8  ] train iteration=8  step=8    reward=1.0   done=False action=0 observation=[-0.05742347 -0.82886018  0.0110273   1.08848534]\n",
      "[CartPole-v0 2:24 :9  ] train iteration=8  step=9    reward=1.0   done=False action=0 observation=[-0.07400067 -1.02412578  0.032797    1.3846079 ]\n",
      "[CartPole-v0 2:24 :10 ] train iteration=8  step=10   reward=1.0   done=False action=0 observation=[-0.09448319 -1.21964104  0.06048916  1.68736366]\n",
      "[CartPole-v0 2:24 :11 ] train iteration=8  step=11   reward=1.0   done=False action=0 observation=[-0.11887601 -1.41540811  0.09423643  1.99825017]\n",
      "[CartPole-v0 2:24 :12 ] train iteration=8  step=12   reward=1.0   done=False action=1 observation=[-0.14718417 -1.22138879  0.13420144  1.73617701]\n",
      "[CartPole-v0 2:24 :13 ] train iteration=8  step=13   reward=1.0   done=False action=1 observation=[-0.17161194 -1.02802827  0.16892498  1.48808103]\n",
      "[CartPole-v0 2:24 :14 ] train iteration=8  step=14   reward=1.0   done=False action=1 observation=[-0.19217251 -0.83531848  0.1986866   1.25255895]\n",
      "[CartPole-v0 2:25 :15 ] train iteration=8  step=15   reward=1.0   done=True  action=1 observation=[-0.20887888 -0.64321709  0.22373778  1.02810606]\n",
      "[CartPole-v0 2:25 :1  ] train iteration=8  step=16   reward=1.0   done=False action=0 observation=[-0.00272278 -0.2439735  -0.03841203  0.30063826]\n",
      "[CartPole-v0 2:25 :2  ] train iteration=8  step=17   reward=1.0   done=False action=0 observation=[-0.00760225 -0.4385275  -0.03239927  0.58096363]\n",
      "[CartPole-v0 2:25 :3  ] train iteration=8  step=18   reward=1.0   done=False action=1 observation=[-0.0163728  -0.2429669  -0.02077999  0.27825296]\n",
      "[CartPole-v0 2:25 :4  ] train iteration=8  step=19   reward=1.0   done=False action=0 observation=[-0.02123214 -0.43778634 -0.01521493  0.56431015]\n",
      "[CartPole-v0 2:25 :5  ] train iteration=8  step=20   reward=1.0   done=False action=1 observation=[-0.02998787 -0.24245425 -0.00392873  0.26687291]\n",
      "[CartPole-v0 2:25 :6  ] train iteration=8  step=21   reward=1.0   done=False action=1 observation=[-0.03483695 -0.04727645  0.00140873 -0.02704657]\n",
      "[CartPole-v0 2:25 :7  ] train iteration=8  step=22   reward=1.0   done=False action=1 observation=[-0.03578248  0.14782527  0.0008678  -0.3192847 ]\n",
      "[CartPole-v0 2:25 :8  ] train iteration=8  step=23   reward=1.0   done=False action=1 observation=[-0.03282598  0.34293485 -0.0055179  -0.61169383]\n",
      "[CartPole-v0 2:25 :9  ] train iteration=8  step=24   reward=1.0   done=False action=1 observation=[-0.02596728  0.53813349 -0.01775178 -0.90610958]\n",
      "[CartPole-v0 2:25 :10 ] train iteration=8  step=25   reward=1.0   done=False action=0 observation=[-0.01520461  0.34325634 -0.03587397 -0.61905867]\n",
      "[CartPole-v0 2:25 :11 ] train iteration=8  step=26   reward=1.0   done=False action=0 observation=[-0.00833948  0.14865334 -0.04825514 -0.33788666]\n",
      "[CartPole-v0 2:25 :12 ] train iteration=8  step=27   reward=1.0   done=False action=0 observation=[-0.00536642 -0.04574991 -0.05501287 -0.06080274]\n",
      "[CartPole-v0 2:25 :13 ] train iteration=8  step=28   reward=1.0   done=False action=1 observation=[-0.00628142  0.15011589 -0.05622893 -0.37032259]\n",
      "[CartPole-v0 2:25 :14 ] train iteration=8  step=29   reward=1.0   done=False action=1 observation=[-0.0032791   0.34598976 -0.06363538 -0.68019165]\n",
      "[CartPole-v0 2:25 :15 ] train iteration=8  step=30   reward=1.0   done=False action=1 observation=[ 0.0036407   0.54193519 -0.07723921 -0.99221107]\n",
      "[CartPole-v0 2:25 :16 ] train iteration=8  step=31   reward=1.0   done=False action=1 observation=[ 0.0144794   0.73800093 -0.09708343 -1.30811859]\n",
      "[CartPole-v0 2:25 :17 ] train iteration=8  step=32   reward=1.0   done=False action=1 observation=[ 0.02923942  0.93420976 -0.12324581 -1.62954366]\n",
      "[CartPole-v0 2:25 :18 ] train iteration=8  step=33   reward=1.0   done=False action=1 observation=[ 0.04792362  1.1305458  -0.15583668 -1.95795647]\n",
      "[CartPole-v0 2:25 :19 ] train iteration=8  step=34   reward=1.0   done=False action=1 observation=[ 0.07053453  1.32694002 -0.19499581 -2.2946087 ]\n",
      "[CartPole-v0 2:26 :20 ] train iteration=8  step=35   reward=1.0   done=True  action=1 observation=[ 0.09707333  1.52325353 -0.24088798 -2.64046446]\n",
      "[CartPole-v0 2:26 :1  ] train iteration=8  step=36   reward=1.0   done=False action=1 observation=[-0.04332689  0.16322662 -0.02759062 -0.29919049]\n",
      "[CartPole-v0 2:26 :2  ] train iteration=8  step=37   reward=1.0   done=False action=0 observation=[-0.04006236 -0.0314914  -0.03357443 -0.01533523]\n",
      "[CartPole-v0 2:26 :3  ] train iteration=8  step=38   reward=1.0   done=False action=1 observation=[-0.04069219  0.16409556 -0.03388113 -0.31841936]\n",
      "[CartPole-v0 2:26 :4  ] train iteration=8  step=39   reward=1.0   done=False action=0 observation=[-0.03741028 -0.03052787 -0.04024952 -0.03661091]\n",
      "[CartPole-v0 2:26 :5  ] train iteration=8  step=40   reward=1.0   done=False action=1 observation=[-0.03802083  0.16514746 -0.04098173 -0.34171635]\n",
      "[CartPole-v0 2:26 :6  ] train iteration=8  step=41   reward=1.0   done=False action=1 observation=[-0.03471788  0.36082779 -0.04781606 -0.64703565]\n",
      "[CartPole-v0 2:26 :7  ] train iteration=8  step=42   reward=1.0   done=False action=1 observation=[-0.02750133  0.5565822  -0.06075677 -0.95438422]\n",
      "[CartPole-v0 2:26 :8  ] train iteration=8  step=43   reward=1.0   done=False action=0 observation=[-0.01636968  0.3623279  -0.07984446 -0.6813919 ]\n",
      "[CartPole-v0 2:26 :9  ] train iteration=8  step=44   reward=1.0   done=False action=0 observation=[-0.00912313  0.16840031 -0.0934723  -0.41487661]\n",
      "[CartPole-v0 2:26 :10 ] train iteration=8  step=45   reward=1.0   done=False action=0 observation=[-0.00575512 -0.02528112 -0.10176983 -0.15306355]\n",
      "[CartPole-v0 2:26 :11 ] train iteration=8  step=46   reward=1.0   done=False action=0 observation=[-0.00626074 -0.21880976 -0.1048311   0.10585871]\n",
      "[CartPole-v0 2:26 :12 ] train iteration=8  step=47   reward=1.0   done=False action=1 observation=[-0.01063694 -0.02235391 -0.10271393 -0.21797126]\n",
      "[CartPole-v0 2:26 :13 ] train iteration=8  step=48   reward=1.0   done=False action=0 observation=[-0.01108402 -0.21586902 -0.10707335  0.04062673]\n",
      "[CartPole-v0 2:26 :14 ] train iteration=8  step=49   reward=1.0   done=False action=1 observation=[-0.0154014  -0.01938756 -0.10626082 -0.28382708]\n",
      "[CartPole-v0 2:26 :15 ] train iteration=8  step=50   reward=1.0   done=False action=1 observation=[-0.01578915  0.17707684 -0.11193736 -0.6080434 ]\n",
      "[CartPole-v0 2:26 :16 ] train iteration=8  step=51   reward=1.0   done=False action=1 observation=[-0.01224761  0.37357107 -0.12409823 -0.93378102]\n",
      "[CartPole-v0 2:26 :17 ] train iteration=8  step=52   reward=1.0   done=False action=0 observation=[-0.00477619  0.180322   -0.14277385 -0.68252794]\n",
      "[CartPole-v0 2:26 :18 ] train iteration=8  step=53   reward=1.0   done=False action=1 observation=[-0.00116975  0.37710763 -0.15642441 -1.01653603]\n",
      "[CartPole-v0 2:26 :19 ] train iteration=8  step=54   reward=1.0   done=False action=1 observation=[ 0.0063724   0.57392994 -0.17675513 -1.35396634]\n",
      "[CartPole-v0 2:26 :20 ] train iteration=8  step=55   reward=1.0   done=False action=1 observation=[ 0.017851    0.77077454 -0.20383445 -1.69632866]\n",
      "[CartPole-v0 2:27 :21 ] train iteration=8  step=56   reward=1.0   done=True  action=1 observation=[ 0.03326649  0.96758112 -0.23776103 -2.04494017]\n",
      "[CartPole-v0 2:27 :1  ] train iteration=9  step=1    reward=1.0   done=False action=0 observation=[-0.04495382 -0.24024451 -0.00600389  0.32411136]\n",
      "[CartPole-v0 2:27 :2  ] train iteration=9  step=2    reward=1.0   done=False action=1 observation=[-0.04975871 -0.04503759  0.00047833  0.02954112]\n",
      "[CartPole-v0 2:27 :3  ] train iteration=9  step=3    reward=1.0   done=False action=0 observation=[-0.05065946 -0.24016639  0.00106915  0.32237492]\n",
      "[CartPole-v0 2:27 :4  ] train iteration=9  step=4    reward=1.0   done=False action=1 observation=[-0.05546279 -0.04505968  0.00751665  0.03002936]\n",
      "[CartPole-v0 2:27 :5  ] train iteration=9  step=5    reward=1.0   done=False action=1 observation=[-0.05636398  0.14995367  0.00811724 -0.26027254]\n",
      "[CartPole-v0 2:27 :6  ] train iteration=9  step=6    reward=1.0   done=False action=0 observation=[-0.05336491 -0.04528321  0.00291179  0.03495958]\n",
      "[CartPole-v0 2:27 :7  ] train iteration=9  step=7    reward=1.0   done=False action=0 observation=[-0.05427057 -0.2404468   0.00361098  0.32855978]\n",
      "[CartPole-v0 2:27 :8  ] train iteration=9  step=8    reward=1.0   done=False action=0 observation=[-0.05907951 -0.43561997  0.01018218  0.62237926]\n",
      "[CartPole-v0 2:27 :9  ] train iteration=9  step=9    reward=1.0   done=False action=1 observation=[-0.06779191 -0.24064166  0.02262976  0.33292047]\n",
      "[CartPole-v0 2:27 :10 ] train iteration=9  step=10   reward=1.0   done=False action=1 observation=[-0.07260474 -0.045849    0.02928817  0.04745886]\n",
      "[CartPole-v0 2:27 :11 ] train iteration=9  step=11   reward=1.0   done=False action=1 observation=[-0.07352172  0.14884101  0.03023735 -0.23584141]\n",
      "[CartPole-v0 2:27 :12 ] train iteration=9  step=12   reward=1.0   done=False action=1 observation=[-0.0705449   0.3435182   0.02552052 -0.51883528]\n",
      "[CartPole-v0 2:27 :13 ] train iteration=9  step=13   reward=1.0   done=False action=1 observation=[-0.06367454  0.53827173  0.01514382 -0.80336823]\n",
      "[CartPole-v0 2:27 :14 ] train iteration=9  step=14   reward=1.0   done=False action=0 observation=[-0.0529091   0.34294544 -0.00092355 -0.50596028]\n",
      "[CartPole-v0 2:27 :15 ] train iteration=9  step=15   reward=1.0   done=False action=1 observation=[-0.04605019  0.53808039 -0.01104276 -0.79893411]\n",
      "[CartPole-v0 2:27 :16 ] train iteration=9  step=16   reward=1.0   done=False action=0 observation=[-0.03528858  0.34311166 -0.02702144 -0.50974534]\n",
      "[CartPole-v0 2:27 :17 ] train iteration=9  step=17   reward=1.0   done=False action=0 observation=[-0.02842635  0.1483806  -0.03721634 -0.22569872]\n",
      "[CartPole-v0 2:27 :18 ] train iteration=9  step=18   reward=1.0   done=False action=0 observation=[-0.02545874 -0.04619025 -0.04173032  0.05501637]\n",
      "[CartPole-v0 2:27 :19 ] train iteration=9  step=19   reward=1.0   done=False action=1 observation=[-0.02638254  0.14950444 -0.04062999 -0.25053526]\n",
      "[CartPole-v0 2:27 :20 ] train iteration=9  step=20   reward=1.0   done=False action=0 observation=[-0.02339246 -0.04501447 -0.0456407   0.02906037]\n",
      "[CartPole-v0 2:27 :21 ] train iteration=9  step=21   reward=1.0   done=False action=0 observation=[-0.02429275 -0.23945319 -0.04505949  0.30700103]\n",
      "[CartPole-v0 2:27 :22 ] train iteration=9  step=22   reward=1.0   done=False action=1 observation=[-0.02908181 -0.0437191  -0.03891947  0.00045489]\n",
      "[CartPole-v0 2:27 :23 ] train iteration=9  step=23   reward=1.0   done=False action=0 observation=[-0.02995619 -0.2382619  -0.03891037  0.28060868]\n",
      "[CartPole-v0 2:27 :24 ] train iteration=9  step=24   reward=1.0   done=False action=1 observation=[-0.03472143 -0.04260713 -0.0332982  -0.0240881 ]\n",
      "[CartPole-v0 2:27 :25 ] train iteration=9  step=25   reward=1.0   done=False action=1 observation=[-0.03557357  0.15297613 -0.03377996 -0.32708822]\n",
      "[CartPole-v0 2:27 :26 ] train iteration=9  step=26   reward=1.0   done=False action=1 observation=[-0.03251405  0.34856232 -0.04032172 -0.63022956]\n",
      "[CartPole-v0 2:27 :27 ] train iteration=9  step=27   reward=1.0   done=False action=0 observation=[-0.0255428   0.15402552 -0.05292631 -0.35051292]\n",
      "[CartPole-v0 2:27 :28 ] train iteration=9  step=28   reward=1.0   done=False action=0 observation=[-0.02246229 -0.04030535 -0.05993657 -0.07497785]\n",
      "[CartPole-v0 2:27 :29 ] train iteration=9  step=29   reward=1.0   done=False action=0 observation=[-0.0232684  -0.23451912 -0.06143613  0.19820888]\n",
      "[CartPole-v0 2:27 :30 ] train iteration=9  step=30   reward=1.0   done=False action=1 observation=[-0.02795878 -0.0385747  -0.05747195 -0.1132041 ]\n",
      "[CartPole-v0 2:27 :31 ] train iteration=9  step=31   reward=1.0   done=False action=0 observation=[-0.02873028 -0.23282806 -0.05973603  0.16080739]\n",
      "[CartPole-v0 2:27 :32 ] train iteration=9  step=32   reward=1.0   done=False action=1 observation=[-0.03338684 -0.03690404 -0.05651989 -0.15010639]\n",
      "[CartPole-v0 2:27 :33 ] train iteration=9  step=33   reward=1.0   done=False action=1 observation=[-0.03412492  0.15897978 -0.05952201 -0.46007094]\n",
      "[CartPole-v0 2:27 :34 ] train iteration=9  step=34   reward=1.0   done=False action=0 observation=[-0.03094532 -0.03525254 -0.06872343 -0.18672755]\n",
      "[CartPole-v0 2:27 :35 ] train iteration=9  step=35   reward=1.0   done=False action=1 observation=[-0.03165037  0.16078193 -0.07245798 -0.50027392]\n",
      "[CartPole-v0 2:27 :36 ] train iteration=9  step=36   reward=1.0   done=False action=0 observation=[-0.02843473 -0.03324777 -0.08246346 -0.23127707]\n",
      "[CartPole-v0 2:27 :37 ] train iteration=9  step=37   reward=1.0   done=False action=1 observation=[-0.02909969  0.16294977 -0.087089   -0.5487901 ]\n",
      "[CartPole-v0 2:27 :38 ] train iteration=9  step=38   reward=1.0   done=False action=0 observation=[-0.02584069 -0.03084778 -0.09806481 -0.28476728]\n",
      "[CartPole-v0 2:27 :39 ] train iteration=9  step=39   reward=1.0   done=False action=0 observation=[-0.02645765 -0.22444429 -0.10376015 -0.02455258]\n",
      "[CartPole-v0 2:27 :40 ] train iteration=9  step=40   reward=1.0   done=False action=0 observation=[-0.03094654 -0.41793701 -0.1042512   0.23367474]\n",
      "[CartPole-v0 2:27 :41 ] train iteration=9  step=41   reward=1.0   done=False action=0 observation=[-0.03930528 -0.61142688 -0.09957771  0.49173943]\n",
      "[CartPole-v0 2:27 :42 ] train iteration=9  step=42   reward=1.0   done=False action=0 observation=[-0.05153381 -0.80501363 -0.08974292  0.75145359]\n",
      "[CartPole-v0 2:27 :43 ] train iteration=9  step=43   reward=1.0   done=False action=0 observation=[-0.06763409 -0.99879092 -0.07471385  1.01460081]\n",
      "[CartPole-v0 2:27 :44 ] train iteration=9  step=44   reward=1.0   done=False action=1 observation=[-0.0876099  -0.80275633 -0.05442183  0.69942383]\n",
      "[CartPole-v0 2:27 :45 ] train iteration=9  step=45   reward=1.0   done=False action=1 observation=[-0.10366503 -0.60692379 -0.04043335  0.39011779]\n",
      "[CartPole-v0 2:27 :46 ] train iteration=9  step=46   reward=1.0   done=False action=1 observation=[-0.11580351 -0.41125199 -0.032631    0.08496582]\n",
      "[CartPole-v0 2:27 :47 ] train iteration=9  step=47   reward=1.0   done=False action=1 observation=[-0.12402855 -0.21567786 -0.03093168 -0.21783102]\n",
      "[CartPole-v0 2:27 :48 ] train iteration=9  step=48   reward=1.0   done=False action=1 observation=[-0.1283421  -0.0201277  -0.0352883  -0.52010841]\n",
      "[CartPole-v0 2:27 :49 ] train iteration=9  step=49   reward=1.0   done=False action=1 observation=[-0.12874466  0.17547279 -0.04569047 -0.82369909]\n",
      "[CartPole-v0 2:28 :50 ] train iteration=9  step=50   reward=1.0   done=True  action=0 observation=[-0.1252352  -0.01899536 -0.06216445 -0.54572963]\n",
      "[CartPole-v0 2:28 :1  ] train iteration=9  step=51   reward=1.0   done=False action=1 observation=[ 0.03178433  0.23239601  0.00656717 -0.30991708]\n",
      "[CartPole-v0 2:28 :2  ] train iteration=9  step=52   reward=1.0   done=False action=1 observation=[ 3.64322491e-02  4.27423783e-01  3.68831377e-04 -6.00521691e-01]\n",
      "[CartPole-v0 2:28 :3  ] train iteration=9  step=53   reward=1.0   done=False action=0 observation=[ 0.04498072  0.23229667 -0.0116416  -0.30772261]\n",
      "[CartPole-v0 2:28 :4  ] train iteration=9  step=54   reward=1.0   done=False action=0 observation=[ 0.04962666  0.03734252 -0.01779605 -0.01873375]\n",
      "[CartPole-v0 2:28 :5  ] train iteration=9  step=55   reward=1.0   done=False action=0 observation=[ 0.05037351 -0.15751975 -0.01817073  0.26828161]\n",
      "[CartPole-v0 2:28 :6  ] train iteration=9  step=56   reward=1.0   done=False action=0 observation=[ 0.04722311 -0.35237773 -0.0128051   0.55517843]\n",
      "[CartPole-v0 2:28 :7  ] train iteration=9  step=57   reward=1.0   done=False action=0 observation=[ 0.04017556 -0.54731757 -0.00170153  0.84379962]\n",
      "[CartPole-v0 2:28 :8  ] train iteration=9  step=58   reward=1.0   done=False action=1 observation=[ 0.02922921 -0.35217244  0.01517446  0.5505821 ]\n",
      "[CartPole-v0 2:28 :9  ] train iteration=9  step=59   reward=1.0   done=False action=1 observation=[ 0.02218576 -0.15726688  0.02618611  0.26271853]\n",
      "[CartPole-v0 2:28 :10 ] train iteration=9  step=60   reward=1.0   done=False action=1 observation=[ 0.01904042  0.03747169  0.03144048 -0.02159134]\n",
      "[CartPole-v0 2:28 :11 ] train iteration=9  step=61   reward=1.0   done=False action=1 observation=[ 0.01978985  0.23212898  0.03100865 -0.30419099]\n",
      "[CartPole-v0 2:28 :12 ] train iteration=9  step=62   reward=1.0   done=False action=0 observation=[ 0.02443243  0.03657915  0.02492483 -0.00189218]\n",
      "[CartPole-v0 2:28 :13 ] train iteration=9  step=63   reward=1.0   done=False action=0 observation=[ 0.02516402 -0.15889122  0.02488699  0.29854945]\n",
      "[CartPole-v0 2:28 :14 ] train iteration=9  step=64   reward=1.0   done=False action=1 observation=[0.02198619 0.0358673  0.03085798 0.01381815]\n",
      "[CartPole-v0 2:28 :15 ] train iteration=9  step=65   reward=1.0   done=False action=0 observation=[ 0.02270354 -0.15968329  0.03113434  0.31607521]\n",
      "[CartPole-v0 2:28 :16 ] train iteration=9  step=66   reward=1.0   done=False action=1 observation=[0.01950987 0.03498166 0.03745584 0.0333713 ]\n",
      "[CartPole-v0 2:28 :17 ] train iteration=9  step=67   reward=1.0   done=False action=1 observation=[ 0.02020951  0.22954702  0.03812327 -0.2472626 ]\n",
      "[CartPole-v0 2:28 :18 ] train iteration=9  step=68   reward=1.0   done=False action=1 observation=[ 0.02480045  0.42410435  0.03317802 -0.52768102]\n",
      "[CartPole-v0 2:28 :19 ] train iteration=9  step=69   reward=1.0   done=False action=1 observation=[ 0.03328253  0.61874417  0.0226244  -0.80972753]\n",
      "[CartPole-v0 2:28 :20 ] train iteration=9  step=70   reward=1.0   done=False action=0 observation=[ 0.04565742  0.42331965  0.00642985 -0.51001476]\n",
      "[CartPole-v0 2:28 :21 ] train iteration=9  step=71   reward=1.0   done=False action=0 observation=[ 0.05412381  0.22810771 -0.00377045 -0.21531255]\n",
      "[CartPole-v0 2:28 :22 ] train iteration=9  step=72   reward=1.0   done=False action=0 observation=[ 0.05868596  0.03303987 -0.0080767   0.07617863]\n",
      "[CartPole-v0 2:28 :23 ] train iteration=9  step=73   reward=1.0   done=False action=1 observation=[ 0.05934676  0.22827667 -0.00655313 -0.21904154]\n",
      "[CartPole-v0 2:28 :24 ] train iteration=9  step=74   reward=1.0   done=False action=1 observation=[ 0.0639123   0.42349168 -0.01093396 -0.51378437]\n",
      "[CartPole-v0 2:28 :25 ] train iteration=9  step=75   reward=1.0   done=False action=0 observation=[ 0.07238213  0.22852541 -0.02120965 -0.22456698]\n",
      "[CartPole-v0 2:28 :26 ] train iteration=9  step=76   reward=1.0   done=False action=0 observation=[ 0.07695264  0.03371292 -0.02570099  0.06135088]\n",
      "[CartPole-v0 2:28 :27 ] train iteration=9  step=77   reward=1.0   done=False action=0 observation=[ 0.0776269  -0.16103129 -0.02447397  0.34581546]\n",
      "[CartPole-v0 2:28 :28 ] train iteration=9  step=78   reward=1.0   done=False action=1 observation=[ 0.07440627  0.03443009 -0.01755766  0.04551656]\n",
      "[CartPole-v0 2:28 :29 ] train iteration=9  step=79   reward=1.0   done=False action=0 observation=[ 0.07509487 -0.16043575 -0.01664733  0.33260858]\n",
      "[CartPole-v0 2:28 :30 ] train iteration=9  step=80   reward=1.0   done=False action=1 observation=[ 0.07188616  0.03491915 -0.00999516  0.03472275]\n",
      "[CartPole-v0 2:28 :31 ] train iteration=9  step=81   reward=1.0   done=False action=1 observation=[ 0.07258454  0.230183   -0.0093007  -0.26109692]\n",
      "[CartPole-v0 2:28 :32 ] train iteration=9  step=82   reward=1.0   done=False action=1 observation=[ 0.0771882   0.42543647 -0.01452264 -0.55669883]\n",
      "[CartPole-v0 2:28 :33 ] train iteration=9  step=83   reward=1.0   done=False action=1 observation=[ 0.08569693  0.62075926 -0.02565662 -0.85392163]\n",
      "[CartPole-v0 2:28 :34 ] train iteration=9  step=84   reward=1.0   done=False action=0 observation=[ 0.09811211  0.42599623 -0.04273505 -0.56941545]\n",
      "[CartPole-v0 2:28 :35 ] train iteration=9  step=85   reward=1.0   done=False action=0 observation=[ 0.10663204  0.23149888 -0.05412336 -0.29049607]\n",
      "[CartPole-v0 2:28 :36 ] train iteration=9  step=86   reward=1.0   done=False action=1 observation=[ 0.11126202  0.42734913 -0.05993328 -0.59974577]\n",
      "[CartPole-v0 2:28 :37 ] train iteration=9  step=87   reward=1.0   done=False action=1 observation=[ 0.119809    0.62325611 -0.07192819 -0.91068845]\n",
      "[CartPole-v0 2:28 :38 ] train iteration=9  step=88   reward=1.0   done=False action=0 observation=[ 0.13227412  0.42917736 -0.09014196 -0.64145173]\n",
      "[CartPole-v0 2:28 :39 ] train iteration=9  step=89   reward=1.0   done=False action=0 observation=[ 0.14085767  0.23541993 -0.102971   -0.37846145]\n",
      "[CartPole-v0 2:28 :40 ] train iteration=9  step=90   reward=1.0   done=False action=0 observation=[ 0.14556607  0.04189956 -0.11054023 -0.11993847]\n",
      "[CartPole-v0 2:28 :41 ] train iteration=9  step=91   reward=1.0   done=False action=1 observation=[ 0.14640406  0.2384174  -0.112939   -0.44534879]\n",
      "[CartPole-v0 2:28 :42 ] train iteration=9  step=92   reward=1.0   done=False action=0 observation=[ 0.15117241  0.04505932 -0.12184597 -0.19029295]\n",
      "[CartPole-v0 2:28 :43 ] train iteration=9  step=93   reward=1.0   done=False action=1 observation=[ 0.15207359  0.24169462 -0.12565183 -0.51879326]\n",
      "[CartPole-v0 2:28 :44 ] train iteration=9  step=94   reward=1.0   done=False action=1 observation=[ 0.15690749  0.43834081 -0.1360277  -0.84828157]\n",
      "[CartPole-v0 2:28 :45 ] train iteration=9  step=95   reward=1.0   done=False action=1 observation=[ 0.1656743   0.63502976 -0.15299333 -1.18045854]\n",
      "[CartPole-v0 2:28 :46 ] train iteration=9  step=96   reward=1.0   done=False action=0 observation=[ 0.1783749   0.4421884  -0.1766025  -0.93938005]\n",
      "[CartPole-v0 2:28 :47 ] train iteration=9  step=97   reward=1.0   done=False action=1 observation=[ 0.18721866  0.63919458 -0.1953901  -1.28194471]\n",
      "[CartPole-v0 2:29 :48 ] train iteration=9  step=98   reward=1.0   done=True  action=0 observation=[ 0.20000256  0.44702278 -0.22102899 -1.05625185]\n",
      "[CartPole-v0 2:29 :1  ] train iteration=9  step=99   reward=1.0   done=False action=1 observation=[-0.0342561   0.16679549 -0.01208295 -0.31296932]\n",
      "[CartPole-v0 2:29 :2  ] train iteration=9  step=100  reward=1.0   done=False action=1 observation=[-0.03092019  0.36208747 -0.01834234 -0.60943821]\n",
      "[CartPole-v0 2:29 :3  ] train iteration=9  step=101  reward=1.0   done=False action=1 observation=[-0.02367844  0.55746097 -0.0305311  -0.90784149]\n",
      "[CartPole-v0 2:29 :4  ] train iteration=9  step=102  reward=1.0   done=False action=1 observation=[-0.01252922  0.75298263 -0.04868793 -1.20996206]\n",
      "[CartPole-v0 2:29 :5  ] train iteration=9  step=103  reward=1.0   done=False action=0 observation=[ 0.00253043  0.55852202 -0.07288717 -0.9329254 ]\n",
      "[CartPole-v0 2:29 :6  ] train iteration=9  step=104  reward=1.0   done=False action=1 observation=[ 0.01370088  0.75454768 -0.09154568 -1.24759306]\n",
      "[CartPole-v0 2:29 :7  ] train iteration=9  step=105  reward=1.0   done=False action=1 observation=[ 0.02879183  0.95071643 -0.11649754 -1.56749088]\n",
      "[CartPole-v0 2:29 :8  ] train iteration=9  step=106  reward=1.0   done=False action=1 observation=[ 0.04780616  1.14702137 -0.14784736 -1.89412526]\n",
      "[CartPole-v0 2:29 :9  ] train iteration=9  step=107  reward=1.0   done=False action=0 observation=[ 0.07074658  0.95378022 -0.18572987 -1.65073473]\n",
      "[CartPole-v0 2:30 :10 ] train iteration=9  step=108  reward=1.0   done=True  action=1 observation=[ 0.08982219  1.15052314 -0.21874456 -1.99506485]\n",
      "[CartPole-v0 3:9  :1  ] train iteration=10 step=108 play  episode=0  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[ 0.0404217   0.17985274 -0.0010204  -0.31721629]\n",
      "[CartPole-v0 3:9  :2  ] train iteration=10 step=108 play  episode=0  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[ 0.04401875 -0.01525466 -0.00736473 -0.02485534]\n",
      "[CartPole-v0 3:9  :3  ] train iteration=10 step=108 play  episode=0  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 0.04371366  0.17997213 -0.00786184 -0.31985279]\n",
      "[CartPole-v0 3:9  :4  ] train iteration=10 step=108 play  episode=0  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[ 0.0473131  -0.01503698 -0.01425889 -0.02965953]\n",
      "[CartPole-v0 3:9  :5  ] train iteration=10 step=108 play  episode=0  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[ 0.04701236  0.18028652 -0.01485208 -0.32680696]\n",
      "[CartPole-v0 3:9  :6  ] train iteration=10 step=108 play  episode=0  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[ 0.05061809 -0.01462086 -0.02138822 -0.03884448]\n",
      "[CartPole-v0 3:9  :7  ] train iteration=10 step=108 play  episode=0  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=1 observation=[ 0.05032568  0.18080116 -0.02216511 -0.33819813]\n",
      "[CartPole-v0 3:9  :8  ] train iteration=10 step=108 play  episode=0  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=0 observation=[ 0.0539417  -0.01399849 -0.02892907 -0.05258644]\n",
      "[CartPole-v0 3:9  :9  ] train iteration=10 step=108 play  episode=0  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[ 0.05366173  0.18152607 -0.0299808  -0.35425453]\n",
      "[CartPole-v0 3:9  :10 ] train iteration=10 step=108 play  episode=0  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[ 0.05729225 -0.01315704 -0.03706589 -0.07117413]\n",
      "[CartPole-v0 3:9  :11 ] train iteration=10 step=108 play  episode=0  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=1 observation=[ 0.05702911  0.18247616 -0.03848938 -0.37531725]\n",
      "[CartPole-v0 3:9  :12 ] train iteration=10 step=108 play  episode=0  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=0 observation=[ 0.06067863 -0.01207855 -0.04599572 -0.0950144 ]\n",
      "[CartPole-v0 3:9  :13 ] train iteration=10 step=108 play  episode=0  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[ 0.06043706 -0.20651211 -0.04789601  0.18280951]\n",
      "[CartPole-v0 3:9  :14 ] train iteration=10 step=108 play  episode=0  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[ 0.05630682 -0.01073871 -0.04423982 -0.12458987]\n",
      "[CartPole-v0 3:9  :15 ] train iteration=10 step=108 play  episode=0  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=0 observation=[ 0.05609205 -0.20519986 -0.04673162  0.1538142 ]\n",
      "[CartPole-v0 3:9  :16 ] train iteration=10 step=108 play  episode=0  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=1 observation=[ 0.05198805 -0.00944102 -0.04365533 -0.15323758]\n",
      "[CartPole-v0 3:9  :17 ] train iteration=10 step=108 play  episode=0  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[ 0.05179923 -0.20391159 -0.04672008  0.12535975]\n",
      "[CartPole-v0 3:9  :18 ] train iteration=10 step=108 play  episode=0  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[ 0.047721   -0.00815254 -0.04421289 -0.18168912]\n",
      "[CartPole-v0 3:9  :19 ] train iteration=10 step=108 play  episode=0  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[ 0.04755795 -0.20261486 -0.04784667  0.09672497]\n",
      "[CartPole-v0 3:9  :20 ] train iteration=10 step=108 play  episode=0  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[ 0.04350565 -0.00684097 -0.04591217 -0.21066135]\n",
      "[CartPole-v0 3:9  :21 ] train iteration=10 step=108 play  episode=0  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[ 0.04336883 -0.20127742 -0.0501254   0.06719255]\n",
      "[CartPole-v0 3:9  :22 ] train iteration=10 step=108 play  episode=0  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[ 0.03934328 -0.00547399 -0.04878155 -0.2408744 ]\n",
      "[CartPole-v0 3:9  :23 ] train iteration=10 step=108 play  episode=0  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[ 0.0392338  -0.19986639 -0.05359904  0.03603125]\n",
      "[CartPole-v0 3:9  :24 ] train iteration=10 step=108 play  episode=0  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[ 0.03523647 -0.00401842 -0.05287841 -0.2730694 ]\n",
      "[CartPole-v0 3:9  :25 ] train iteration=10 step=108 play  episode=0  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[ 0.0351561  -0.19834755 -0.0583398   0.00247786]\n",
      "[CartPole-v0 3:9  :26 ] train iteration=10 step=108 play  episode=0  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=1 observation=[ 0.03118915 -0.00243955 -0.05829024 -0.30802637]\n",
      "[CartPole-v0 3:9  :27 ] train iteration=10 step=108 play  episode=0  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[ 0.03114036 -0.19668459 -0.06445077 -0.03428131]\n",
      "[CartPole-v0 3:9  :28 ] train iteration=10 step=108 play  episode=0  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[ 0.02720667 -0.00070043 -0.06513639 -0.34658258]\n",
      "[CartPole-v0 3:9  :29 ] train iteration=10 step=108 play  episode=0  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[ 0.02719266 -0.19483832 -0.07206805 -0.07512986]\n",
      "[CartPole-v0 3:9  :30 ] train iteration=10 step=108 play  episode=0  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=0 observation=[ 0.0232959  -0.38885707 -0.07357064  0.19397316]\n",
      "[CartPole-v0 3:9  :31 ] train iteration=10 step=108 play  episode=0  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=1 observation=[ 0.01551875 -0.19276403 -0.06969118 -0.12098098]\n",
      "[CartPole-v0 3:9  :32 ] train iteration=10 step=108 play  episode=0  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=0 observation=[ 0.01166347 -0.38682189 -0.0721108   0.14892657]\n",
      "[CartPole-v0 3:9  :33 ] train iteration=10 step=108 play  episode=0  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=1 observation=[ 0.00392704 -0.19074538 -0.06913227 -0.16560604]\n",
      "[CartPole-v0 3:9  :34 ] train iteration=10 step=108 play  episode=0  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=0 observation=[ 1.12128043e-04 -3.84813115e-01 -7.24443893e-02  1.04491521e-01]\n",
      "[CartPole-v0 3:9  :35 ] train iteration=10 step=108 play  episode=0  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=1 observation=[-0.00758413 -0.18873177 -0.07035456 -0.21013905]\n",
      "[CartPole-v0 3:9  :36 ] train iteration=10 step=108 play  episode=0  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=0 observation=[-0.01135877 -0.38278093 -0.07455734  0.05954742]\n",
      "[CartPole-v0 3:9  :37 ] train iteration=10 step=108 play  episode=0  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.01901439 -0.18667355 -0.07336639 -0.25569599]\n",
      "[CartPole-v0 3:9  :38 ] train iteration=10 step=108 play  episode=0  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.02274786 -0.38067549 -0.07848031  0.01297373]\n",
      "[CartPole-v0 3:9  :39 ] train iteration=10 step=108 play  episode=0  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=1 observation=[-0.03036137 -0.18452087 -0.07822084 -0.3034021 ]\n",
      "[CartPole-v0 3:9  :40 ] train iteration=10 step=108 play  episode=0  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[-0.03405179 -0.37844596 -0.08428888 -0.03637738]\n",
      "[CartPole-v0 3:9  :41 ] train iteration=10 step=108 play  episode=0  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=1 observation=[-0.04162071 -0.18222278 -0.08501643 -0.35441881]\n",
      "[CartPole-v0 3:9  :42 ] train iteration=10 step=108 play  episode=0  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=0 observation=[-0.04526516 -0.37603949 -0.0921048  -0.08970849]\n",
      "[CartPole-v0 3:9  :43 ] train iteration=10 step=108 play  episode=0  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=1 observation=[-0.05278595 -0.17972631 -0.09389897 -0.40997065]\n",
      "[CartPole-v0 3:9  :44 ] train iteration=10 step=108 play  episode=0  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=0 observation=[-0.05638048 -0.37340031 -0.10209839 -0.14830518]\n",
      "[CartPole-v0 3:9  :45 ] train iteration=10 step=108 play  episode=0  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=1 observation=[-0.06384848 -0.17697576 -0.10506449 -0.47137248]\n",
      "[CartPole-v0 3:9  :46 ] train iteration=10 step=108 play  episode=0  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=0 observation=[-0.067388   -0.37046902 -0.11449194 -0.21356519]\n",
      "[CartPole-v0 3:9  :47 ] train iteration=10 step=108 play  episode=0  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=1 observation=[-0.07479738 -0.17391219 -0.11876324 -0.54005728]\n",
      "[CartPole-v0 3:9  :48 ] train iteration=10 step=108 play  episode=0  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=0 observation=[-0.07827562 -0.36718206 -0.12956439 -0.28702896]\n",
      "[CartPole-v0 3:9  :49 ] train iteration=10 step=108 play  episode=0  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[-0.08561926 -0.56024116 -0.13530497 -0.037853  ]\n",
      "[CartPole-v0 3:10 :50 ] train iteration=10 step=108 play  episode=0  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[-0.09682409 -0.36346452 -0.13606203 -0.36997862]\n",
      "[CartPole-v0 3:10 :1  ] train iteration=10 step=108 play  episode=1  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=0 observation=[-0.01310465 -0.14877215 -0.05026826  0.2543471 ]\n",
      "[CartPole-v0 3:10 :2  ] train iteration=10 step=108 play  episode=1  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=1 observation=[-0.01608009  0.04703016 -0.04518132 -0.05375801]\n",
      "[CartPole-v0 3:10 :3  ] train iteration=10 step=108 play  episode=1  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=0 observation=[-0.01513949 -0.14741581 -0.04625648  0.2243345 ]\n",
      "[CartPole-v0 3:10 :4  ] train iteration=10 step=108 play  episode=1  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=1 observation=[-0.01808781  0.04833569 -0.04176979 -0.08257322]\n",
      "[CartPole-v0 3:10 :5  ] train iteration=10 step=108 play  episode=1  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=0 observation=[-0.01712109 -0.14616338 -0.04342125  0.19664417]\n",
      "[CartPole-v0 3:10 :6  ] train iteration=10 step=108 play  episode=1  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=1 observation=[-0.02004436  0.04955189 -0.03948837 -0.10941387]\n",
      "[CartPole-v0 3:10 :7  ] train iteration=10 step=108 play  episode=1  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=0 observation=[-0.01905332 -0.1449826  -0.04167665  0.17055383]\n",
      "[CartPole-v0 3:10 :8  ] train iteration=10 step=108 play  episode=1  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=1 observation=[-0.02195297  0.05071032 -0.03826557 -0.13498005]\n",
      "[CartPole-v0 3:10 :9  ] train iteration=10 step=108 play  episode=1  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=0 observation=[-0.02093877 -0.14384323 -0.04096517  0.14538931]\n",
      "[CartPole-v0 3:10 :10 ] train iteration=10 step=108 play  episode=1  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=1 observation=[-0.02381563  0.05184071 -0.03805739 -0.15993073]\n",
      "[CartPole-v0 3:10 :11 ] train iteration=10 step=108 play  episode=1  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=0 observation=[-0.02277882 -0.14271631 -0.041256    0.12050731]\n",
      "[CartPole-v0 3:10 :12 ] train iteration=10 step=108 play  episode=1  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=1 observation=[-0.02563315  0.0529717  -0.03884586 -0.18490076]\n",
      "[CartPole-v0 3:10 :13 ] train iteration=10 step=108 play  episode=1  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=0 observation=[-0.02457371 -0.14157353 -0.04254387  0.09527913]\n",
      "[CartPole-v0 3:10 :14 ] train iteration=10 step=108 play  episode=1  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=1 observation=[-0.02740518  0.05413154 -0.04063829 -0.21051699]\n",
      "[CartPole-v0 3:10 :15 ] train iteration=10 step=108 play  episode=1  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=0 observation=[-0.02632255 -0.1403865  -0.04484863  0.06907481]\n",
      "[CartPole-v0 3:10 :16 ] train iteration=10 step=108 play  episode=1  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=1 observation=[-0.02913028  0.05534879 -0.04346713 -0.23741397]\n",
      "[CartPole-v0 3:10 :17 ] train iteration=10 step=108 play  episode=1  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=0 observation=[-0.02802331 -0.13912609 -0.04821541  0.0412475 ]\n",
      "[CartPole-v0 3:10 :18 ] train iteration=10 step=108 play  episode=1  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=1 observation=[-0.03080583  0.05665291 -0.04739046 -0.26624956]\n",
      "[CartPole-v0 3:10 :19 ] train iteration=10 step=108 play  episode=1  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=0 observation=[-0.02967277 -0.13776176 -0.05271545  0.01111745]\n",
      "[CartPole-v0 3:10 :20 ] train iteration=10 step=108 play  episode=1  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[-0.032428    0.05807502 -0.0524931  -0.29772081]\n",
      "[CartPole-v0 3:10 :21 ] train iteration=10 step=108 play  episode=1  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[-0.0312665  -0.13626087 -0.05844752 -0.02204439]\n",
      "[CartPole-v0 3:10 :22 ] train iteration=10 step=108 play  episode=1  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[-0.03399172  0.05964845 -0.05888841 -0.33258037]\n",
      "[CartPole-v0 3:10 :23 ] train iteration=10 step=108 play  episode=1  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[-0.03279875 -0.13458803 -0.06554001 -0.05903388]\n",
      "[CartPole-v0 3:10 :24 ] train iteration=10 step=108 play  episode=1  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[-0.03549051  0.06140944 -0.06672069 -0.37165384]\n",
      "[CartPole-v0 3:10 :25 ] train iteration=10 step=108 play  episode=1  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[-0.03426232 -0.13270433 -0.07415377 -0.10073238]\n",
      "[CartPole-v0 3:10 :26 ] train iteration=10 step=108 play  episode=1  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=1 observation=[-0.03691641  0.06339771 -0.07616842 -0.41585831]\n",
      "[CartPole-v0 3:10 :27 ] train iteration=10 step=108 play  episode=1  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[-0.03564846 -0.13056675 -0.08448558 -0.14812705]\n",
      "[CartPole-v0 3:10 :28 ] train iteration=10 step=108 play  episode=1  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=0 observation=[-0.03825979 -0.32438363 -0.08744812  0.11675209]\n",
      "[CartPole-v0 3:10 :29 ] train iteration=10 step=108 play  episode=1  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=1 observation=[-0.04474746 -0.12812463 -0.08511308 -0.2021885 ]\n",
      "[CartPole-v0 3:10 :30 ] train iteration=10 step=108 play  episode=1  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=0 observation=[-0.04730996 -0.32193273 -0.08915685  0.06247824]\n",
      "[CartPole-v0 3:10 :31 ] train iteration=10 step=108 play  episode=1  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=1 observation=[-0.05374861 -0.1256531  -0.08790729 -0.25694921]\n",
      "[CartPole-v0 3:10 :32 ] train iteration=10 step=108 play  episode=1  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=0 observation=[-0.05626167 -0.3194172  -0.09304627  0.00676317]\n",
      "[CartPole-v0 3:10 :33 ] train iteration=10 step=108 play  episode=1  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=1 observation=[-0.06265002 -0.12309253 -0.09291101 -0.31376612]\n",
      "[CartPole-v0 3:10 :34 ] train iteration=10 step=108 play  episode=1  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=0 observation=[-0.06511187 -0.31677658 -0.09918633 -0.05176968]\n",
      "[CartPole-v0 3:10 :35 ] train iteration=10 step=108 play  episode=1  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=1 observation=[-0.0714474  -0.12038263 -0.10022172 -0.37402569]\n",
      "[CartPole-v0 3:10 :36 ] train iteration=10 step=108 play  episode=1  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=0 observation=[-0.07385505 -0.31394873 -0.10770224 -0.1145494 ]\n",
      "[CartPole-v0 3:10 :37 ] train iteration=10 step=108 play  episode=1  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=1 observation=[-0.08013403 -0.11746159 -0.10999323 -0.43917563]\n",
      "[CartPole-v0 3:10 :38 ] train iteration=10 step=108 play  episode=1  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=0 observation=[-0.08248326 -0.3108689  -0.11877674 -0.18309069]\n",
      "[CartPole-v0 3:10 :39 ] train iteration=10 step=108 play  episode=1  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=1 observation=[-0.08870064 -0.11426537 -0.12243855 -0.5107565 ]\n",
      "[CartPole-v0 3:10 :40 ] train iteration=10 step=108 play  episode=1  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=0 observation=[-0.09098594 -0.30746908 -0.13265368 -0.25902755]\n",
      "[CartPole-v0 3:10 :41 ] train iteration=10 step=108 play  episode=1  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[-0.09713533 -0.50047243 -0.13783423 -0.0109519 ]\n",
      "[CartPole-v0 3:10 :42 ] train iteration=10 step=108 play  episode=1  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[-0.10714477 -0.30367054 -0.13805327 -0.34375008]\n",
      "[CartPole-v0 3:10 :43 ] train iteration=10 step=108 play  episode=1  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=0 observation=[-0.11321818 -0.4965862  -0.14492827 -0.0975886 ]\n",
      "[CartPole-v0 3:10 :44 ] train iteration=10 step=108 play  episode=1  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=1 observation=[-0.12314991 -0.29971655 -0.14688004 -0.4322571 ]\n",
      "[CartPole-v0 3:10 :45 ] train iteration=10 step=108 play  episode=1  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=0 observation=[-0.12914424 -0.49248675 -0.15552519 -0.18924291]\n",
      "[CartPole-v0 3:10 :46 ] train iteration=10 step=108 play  episode=1  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=1 observation=[-0.13899397 -0.29552135 -0.15931004 -0.52666534]\n",
      "[CartPole-v0 3:10 :47 ] train iteration=10 step=108 play  episode=1  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=0 observation=[-0.1449044  -0.48808536 -0.16984335 -0.28811627]\n",
      "[CartPole-v0 3:10 :48 ] train iteration=10 step=108 play  episode=1  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=1 observation=[-0.15466611 -0.29099988 -0.17560568 -0.62918499]\n",
      "[CartPole-v0 3:10 :49 ] train iteration=10 step=108 play  episode=1  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[-0.16048611 -0.48329288 -0.18818938 -0.39654457]\n",
      "[CartPole-v0 3:11 :50 ] train iteration=10 step=108 play  episode=1  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=0 observation=[-0.17015196 -0.67531613 -0.19612027 -0.16859674]\n",
      "[CartPole-v0 3:11 :1  ] train iteration=10 step=108 play  episode=2  step=1     sum_of_rewards=1.0     reward=1.0   done=False action=1 observation=[ 0.0465928   0.17036295  0.04264826 -0.2425029 ]\n",
      "[CartPole-v0 3:11 :2  ] train iteration=10 step=108 play  episode=2  step=2     sum_of_rewards=2.0     reward=1.0   done=False action=0 observation=[ 0.05000006 -0.02534142  0.0377982   0.06332151]\n",
      "[CartPole-v0 3:11 :3  ] train iteration=10 step=108 play  episode=2  step=3     sum_of_rewards=3.0     reward=1.0   done=False action=1 observation=[ 0.04949323  0.16921878  0.03906463 -0.21720032]\n",
      "[CartPole-v0 3:11 :4  ] train iteration=10 step=108 play  episode=2  step=4     sum_of_rewards=4.0     reward=1.0   done=False action=0 observation=[ 0.05287761 -0.02643921  0.03472063  0.08754484]\n",
      "[CartPole-v0 3:11 :5  ] train iteration=10 step=108 play  episode=2  step=5     sum_of_rewards=5.0     reward=1.0   done=False action=1 observation=[ 0.05234882  0.1681683   0.03647152 -0.19398467]\n",
      "[CartPole-v0 3:11 :6  ] train iteration=10 step=108 play  episode=2  step=6     sum_of_rewards=6.0     reward=1.0   done=False action=0 observation=[ 0.05571219 -0.02745587  0.03259183  0.1099767 ]\n",
      "[CartPole-v0 3:11 :7  ] train iteration=10 step=108 play  episode=2  step=7     sum_of_rewards=7.0     reward=1.0   done=False action=1 observation=[ 0.05516307  0.16718426  0.03479136 -0.17224814]\n",
      "[CartPole-v0 3:11 :8  ] train iteration=10 step=108 play  episode=2  step=8     sum_of_rewards=8.0     reward=1.0   done=False action=0 observation=[ 0.05850676 -0.02841793  0.0313464   0.13120418]\n",
      "[CartPole-v0 3:11 :9  ] train iteration=10 step=108 play  episode=2  step=9     sum_of_rewards=9.0     reward=1.0   done=False action=1 observation=[ 0.0579384   0.1662413   0.03397048 -0.15142689]\n",
      "[CartPole-v0 3:11 :10 ] train iteration=10 step=108 play  episode=2  step=10    sum_of_rewards=10.0    reward=1.0   done=False action=0 observation=[ 0.06126322 -0.02935019  0.03094195  0.15177648]\n",
      "[CartPole-v0 3:11 :11 ] train iteration=10 step=108 play  episode=2  step=11    sum_of_rewards=11.0    reward=1.0   done=False action=1 observation=[ 0.06067622  0.16531535  0.03397748 -0.13098658]\n",
      "[CartPole-v0 3:11 :12 ] train iteration=10 step=108 play  episode=2  step=12    sum_of_rewards=12.0    reward=1.0   done=False action=0 observation=[ 0.06398253 -0.03027643  0.03135774  0.1722192 ]\n",
      "[CartPole-v0 3:11 :13 ] train iteration=10 step=108 play  episode=2  step=13    sum_of_rewards=13.0    reward=1.0   done=False action=1 observation=[ 0.063377    0.16438301  0.03480213 -0.11040874]\n",
      "[CartPole-v0 3:11 :14 ] train iteration=10 step=108 play  episode=2  step=14    sum_of_rewards=14.0    reward=1.0   done=False action=0 observation=[ 0.06666466 -0.03121991  0.03259395  0.19304774]\n",
      "[CartPole-v0 3:11 :15 ] train iteration=10 step=108 play  episode=2  step=15    sum_of_rewards=15.0    reward=1.0   done=False action=1 observation=[ 0.06604026  0.16342099  0.03645491 -0.08917761]\n",
      "[CartPole-v0 3:11 :16 ] train iteration=10 step=108 play  episode=2  step=16    sum_of_rewards=16.0    reward=1.0   done=False action=0 observation=[ 0.06930868 -0.03220402  0.03467136  0.21478031]\n",
      "[CartPole-v0 3:11 :17 ] train iteration=10 step=108 play  episode=2  step=17    sum_of_rewards=17.0    reward=1.0   done=False action=1 observation=[ 0.0686646   0.16240554  0.03896696 -0.06676726]\n",
      "[CartPole-v0 3:11 :18 ] train iteration=10 step=108 play  episode=2  step=18    sum_of_rewards=18.0    reward=1.0   done=False action=0 observation=[ 0.07191271 -0.03325279  0.03763162  0.23795083]\n",
      "[CartPole-v0 3:11 :19 ] train iteration=10 step=108 play  episode=2  step=19    sum_of_rewards=19.0    reward=1.0   done=False action=1 observation=[ 0.07124765  0.1613119   0.04239063 -0.0426285 ]\n",
      "[CartPole-v0 3:11 :20 ] train iteration=10 step=108 play  episode=2  step=20    sum_of_rewards=20.0    reward=1.0   done=False action=1 observation=[ 0.07447389  0.35580115  0.04153806 -0.32164119]\n",
      "[CartPole-v0 3:11 :21 ] train iteration=10 step=108 play  episode=2  step=21    sum_of_rewards=21.0    reward=1.0   done=False action=0 observation=[ 0.08158991  0.16011305  0.03510524 -0.01615356]\n",
      "[CartPole-v0 3:11 :22 ] train iteration=10 step=108 play  episode=2  step=22    sum_of_rewards=22.0    reward=1.0   done=False action=1 observation=[ 0.08479218  0.35471443  0.03478217 -0.29755695]\n",
      "[CartPole-v0 3:11 :23 ] train iteration=10 step=108 play  episode=2  step=23    sum_of_rewards=23.0    reward=1.0   done=False action=0 observation=[0.09188646 0.15911436 0.02883103 0.00588959]\n",
      "[CartPole-v0 3:11 :24 ] train iteration=10 step=108 play  episode=2  step=24    sum_of_rewards=24.0    reward=1.0   done=False action=1 observation=[ 0.09506875  0.35381123  0.02894882 -0.27755919]\n",
      "[CartPole-v0 3:11 :25 ] train iteration=10 step=108 play  episode=2  step=25    sum_of_rewards=25.0    reward=1.0   done=False action=0 observation=[0.10214498 0.1582885  0.02339764 0.02411178]\n",
      "[CartPole-v0 3:11 :26 ] train iteration=10 step=108 play  episode=2  step=26    sum_of_rewards=26.0    reward=1.0   done=False action=1 observation=[ 0.10531075  0.35306723  0.02387987 -0.26109807]\n",
      "[CartPole-v0 3:11 :27 ] train iteration=10 step=108 play  episode=2  step=27    sum_of_rewards=27.0    reward=1.0   done=False action=0 observation=[0.11237209 0.15761268 0.01865791 0.03902019]\n",
      "[CartPole-v0 3:11 :28 ] train iteration=10 step=108 play  episode=2  step=28    sum_of_rewards=28.0    reward=1.0   done=False action=1 observation=[ 0.11552434  0.35246218  0.01943832 -0.24771808]\n",
      "[CartPole-v0 3:11 :29 ] train iteration=10 step=108 play  episode=2  step=29    sum_of_rewards=29.0    reward=1.0   done=False action=0 observation=[0.12257359 0.15706809 0.01448395 0.05103219]\n",
      "[CartPole-v0 3:11 :30 ] train iteration=10 step=108 play  episode=2  step=30    sum_of_rewards=30.0    reward=1.0   done=False action=1 observation=[ 0.12571495  0.35197939  0.0155046  -0.23704597]\n",
      "[CartPole-v0 3:11 :31 ] train iteration=10 step=108 play  episode=2  step=31    sum_of_rewards=31.0    reward=1.0   done=False action=0 observation=[0.13275454 0.1566394  0.01076368 0.06048697]\n",
      "[CartPole-v0 3:11 :32 ] train iteration=10 step=108 play  episode=2  step=32    sum_of_rewards=32.0    reward=1.0   done=False action=1 observation=[ 0.13588732  0.35160538  0.01197342 -0.2287806 ]\n",
      "[CartPole-v0 3:11 :33 ] train iteration=10 step=108 play  episode=2  step=33    sum_of_rewards=33.0    reward=1.0   done=False action=0 observation=[0.14291943 0.15631439 0.00739781 0.06765499]\n",
      "[CartPole-v0 3:11 :34 ] train iteration=10 step=108 play  episode=2  step=34    sum_of_rewards=34.0    reward=1.0   done=False action=1 observation=[ 0.14604572  0.3513295   0.00875091 -0.22268474]\n",
      "[CartPole-v0 3:11 :35 ] train iteration=10 step=108 play  episode=2  step=35    sum_of_rewards=35.0    reward=1.0   done=False action=0 observation=[0.15307231 0.15608358 0.00429721 0.07274567]\n",
      "[CartPole-v0 3:11 :36 ] train iteration=10 step=108 play  episode=2  step=36    sum_of_rewards=36.0    reward=1.0   done=False action=1 observation=[ 0.15619398  0.35114366  0.00575212 -0.21857838]\n",
      "[CartPole-v0 3:11 :37 ] train iteration=10 step=108 play  episode=2  step=37    sum_of_rewards=37.0    reward=1.0   done=False action=0 observation=[0.16321686 0.15593995 0.00138056 0.07591345]\n",
      "[CartPole-v0 3:11 :38 ] train iteration=10 step=108 play  episode=2  step=38    sum_of_rewards=38.0    reward=1.0   done=False action=1 observation=[ 0.16633565  0.35104209  0.00289883 -0.21633359]\n",
      "[CartPole-v0 3:11 :39 ] train iteration=10 step=108 play  episode=2  step=39    sum_of_rewards=39.0    reward=1.0   done=False action=0 observation=[ 0.1733565   0.15587882 -0.00142785  0.07726234]\n",
      "[CartPole-v0 3:11 :40 ] train iteration=10 step=108 play  episode=2  step=40    sum_of_rewards=40.0    reward=1.0   done=False action=1 observation=[ 1.76474072e-01  3.51021207e-01  1.17400385e-04 -2.15870731e-01]\n",
      "[CartPole-v0 3:11 :41 ] train iteration=10 step=108 play  episode=2  step=41    sum_of_rewards=41.0    reward=1.0   done=False action=0 observation=[ 0.1834945   0.15589758 -0.00420001  0.07684923]\n",
      "[CartPole-v0 3:11 :42 ] train iteration=10 step=108 play  episode=2  step=42    sum_of_rewards=42.0    reward=1.0   done=False action=1 observation=[ 0.18661245  0.35107949 -0.00266303 -0.21715585]\n",
      "[CartPole-v0 3:11 :43 ] train iteration=10 step=108 play  episode=2  step=43    sum_of_rewards=43.0    reward=1.0   done=False action=0 observation=[ 0.19363404  0.15599571 -0.00700615  0.07468585]\n",
      "[CartPole-v0 3:11 :44 ] train iteration=10 step=108 play  episode=2  step=44    sum_of_rewards=44.0    reward=1.0   done=False action=1 observation=[ 0.19675395  0.35121739 -0.00551243 -0.22019928]\n",
      "[CartPole-v0 3:11 :45 ] train iteration=10 step=108 play  episode=2  step=45    sum_of_rewards=45.0    reward=1.0   done=False action=0 observation=[ 0.2037783   0.15617467 -0.00991642  0.07073971]\n",
      "[CartPole-v0 3:11 :46 ] train iteration=10 step=108 play  episode=2  step=46    sum_of_rewards=46.0    reward=1.0   done=False action=1 observation=[ 0.20690179  0.35143737 -0.00850162 -0.22505532]\n",
      "[CartPole-v0 3:11 :47 ] train iteration=10 step=108 play  episode=2  step=47    sum_of_rewards=47.0    reward=1.0   done=False action=0 observation=[ 0.21393054  0.15643795 -0.01300273  0.06493379]\n",
      "[CartPole-v0 3:11 :48 ] train iteration=10 step=108 play  episode=2  step=48    sum_of_rewards=48.0    reward=1.0   done=False action=1 observation=[ 0.2170593   0.35174389 -0.01170405 -0.23182305]\n",
      "[CartPole-v0 3:11 :49 ] train iteration=10 step=108 play  episode=2  step=49    sum_of_rewards=49.0    reward=1.0   done=False action=0 observation=[ 0.22409418  0.15679112 -0.01634051  0.05714517]\n",
      "[CartPole-v0 3:12 :50 ] train iteration=10 step=108 play  episode=2  step=50    sum_of_rewards=50.0    reward=1.0   done=True  action=1 observation=[ 0.22723     0.35214351 -0.01519761 -0.24064819]\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<easyagents.core.PpoTrainContext at 0x2a1609bec88>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    },
    {
     "data": {
      "text/plain": "<Figure size 1224x432 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import duration, log\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0')\n",
    "ppoAgent.train([log.Step(), duration.Fast()], default_plots=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For each call to the gym environments step method you get a log entry, along with the action taken and current\n",
    "observation. Each entry starts with \n",
    "\n",
    "[{gym_env_id} {instance_id}:{episode_in_instance}:{step_in_episode}]\n",
    "\n",
    "followed by the id of the current training iteration as well as the current iteration step count.\n",
    "If in a evaluation period you get the same statistics for the current evaluation episode.\n",
    "\n",
    "You may easily implement other log callbacks to produce statistics specific to your problem domain.\n",
    "\n",
    "## Fixing a jupyter output cell clearing\n",
    "It seems that jupyter / matplotlib backend changes its behaviour of outputing the current figure of an \n",
    "evaluated cell (if you can help here, please let use know by \n",
    "[creating an issue](https://github.com/christianhidber/easyagents/issues/new/choose)).\n",
    "\n",
    "Nonetheless you may directly control easyagents jupyter ouput cell clearing behaviour through the plot.Clear()\n",
    "callback:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import duration, log\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0')\n",
    "ppoAgent.train([log.Clear(on_train=False,on_play=False), duration.Fast()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If your plot gets \"doubled\" after cell evaluation set on_train / on_play to True, if it disappears to False."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "zpzHtN3-kQ26",
    "w3OdHyWEEEwy",
    "bzoq0VM85p46"
   ],
   "include_colab_link": true,
   "name": "easyagents_orso.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}