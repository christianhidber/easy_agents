{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/christianhidber/easyagents/blob/master/jupyter_notebooks/easyagents_logging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving & loading a trained policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages (gym, tfagents, tensorflow,....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### suppress package warnings, in colab: load additional packages for rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "if 'google.colab' in sys.modules:\n",
    "    !apt-get install xvfb >/dev/null\n",
    "    !pip install pyvirtualdisplay >/dev/null    \n",
    "    \n",
    "    from pyvirtualdisplay import Display\n",
    "    Display(visible=0, size=(960, 720)).start() \n",
    "else:\n",
    "    #  for local installation\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### install easyagents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    !pip install -q easyagents >/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading\n",
    "\n",
    "Use `agent.save(directory)` to save the current policy to `directory`.\n",
    "If you omit directory, the policy is saved to a temp directory, if `directory` does not exist yet, it is created.\n",
    "`save` returns the location of the saved policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import plot\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0')\n",
    "ppoAgent.train(num_iterations=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dir = tempfile.mkdtemp()\n",
    "ppoAgent.save(directory=dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at directory content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.listdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `easyagent.json` contains the agent definition (type, model, backend & seed) while \n",
    "the `policy` directory contains the actual policy in a backend specific format.\n",
    "\n",
    "To load a previously saved policy use `EasyAgent.load(directory)`. Once loaded you may directly call `play()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from easyagents.agents import load\n",
    "\n",
    "ppoAgent = load(dir)\n",
    "ppoAgent.play([plot.State()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Saving during training\n",
    "\n",
    "To save intermediate versions of the agent during training use the `save.Best(...)` or `save.Every(...)` callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from easyagents.agents import PpoAgent\n",
    "from easyagents.callbacks import save\n",
    "\n",
    "ppoAgent = PpoAgent('CartPole-v0')\n",
    "dir = tempfile.mkdtemp()\n",
    "ppoAgent.train([save.Best(dir)], num_iterations=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`save.Best` saves an agent after evaluation, if the average reward is larger than all previous ones. \n",
    "If we don't pass a directory to the constructor, the agents are stored in a temp directory.\n",
    "Let's take a look at the save policies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.listdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note that each version is stored in a sub-directory reflecting the number of episodes trained as well as the \n",
    "achieved average reward. \n",
    "\n",
    "If you prefer saving a copy in a fixed interval, use `save.Every`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dir = tempfile.mkdtemp()\n",
    "ppoAgent.train([save.Every(directory=dir)], num_iterations=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.listdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By default the policy is saved after each evaluation. To specify another frequency use the `num_evals_between_save`\n",
    "parameter.\n",
    "\n",
    "Note that the directory names again reflect the number of trained episodes as well as the average reward.\n",
    "A save occurs every\n",
    "````\n",
    "num_evals_between_save * num_iterations_between_eval * num_iterations * num_episodes_per_iteration\n",
    "````\n",
    "episodes. All values are `agent.train(...)` parameters, except `num_evals_between_save`."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "zpzHtN3-kQ26",
    "w3OdHyWEEEwy",
    "bzoq0VM85p46"
   ],
   "include_colab_link": true,
   "name": "easyagents_logging.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}